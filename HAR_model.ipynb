{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"../data/HAR_Dataset\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"../data/HAR_Dataset\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body_acc_x',\n",
       " 'body_acc_y',\n",
       " 'body_acc_z',\n",
       " 'body_gyro_x',\n",
       " 'body_gyro_y',\n",
       " 'body_gyro_z',\n",
       " 'total_acc_x',\n",
       " 'total_acc_y',\n",
       " 'total_acc_z']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ch_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: N = 7352, steps = 128, channels = 9\n",
      "Test data shape: N = 2947, steps = 128, channels = 9\n"
     ]
    }
   ],
   "source": [
    "print (\"Training data shape: N = {:d}, steps = {:d}, channels = {:d}\".format(X_train.shape[0],\n",
    "                                                                             X_train.shape[1],\n",
    "                                                                             X_train.shape[2]))\n",
    "print (\"Test data shape: N = {:d}, steps = {:d}, channels = {:d}\".format(X_test.shape[0],\n",
    "                                                                         X_test.shape[1],\n",
    "                                                                         X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean value for each channel at each step\n",
    "all_data = np.concatenate((X_train,X_test), axis = 0)\n",
    "means_ = np.zeros((all_data.shape[1],all_data.shape[2]))\n",
    "stds_ = np.zeros((all_data.shape[1],all_data.shape[2]))\n",
    "\n",
    "for ch in range(X_train.shape[2]):\n",
    "    means_[:,ch] = np.mean(all_data[:,:,ch], axis=0)\n",
    "    stds_[:,ch] = np.std(all_data[:,:,ch], axis=0)\n",
    "    \n",
    "df_mean = pd.DataFrame(data = means_)\n",
    "df_std = pd.DataFrame(data = stds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_mean.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_std.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Mean value for each channel at each step\n",
    "all_data = np.concatenate((X_train,X_test), axis = 0)\n",
    "means_ = np.zeros((all_data.shape[1],all_data.shape[2]))\n",
    "stds_ = np.zeros((all_data.shape[1],all_data.shape[2]))\n",
    "\n",
    "for ch in range(X_train.shape[2]):\n",
    "    means_[:,ch] = np.mean(all_data[:,:,ch], axis=0)\n",
    "    stds_[:,ch] = np.std(all_data[:,:,ch], axis=0)\n",
    "    \n",
    "df_mean = pd.DataFrame(data = means_)\n",
    "df_std = pd.DataFrame(data = stds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_mean.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"../data/HAR_Dataset\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"../data/HAR_Dataset\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb7437fa58>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb666d4c88>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train[:,:,np.newaxis,:][0,:,0,0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 7352\n",
      "validation dataset size: 2947\n",
      "build conv_x\n",
      "build conv_y\n",
      "build conv_z\n",
      "Merging skip connection\n",
      "        -- model was built.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 1, 9)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 1, 10)   1540        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 1, 10)   40          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 1, 64)   10944       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 1, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 1, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 1, 128)  139392      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 1, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 1, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 1, 128)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 1, 64)   704         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 1, 64)   73792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 1, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 1, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 1, 64)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 1, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            455         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 228,147\n",
      "Trainable params: 227,487\n",
      "Non-trainable params: 660\n",
      "__________________________________________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/700\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001FB56A8EEA0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001FB56A8EEA0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001FB56A8EEA0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.2397 - accuracy: 0.9240 - val_loss: 0.6816 - val_accuracy: 0.7282\n",
      "Epoch 2/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.1389 - accuracy: 0.9470 - val_loss: 0.5084 - val_accuracy: 0.8521\n",
      "Epoch 3/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.1396 - accuracy: 0.9440 - val_loss: 0.2499 - val_accuracy: 0.9125\n",
      "Epoch 4/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.1203 - accuracy: 0.9506 - val_loss: 0.2616 - val_accuracy: 0.9199\n",
      "Epoch 5/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.1397 - accuracy: 0.9436 - val_loss: 0.2397 - val_accuracy: 0.9247\n",
      "Epoch 6/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.1169 - accuracy: 0.9499 - val_loss: 0.2021 - val_accuracy: 0.9264\n",
      "Epoch 7/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.1274 - accuracy: 0.9478 - val_loss: 0.2972 - val_accuracy: 0.9040\n",
      "Epoch 8/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.1219 - accuracy: 0.9502 - val_loss: 0.1666 - val_accuracy: 0.9243\n",
      "Epoch 9/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.1119 - accuracy: 0.9527 - val_loss: 0.2058 - val_accuracy: 0.9050\n",
      "Epoch 10/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.1093 - accuracy: 0.9523 - val_loss: 0.2163 - val_accuracy: 0.9247\n",
      "Epoch 11/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.1055 - accuracy: 0.9529 - val_loss: 0.2337 - val_accuracy: 0.9111\n",
      "Epoch 12/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.1072 - accuracy: 0.9497 - val_loss: 0.1973 - val_accuracy: 0.9131\n",
      "Epoch 13/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.1027 - accuracy: 0.9561 - val_loss: 0.1731 - val_accuracy: 0.9450\n",
      "Epoch 14/700\n",
      "7352/7352 [==============================] - 3s 361us/sample - loss: 0.1042 - accuracy: 0.9544 - val_loss: 0.1781 - val_accuracy: 0.9477\n",
      "Epoch 15/700\n",
      "7352/7352 [==============================] - 3s 342us/sample - loss: 0.1141 - accuracy: 0.9527 - val_loss: 0.1902 - val_accuracy: 0.9287\n",
      "Epoch 16/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.1196 - accuracy: 0.9499 - val_loss: 0.1966 - val_accuracy: 0.9253\n",
      "Epoch 17/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.1041 - accuracy: 0.9555 - val_loss: 0.2160 - val_accuracy: 0.9264\n",
      "Epoch 18/700\n",
      "7352/7352 [==============================] - 3s 388us/sample - loss: 0.1046 - accuracy: 0.9570 - val_loss: 0.1991 - val_accuracy: 0.9321\n",
      "Epoch 19/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.1148 - accuracy: 0.9509 - val_loss: 0.2415 - val_accuracy: 0.9060\n",
      "Epoch 20/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.1075 - accuracy: 0.9525 - val_loss: 0.2647 - val_accuracy: 0.9162\n",
      "Epoch 21/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.1048 - accuracy: 0.9543 - val_loss: 0.2005 - val_accuracy: 0.9233\n",
      "Epoch 22/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0969 - accuracy: 0.9563 - val_loss: 0.2110 - val_accuracy: 0.9328\n",
      "Epoch 23/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.1063 - accuracy: 0.9542 - val_loss: 0.2213 - val_accuracy: 0.9440\n",
      "Epoch 24/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.1005 - accuracy: 0.9557 - val_loss: 0.2244 - val_accuracy: 0.9298\n",
      "Epoch 25/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.1001 - accuracy: 0.9538 - val_loss: 0.2062 - val_accuracy: 0.9379\n",
      "Epoch 26/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0963 - accuracy: 0.9555 - val_loss: 0.3088 - val_accuracy: 0.9033\n",
      "Epoch 27/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0951 - accuracy: 0.9559 - val_loss: 0.2635 - val_accuracy: 0.9155\n",
      "Epoch 28/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0949 - accuracy: 0.9576 - val_loss: 0.2392 - val_accuracy: 0.9291\n",
      "Epoch 29/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0933 - accuracy: 0.9580 - val_loss: 0.2107 - val_accuracy: 0.9338\n",
      "Epoch 30/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0952 - accuracy: 0.9581 - val_loss: 0.2640 - val_accuracy: 0.9189\n",
      "Epoch 31/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0936 - accuracy: 0.9600 - val_loss: 0.2267 - val_accuracy: 0.9298\n",
      "Epoch 32/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.1006 - accuracy: 0.9555 - val_loss: 0.2239 - val_accuracy: 0.9301\n",
      "Epoch 33/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0913 - accuracy: 0.9572 - val_loss: 0.2087 - val_accuracy: 0.9345\n",
      "Epoch 34/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0928 - accuracy: 0.9589 - val_loss: 0.2480 - val_accuracy: 0.9277\n",
      "Epoch 35/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0911 - accuracy: 0.9618 - val_loss: 0.2728 - val_accuracy: 0.9169\n",
      "Epoch 36/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0909 - accuracy: 0.9607 - val_loss: 0.2200 - val_accuracy: 0.9325\n",
      "Epoch 37/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0882 - accuracy: 0.9623 - val_loss: 0.2523 - val_accuracy: 0.9192\n",
      "Epoch 38/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0896 - accuracy: 0.9619 - val_loss: 0.2538 - val_accuracy: 0.9209\n",
      "Epoch 39/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0962 - accuracy: 0.9542 - val_loss: 0.2530 - val_accuracy: 0.9321\n",
      "Epoch 40/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0884 - accuracy: 0.9597 - val_loss: 0.2511 - val_accuracy: 0.9345\n",
      "Epoch 41/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0916 - accuracy: 0.9585 - val_loss: 0.2288 - val_accuracy: 0.9403\n",
      "Epoch 42/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0938 - accuracy: 0.9570 - val_loss: 0.2207 - val_accuracy: 0.9460\n",
      "Epoch 43/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0877 - accuracy: 0.9611 - val_loss: 0.2390 - val_accuracy: 0.9223\n",
      "Epoch 44/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0989 - accuracy: 0.9585 - val_loss: 0.1951 - val_accuracy: 0.9423\n",
      "Epoch 45/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0887 - accuracy: 0.9592 - val_loss: 0.2159 - val_accuracy: 0.9406\n",
      "Epoch 46/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0870 - accuracy: 0.9585 - val_loss: 0.2328 - val_accuracy: 0.9223\n",
      "Epoch 47/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0907 - accuracy: 0.9588 - val_loss: 0.2335 - val_accuracy: 0.9321\n",
      "Epoch 48/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0853 - accuracy: 0.9589 - val_loss: 0.2472 - val_accuracy: 0.9284\n",
      "Epoch 49/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0880 - accuracy: 0.9601 - val_loss: 0.2158 - val_accuracy: 0.9467\n",
      "Epoch 50/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0914 - accuracy: 0.9592 - val_loss: 0.2311 - val_accuracy: 0.9294\n",
      "Epoch 51/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0877 - accuracy: 0.9610 - val_loss: 0.2268 - val_accuracy: 0.9281\n",
      "Epoch 52/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0883 - accuracy: 0.9587 - val_loss: 0.2300 - val_accuracy: 0.9291\n",
      "Epoch 53/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0851 - accuracy: 0.9597 - val_loss: 0.2488 - val_accuracy: 0.9175\n",
      "Epoch 54/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0788 - accuracy: 0.9656 - val_loss: 0.2250 - val_accuracy: 0.9342\n",
      "Epoch 55/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0941 - accuracy: 0.9593 - val_loss: 0.2331 - val_accuracy: 0.9274\n",
      "Epoch 56/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0840 - accuracy: 0.9614 - val_loss: 0.2346 - val_accuracy: 0.9220\n",
      "Epoch 57/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0851 - accuracy: 0.9608 - val_loss: 0.2161 - val_accuracy: 0.9413\n",
      "Epoch 58/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0809 - accuracy: 0.9635 - val_loss: 0.2278 - val_accuracy: 0.9281\n",
      "Epoch 59/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0846 - accuracy: 0.9621 - val_loss: 0.2426 - val_accuracy: 0.9240\n",
      "Epoch 60/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0858 - accuracy: 0.9619 - val_loss: 0.2403 - val_accuracy: 0.9372\n",
      "Epoch 61/700\n",
      "7352/7352 [==============================] - 2s 336us/sample - loss: 0.0849 - accuracy: 0.9611 - val_loss: 0.2324 - val_accuracy: 0.9348\n",
      "Epoch 62/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0838 - accuracy: 0.9626 - val_loss: 0.2430 - val_accuracy: 0.9220\n",
      "Epoch 63/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0903 - accuracy: 0.9608 - val_loss: 0.2080 - val_accuracy: 0.9498\n",
      "Epoch 64/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0865 - accuracy: 0.9612 - val_loss: 0.2395 - val_accuracy: 0.9311\n",
      "Epoch 65/700\n",
      "7352/7352 [==============================] - 3s 350us/sample - loss: 0.0843 - accuracy: 0.9611 - val_loss: 0.2589 - val_accuracy: 0.9199\n",
      "Epoch 66/700\n",
      "7352/7352 [==============================] - 3s 350us/sample - loss: 0.0794 - accuracy: 0.9653 - val_loss: 0.2575 - val_accuracy: 0.9230\n",
      "Epoch 67/700\n",
      "7352/7352 [==============================] - 3s 370us/sample - loss: 0.0774 - accuracy: 0.9674 - val_loss: 0.2486 - val_accuracy: 0.9253\n",
      "Epoch 68/700\n",
      "7352/7352 [==============================] - 3s 371us/sample - loss: 0.0776 - accuracy: 0.9645 - val_loss: 0.2419 - val_accuracy: 0.9328\n",
      "Epoch 69/700\n",
      "7352/7352 [==============================] - 3s 386us/sample - loss: 0.0808 - accuracy: 0.9627 - val_loss: 0.2496 - val_accuracy: 0.9369\n",
      "Epoch 70/700\n",
      "7352/7352 [==============================] - 3s 365us/sample - loss: 0.0842 - accuracy: 0.9633 - val_loss: 0.2493 - val_accuracy: 0.9359\n",
      "Epoch 71/700\n",
      "7352/7352 [==============================] - 3s 384us/sample - loss: 0.0779 - accuracy: 0.9649 - val_loss: 0.2460 - val_accuracy: 0.9345\n",
      "Epoch 72/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0787 - accuracy: 0.9638 - val_loss: 0.2448 - val_accuracy: 0.9321\n",
      "Epoch 73/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0809 - accuracy: 0.9635 - val_loss: 0.2381 - val_accuracy: 0.9420\n",
      "Epoch 74/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0811 - accuracy: 0.9629 - val_loss: 0.2275 - val_accuracy: 0.9328\n",
      "Epoch 75/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0831 - accuracy: 0.9618 - val_loss: 0.2445 - val_accuracy: 0.9220\n",
      "Epoch 76/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0806 - accuracy: 0.9630 - val_loss: 0.2281 - val_accuracy: 0.9386\n",
      "Epoch 77/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0832 - accuracy: 0.9626 - val_loss: 0.2205 - val_accuracy: 0.9501\n",
      "Epoch 78/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0850 - accuracy: 0.9607 - val_loss: 0.2462 - val_accuracy: 0.9298\n",
      "Epoch 79/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0746 - accuracy: 0.9660 - val_loss: 0.2514 - val_accuracy: 0.9260\n",
      "Epoch 80/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0780 - accuracy: 0.9648 - val_loss: 0.2298 - val_accuracy: 0.9423\n",
      "Epoch 81/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0732 - accuracy: 0.9665 - val_loss: 0.2326 - val_accuracy: 0.9413\n",
      "Epoch 82/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0752 - accuracy: 0.9641 - val_loss: 0.2466 - val_accuracy: 0.9352\n",
      "Epoch 83/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0751 - accuracy: 0.9656 - val_loss: 0.2397 - val_accuracy: 0.9338\n",
      "Epoch 84/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0731 - accuracy: 0.9656 - val_loss: 0.2613 - val_accuracy: 0.9311\n",
      "Epoch 85/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0772 - accuracy: 0.9631 - val_loss: 0.2604 - val_accuracy: 0.9352\n",
      "Epoch 86/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0733 - accuracy: 0.9655 - val_loss: 0.2366 - val_accuracy: 0.9406\n",
      "Epoch 87/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0818 - accuracy: 0.9637 - val_loss: 0.3273 - val_accuracy: 0.9111\n",
      "Epoch 88/700\n",
      "7352/7352 [==============================] - 3s 348us/sample - loss: 0.0755 - accuracy: 0.9656 - val_loss: 0.1963 - val_accuracy: 0.9528\n",
      "Epoch 89/700\n",
      "7352/7352 [==============================] - 2s 337us/sample - loss: 0.0827 - accuracy: 0.9597 - val_loss: 0.2155 - val_accuracy: 0.9420\n",
      "Epoch 90/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0716 - accuracy: 0.9676 - val_loss: 0.2465 - val_accuracy: 0.9369\n",
      "Epoch 91/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0764 - accuracy: 0.9655 - val_loss: 0.2485 - val_accuracy: 0.9332\n",
      "Epoch 92/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0703 - accuracy: 0.9678 - val_loss: 0.2339 - val_accuracy: 0.9427\n",
      "Epoch 93/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0702 - accuracy: 0.9664 - val_loss: 0.2397 - val_accuracy: 0.9433\n",
      "Epoch 94/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0738 - accuracy: 0.9652 - val_loss: 0.2354 - val_accuracy: 0.9355\n",
      "Epoch 95/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0819 - accuracy: 0.9630 - val_loss: 0.2387 - val_accuracy: 0.9379\n",
      "Epoch 96/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0733 - accuracy: 0.9674 - val_loss: 0.2195 - val_accuracy: 0.9325\n",
      "Epoch 97/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0752 - accuracy: 0.9656 - val_loss: 0.2353 - val_accuracy: 0.9328\n",
      "Epoch 98/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0775 - accuracy: 0.9672 - val_loss: 0.2661 - val_accuracy: 0.9220\n",
      "Epoch 99/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0735 - accuracy: 0.9653 - val_loss: 0.2344 - val_accuracy: 0.9355\n",
      "Epoch 100/700\n",
      "7352/7352 [==============================] - 3s 350us/sample - loss: 0.0773 - accuracy: 0.9652 - val_loss: 0.2757 - val_accuracy: 0.9135\n",
      "Epoch 101/700\n",
      "7352/7352 [==============================] - 3s 344us/sample - loss: 0.0689 - accuracy: 0.9683 - val_loss: 0.2253 - val_accuracy: 0.9284\n",
      "Epoch 102/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0738 - accuracy: 0.9660 - val_loss: 0.2318 - val_accuracy: 0.9270\n",
      "Epoch 103/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0693 - accuracy: 0.9701 - val_loss: 0.2170 - val_accuracy: 0.9369\n",
      "Epoch 104/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0682 - accuracy: 0.9691 - val_loss: 0.2384 - val_accuracy: 0.9355\n",
      "Epoch 105/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0686 - accuracy: 0.9679 - val_loss: 0.2340 - val_accuracy: 0.9369\n",
      "Epoch 106/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0694 - accuracy: 0.9705 - val_loss: 0.2827 - val_accuracy: 0.9175\n",
      "Epoch 107/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0707 - accuracy: 0.9674 - val_loss: 0.2841 - val_accuracy: 0.9237\n",
      "Epoch 108/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0756 - accuracy: 0.9674 - val_loss: 0.2364 - val_accuracy: 0.9460\n",
      "Epoch 109/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0678 - accuracy: 0.9702 - val_loss: 0.2601 - val_accuracy: 0.9342\n",
      "Epoch 110/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0701 - accuracy: 0.9684 - val_loss: 0.2509 - val_accuracy: 0.9477\n",
      "Epoch 111/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0683 - accuracy: 0.9687 - val_loss: 0.2281 - val_accuracy: 0.9447\n",
      "Epoch 112/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0727 - accuracy: 0.9669 - val_loss: 0.2515 - val_accuracy: 0.9325\n",
      "Epoch 113/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0711 - accuracy: 0.9663 - val_loss: 0.2360 - val_accuracy: 0.9433\n",
      "Epoch 114/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0681 - accuracy: 0.9693 - val_loss: 0.2360 - val_accuracy: 0.9335\n",
      "Epoch 115/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0646 - accuracy: 0.9699 - val_loss: 0.2379 - val_accuracy: 0.9416\n",
      "Epoch 116/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0803 - accuracy: 0.9634 - val_loss: 0.2599 - val_accuracy: 0.9257\n",
      "Epoch 117/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0734 - accuracy: 0.9672 - val_loss: 0.3087 - val_accuracy: 0.9260\n",
      "Epoch 118/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0701 - accuracy: 0.9686 - val_loss: 0.2735 - val_accuracy: 0.9355\n",
      "Epoch 119/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0657 - accuracy: 0.9694 - val_loss: 0.2724 - val_accuracy: 0.9318\n",
      "Epoch 120/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0673 - accuracy: 0.9706 - val_loss: 0.2442 - val_accuracy: 0.9447\n",
      "Epoch 121/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0704 - accuracy: 0.9683 - val_loss: 0.2436 - val_accuracy: 0.9488\n",
      "Epoch 122/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0665 - accuracy: 0.9708 - val_loss: 0.2287 - val_accuracy: 0.9515\n",
      "Epoch 123/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0652 - accuracy: 0.9713 - val_loss: 0.2167 - val_accuracy: 0.9382\n",
      "Epoch 124/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0639 - accuracy: 0.9705 - val_loss: 0.2351 - val_accuracy: 0.9467\n",
      "Epoch 125/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0645 - accuracy: 0.9717 - val_loss: 0.2509 - val_accuracy: 0.9362\n",
      "Epoch 126/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0644 - accuracy: 0.9712 - val_loss: 0.2895 - val_accuracy: 0.9342\n",
      "Epoch 127/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0618 - accuracy: 0.9720 - val_loss: 0.2809 - val_accuracy: 0.9396\n",
      "Epoch 128/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0578 - accuracy: 0.9780 - val_loss: 0.2926 - val_accuracy: 0.9345\n",
      "Epoch 129/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0673 - accuracy: 0.9714 - val_loss: 0.2274 - val_accuracy: 0.9311\n",
      "Epoch 130/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0591 - accuracy: 0.9729 - val_loss: 0.2408 - val_accuracy: 0.9403\n",
      "Epoch 131/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0617 - accuracy: 0.9721 - val_loss: 0.2150 - val_accuracy: 0.9416\n",
      "Epoch 132/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0706 - accuracy: 0.9678 - val_loss: 0.2061 - val_accuracy: 0.9355\n",
      "Epoch 133/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0569 - accuracy: 0.9731 - val_loss: 0.2050 - val_accuracy: 0.9457\n",
      "Epoch 134/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0611 - accuracy: 0.9740 - val_loss: 0.2177 - val_accuracy: 0.9379\n",
      "Epoch 135/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0696 - accuracy: 0.9698 - val_loss: 0.2141 - val_accuracy: 0.9376\n",
      "Epoch 136/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0638 - accuracy: 0.9718 - val_loss: 0.2463 - val_accuracy: 0.9423\n",
      "Epoch 137/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0669 - accuracy: 0.9705 - val_loss: 0.2253 - val_accuracy: 0.9403\n",
      "Epoch 138/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0651 - accuracy: 0.9720 - val_loss: 0.2182 - val_accuracy: 0.9352\n",
      "Epoch 139/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0643 - accuracy: 0.9728 - val_loss: 0.1756 - val_accuracy: 0.9508\n",
      "Epoch 140/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0754 - accuracy: 0.9675 - val_loss: 0.2057 - val_accuracy: 0.9372\n",
      "Epoch 141/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0605 - accuracy: 0.9742 - val_loss: 0.2279 - val_accuracy: 0.9410\n",
      "Epoch 142/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0668 - accuracy: 0.9713 - val_loss: 0.2420 - val_accuracy: 0.9410\n",
      "Epoch 143/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0607 - accuracy: 0.9729 - val_loss: 0.2418 - val_accuracy: 0.9365\n",
      "Epoch 144/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0611 - accuracy: 0.9731 - val_loss: 0.2266 - val_accuracy: 0.9389\n",
      "Epoch 145/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0591 - accuracy: 0.9743 - val_loss: 0.2342 - val_accuracy: 0.9444\n",
      "Epoch 146/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0588 - accuracy: 0.9744 - val_loss: 0.2057 - val_accuracy: 0.9515\n",
      "Epoch 147/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0562 - accuracy: 0.9742 - val_loss: 0.2336 - val_accuracy: 0.9416\n",
      "Epoch 148/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0551 - accuracy: 0.9771 - val_loss: 0.2374 - val_accuracy: 0.9345\n",
      "Epoch 149/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0744 - accuracy: 0.9682 - val_loss: 0.2353 - val_accuracy: 0.9342\n",
      "Epoch 150/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0580 - accuracy: 0.9724 - val_loss: 0.2060 - val_accuracy: 0.9474\n",
      "Epoch 151/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0559 - accuracy: 0.9767 - val_loss: 0.2132 - val_accuracy: 0.9437\n",
      "Epoch 152/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0635 - accuracy: 0.9737 - val_loss: 0.2030 - val_accuracy: 0.9440\n",
      "Epoch 153/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0568 - accuracy: 0.9746 - val_loss: 0.2114 - val_accuracy: 0.9335\n",
      "Epoch 154/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0503 - accuracy: 0.9786 - val_loss: 0.2366 - val_accuracy: 0.9413\n",
      "Epoch 155/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0540 - accuracy: 0.9770 - val_loss: 0.2166 - val_accuracy: 0.9348\n",
      "Epoch 156/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0556 - accuracy: 0.9771 - val_loss: 0.2448 - val_accuracy: 0.9447\n",
      "Epoch 157/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0613 - accuracy: 0.9732 - val_loss: 0.2321 - val_accuracy: 0.9457\n",
      "Epoch 158/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0531 - accuracy: 0.9751 - val_loss: 0.2447 - val_accuracy: 0.9393\n",
      "Epoch 159/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0518 - accuracy: 0.9771 - val_loss: 0.2403 - val_accuracy: 0.9325\n",
      "Epoch 160/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0606 - accuracy: 0.9724 - val_loss: 0.2519 - val_accuracy: 0.9332\n",
      "Epoch 161/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0568 - accuracy: 0.9754 - val_loss: 0.2242 - val_accuracy: 0.9450\n",
      "Epoch 162/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0546 - accuracy: 0.9782 - val_loss: 0.2381 - val_accuracy: 0.9403\n",
      "Epoch 163/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0514 - accuracy: 0.9780 - val_loss: 0.2176 - val_accuracy: 0.9508\n",
      "Epoch 164/700\n",
      "7352/7352 [==============================] - 2s 336us/sample - loss: 0.0522 - accuracy: 0.9762 - val_loss: 0.2109 - val_accuracy: 0.9484\n",
      "Epoch 165/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.0528 - accuracy: 0.9763 - val_loss: 0.2101 - val_accuracy: 0.9457\n",
      "Epoch 166/700\n",
      "7352/7352 [==============================] - 3s 359us/sample - loss: 0.0722 - accuracy: 0.9676 - val_loss: 0.2281 - val_accuracy: 0.9389\n",
      "Epoch 167/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.0590 - accuracy: 0.9743 - val_loss: 0.2377 - val_accuracy: 0.9410\n",
      "Epoch 168/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0505 - accuracy: 0.9771 - val_loss: 0.2095 - val_accuracy: 0.9474\n",
      "Epoch 169/700\n",
      "7352/7352 [==============================] - 2s 337us/sample - loss: 0.0532 - accuracy: 0.9771 - val_loss: 0.2561 - val_accuracy: 0.9427\n",
      "Epoch 170/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0456 - accuracy: 0.9782 - val_loss: 0.2841 - val_accuracy: 0.9396\n",
      "Epoch 171/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0508 - accuracy: 0.9771 - val_loss: 0.2641 - val_accuracy: 0.9348\n",
      "Epoch 172/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0561 - accuracy: 0.9742 - val_loss: 0.2304 - val_accuracy: 0.9457\n",
      "Epoch 173/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0519 - accuracy: 0.9778 - val_loss: 0.2865 - val_accuracy: 0.9352\n",
      "Epoch 174/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0578 - accuracy: 0.9757 - val_loss: 0.3175 - val_accuracy: 0.9332\n",
      "Epoch 175/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0551 - accuracy: 0.9765 - val_loss: 0.3148 - val_accuracy: 0.9348\n",
      "Epoch 176/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0548 - accuracy: 0.9769 - val_loss: 0.2803 - val_accuracy: 0.9420\n",
      "Epoch 177/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0513 - accuracy: 0.9786 - val_loss: 0.2734 - val_accuracy: 0.9423\n",
      "Epoch 178/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0505 - accuracy: 0.9766 - val_loss: 0.2563 - val_accuracy: 0.9481\n",
      "Epoch 179/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0504 - accuracy: 0.9786 - val_loss: 0.2416 - val_accuracy: 0.9457\n",
      "Epoch 180/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0522 - accuracy: 0.9801 - val_loss: 0.2276 - val_accuracy: 0.9518\n",
      "Epoch 181/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0469 - accuracy: 0.9791 - val_loss: 0.2365 - val_accuracy: 0.9433\n",
      "Epoch 182/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0443 - accuracy: 0.9826 - val_loss: 0.2301 - val_accuracy: 0.9511\n",
      "Epoch 183/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0532 - accuracy: 0.9765 - val_loss: 0.2553 - val_accuracy: 0.9481\n",
      "Epoch 184/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0467 - accuracy: 0.9808 - val_loss: 0.2342 - val_accuracy: 0.9488\n",
      "Epoch 185/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0459 - accuracy: 0.9795 - val_loss: 0.2446 - val_accuracy: 0.9477\n",
      "Epoch 186/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0484 - accuracy: 0.9805 - val_loss: 0.2499 - val_accuracy: 0.9464\n",
      "Epoch 187/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0501 - accuracy: 0.9800 - val_loss: 0.2706 - val_accuracy: 0.9433\n",
      "Epoch 188/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0442 - accuracy: 0.9814 - val_loss: 0.2305 - val_accuracy: 0.9488\n",
      "Epoch 189/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.0456 - accuracy: 0.9818 - val_loss: 0.2395 - val_accuracy: 0.9444\n",
      "Epoch 190/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0476 - accuracy: 0.9796 - val_loss: 0.2268 - val_accuracy: 0.9403\n",
      "Epoch 191/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0507 - accuracy: 0.9782 - val_loss: 0.1810 - val_accuracy: 0.9572\n",
      "Epoch 192/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0532 - accuracy: 0.9762 - val_loss: 0.1894 - val_accuracy: 0.9549\n",
      "Epoch 193/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0436 - accuracy: 0.9804 - val_loss: 0.2291 - val_accuracy: 0.9511\n",
      "Epoch 194/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0477 - accuracy: 0.9796 - val_loss: 0.2091 - val_accuracy: 0.9539\n",
      "Epoch 195/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0429 - accuracy: 0.9829 - val_loss: 0.1844 - val_accuracy: 0.9545\n",
      "Epoch 196/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0446 - accuracy: 0.9812 - val_loss: 0.2289 - val_accuracy: 0.9460\n",
      "Epoch 197/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0475 - accuracy: 0.9822 - val_loss: 0.2033 - val_accuracy: 0.9484\n",
      "Epoch 198/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0468 - accuracy: 0.9796 - val_loss: 0.1804 - val_accuracy: 0.9542\n",
      "Epoch 199/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0459 - accuracy: 0.9818 - val_loss: 0.1997 - val_accuracy: 0.9501\n",
      "Epoch 200/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0426 - accuracy: 0.9830 - val_loss: 0.2151 - val_accuracy: 0.9321\n",
      "Epoch 201/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0547 - accuracy: 0.9782 - val_loss: 0.2013 - val_accuracy: 0.9464\n",
      "Epoch 202/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0544 - accuracy: 0.9793 - val_loss: 0.2263 - val_accuracy: 0.9440\n",
      "Epoch 203/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0505 - accuracy: 0.9784 - val_loss: 0.1920 - val_accuracy: 0.9444\n",
      "Epoch 204/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0525 - accuracy: 0.9788 - val_loss: 0.1897 - val_accuracy: 0.9515\n",
      "Epoch 205/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0416 - accuracy: 0.9830 - val_loss: 0.2047 - val_accuracy: 0.9474\n",
      "Epoch 206/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0475 - accuracy: 0.9797 - val_loss: 0.1986 - val_accuracy: 0.9396\n",
      "Epoch 207/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0457 - accuracy: 0.9811 - val_loss: 0.2040 - val_accuracy: 0.9481\n",
      "Epoch 208/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0448 - accuracy: 0.9818 - val_loss: 0.1970 - val_accuracy: 0.9460\n",
      "Epoch 209/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0442 - accuracy: 0.9812 - val_loss: 0.1789 - val_accuracy: 0.9494\n",
      "Epoch 210/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0409 - accuracy: 0.9849 - val_loss: 0.2024 - val_accuracy: 0.9447\n",
      "Epoch 211/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0398 - accuracy: 0.9833 - val_loss: 0.1828 - val_accuracy: 0.9525\n",
      "Epoch 212/700\n",
      "7352/7352 [==============================] - 3s 341us/sample - loss: 0.0400 - accuracy: 0.9839 - val_loss: 0.1817 - val_accuracy: 0.9515\n",
      "Epoch 213/700\n",
      "7352/7352 [==============================] - 3s 344us/sample - loss: 0.0401 - accuracy: 0.9846 - val_loss: 0.1895 - val_accuracy: 0.9532\n",
      "Epoch 214/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0411 - accuracy: 0.9816 - val_loss: 0.2207 - val_accuracy: 0.9332\n",
      "Epoch 215/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0511 - accuracy: 0.9771 - val_loss: 0.2092 - val_accuracy: 0.9491\n",
      "Epoch 216/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0428 - accuracy: 0.9831 - val_loss: 0.2093 - val_accuracy: 0.9386\n",
      "Epoch 217/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0415 - accuracy: 0.9822 - val_loss: 0.1720 - val_accuracy: 0.9508\n",
      "Epoch 218/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0416 - accuracy: 0.9830 - val_loss: 0.1466 - val_accuracy: 0.9610\n",
      "Epoch 219/700\n",
      "7352/7352 [==============================] - 3s 361us/sample - loss: 0.0467 - accuracy: 0.9810 - val_loss: 0.1797 - val_accuracy: 0.9535\n",
      "Epoch 220/700\n",
      "7352/7352 [==============================] - 4s 527us/sample - loss: 0.0430 - accuracy: 0.9816 - val_loss: 0.1690 - val_accuracy: 0.9572\n",
      "Epoch 221/700\n",
      "7352/7352 [==============================] - 3s 345us/sample - loss: 0.0488 - accuracy: 0.9799 - val_loss: 0.2716 - val_accuracy: 0.9399\n",
      "Epoch 222/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0432 - accuracy: 0.9830 - val_loss: 0.1942 - val_accuracy: 0.9552\n",
      "Epoch 223/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.0400 - accuracy: 0.9833 - val_loss: 0.2310 - val_accuracy: 0.9515\n",
      "Epoch 224/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0457 - accuracy: 0.9805 - val_loss: 0.1961 - val_accuracy: 0.9528\n",
      "Epoch 225/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0407 - accuracy: 0.9848 - val_loss: 0.1916 - val_accuracy: 0.9539\n",
      "Epoch 226/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0411 - accuracy: 0.9856 - val_loss: 0.2089 - val_accuracy: 0.9525\n",
      "Epoch 227/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0492 - accuracy: 0.9795 - val_loss: 0.2187 - val_accuracy: 0.9511\n",
      "Epoch 228/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0421 - accuracy: 0.9818 - val_loss: 0.2034 - val_accuracy: 0.9511\n",
      "Epoch 229/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0395 - accuracy: 0.9842 - val_loss: 0.2273 - val_accuracy: 0.9464\n",
      "Epoch 230/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0432 - accuracy: 0.9807 - val_loss: 0.1999 - val_accuracy: 0.9555\n",
      "Epoch 231/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0415 - accuracy: 0.9830 - val_loss: 0.2051 - val_accuracy: 0.9525\n",
      "Epoch 232/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0353 - accuracy: 0.9857 - val_loss: 0.2557 - val_accuracy: 0.9467\n",
      "Epoch 233/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0361 - accuracy: 0.9853 - val_loss: 0.1856 - val_accuracy: 0.9569\n",
      "Epoch 234/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0444 - accuracy: 0.9819 - val_loss: 0.1859 - val_accuracy: 0.9545\n",
      "Epoch 235/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0456 - accuracy: 0.9816 - val_loss: 0.1665 - val_accuracy: 0.9505\n",
      "Epoch 236/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0382 - accuracy: 0.9845 - val_loss: 0.1508 - val_accuracy: 0.9532\n",
      "Epoch 237/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0492 - accuracy: 0.9801 - val_loss: 0.1713 - val_accuracy: 0.9522\n",
      "Epoch 238/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0399 - accuracy: 0.9842 - val_loss: 0.1635 - val_accuracy: 0.9505\n",
      "Epoch 239/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0439 - accuracy: 0.9818 - val_loss: 0.1863 - val_accuracy: 0.9457\n",
      "Epoch 240/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0387 - accuracy: 0.9839 - val_loss: 0.2163 - val_accuracy: 0.9410\n",
      "Epoch 241/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0377 - accuracy: 0.9842 - val_loss: 0.1816 - val_accuracy: 0.9488\n",
      "Epoch 242/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0358 - accuracy: 0.9854 - val_loss: 0.2155 - val_accuracy: 0.9481\n",
      "Epoch 243/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0510 - accuracy: 0.9788 - val_loss: 0.1974 - val_accuracy: 0.9518\n",
      "Epoch 244/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0413 - accuracy: 0.9830 - val_loss: 0.1835 - val_accuracy: 0.9579\n",
      "Epoch 245/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0372 - accuracy: 0.9857 - val_loss: 0.2231 - val_accuracy: 0.9535\n",
      "Epoch 246/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0359 - accuracy: 0.9856 - val_loss: 0.2220 - val_accuracy: 0.9498\n",
      "Epoch 247/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0461 - accuracy: 0.9829 - val_loss: 0.1964 - val_accuracy: 0.9549\n",
      "Epoch 248/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0362 - accuracy: 0.9849 - val_loss: 0.1908 - val_accuracy: 0.9579\n",
      "Epoch 249/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0390 - accuracy: 0.9834 - val_loss: 0.1867 - val_accuracy: 0.9586\n",
      "Epoch 250/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0356 - accuracy: 0.9846 - val_loss: 0.2234 - val_accuracy: 0.9511\n",
      "Epoch 251/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0460 - accuracy: 0.9829 - val_loss: 0.2422 - val_accuracy: 0.9471\n",
      "Epoch 252/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0423 - accuracy: 0.9825 - val_loss: 0.2898 - val_accuracy: 0.9393\n",
      "Epoch 253/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0380 - accuracy: 0.9844 - val_loss: 0.2574 - val_accuracy: 0.9508\n",
      "Epoch 254/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0343 - accuracy: 0.9856 - val_loss: 0.2589 - val_accuracy: 0.9532\n",
      "Epoch 255/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0333 - accuracy: 0.9876 - val_loss: 0.2459 - val_accuracy: 0.9501\n",
      "Epoch 256/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0339 - accuracy: 0.9869 - val_loss: 0.2567 - val_accuracy: 0.9542\n",
      "Epoch 257/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0330 - accuracy: 0.9878 - val_loss: 0.2288 - val_accuracy: 0.9572\n",
      "Epoch 258/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0352 - accuracy: 0.9867 - val_loss: 0.2525 - val_accuracy: 0.9488\n",
      "Epoch 259/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0381 - accuracy: 0.9845 - val_loss: 0.2369 - val_accuracy: 0.9528\n",
      "Epoch 260/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0346 - accuracy: 0.9868 - val_loss: 0.2546 - val_accuracy: 0.9484\n",
      "Epoch 261/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0310 - accuracy: 0.9876 - val_loss: 0.2390 - val_accuracy: 0.9559\n",
      "Epoch 262/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0353 - accuracy: 0.9848 - val_loss: 0.2482 - val_accuracy: 0.9545\n",
      "Epoch 263/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0308 - accuracy: 0.9876 - val_loss: 0.2031 - val_accuracy: 0.9583\n",
      "Epoch 264/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0408 - accuracy: 0.9838 - val_loss: 0.2081 - val_accuracy: 0.9522\n",
      "Epoch 265/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0396 - accuracy: 0.9835 - val_loss: 0.1644 - val_accuracy: 0.9566\n",
      "Epoch 266/700\n",
      "7352/7352 [==============================] - 3s 343us/sample - loss: 0.0339 - accuracy: 0.9860 - val_loss: 0.1911 - val_accuracy: 0.9555\n",
      "Epoch 267/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0366 - accuracy: 0.9859 - val_loss: 0.1965 - val_accuracy: 0.9559\n",
      "Epoch 268/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0333 - accuracy: 0.9871 - val_loss: 0.2223 - val_accuracy: 0.9549\n",
      "Epoch 269/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0366 - accuracy: 0.9863 - val_loss: 0.2257 - val_accuracy: 0.9542\n",
      "Epoch 270/700\n",
      "7352/7352 [==============================] - 2s 336us/sample - loss: 0.0375 - accuracy: 0.9852 - val_loss: 0.2012 - val_accuracy: 0.9552\n",
      "Epoch 271/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0305 - accuracy: 0.9879 - val_loss: 0.2030 - val_accuracy: 0.9535\n",
      "Epoch 272/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0318 - accuracy: 0.9878 - val_loss: 0.1930 - val_accuracy: 0.9511\n",
      "Epoch 273/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0274 - accuracy: 0.9891 - val_loss: 0.1751 - val_accuracy: 0.9613\n",
      "Epoch 274/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0284 - accuracy: 0.9886 - val_loss: 0.1682 - val_accuracy: 0.9627\n",
      "Epoch 275/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0271 - accuracy: 0.9895 - val_loss: 0.1941 - val_accuracy: 0.9552\n",
      "Epoch 276/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0304 - accuracy: 0.9888 - val_loss: 0.1827 - val_accuracy: 0.9650\n",
      "Epoch 277/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0325 - accuracy: 0.9868 - val_loss: 0.1798 - val_accuracy: 0.9606\n",
      "Epoch 278/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0326 - accuracy: 0.9863 - val_loss: 0.1946 - val_accuracy: 0.9566\n",
      "Epoch 279/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0299 - accuracy: 0.9884 - val_loss: 0.1687 - val_accuracy: 0.9603\n",
      "Epoch 280/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0342 - accuracy: 0.9874 - val_loss: 0.2027 - val_accuracy: 0.9501\n",
      "Epoch 281/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0305 - accuracy: 0.9876 - val_loss: 0.1686 - val_accuracy: 0.9539\n",
      "Epoch 282/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.1566 - val_accuracy: 0.9522\n",
      "Epoch 283/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0388 - accuracy: 0.9850 - val_loss: 0.1524 - val_accuracy: 0.9586\n",
      "Epoch 284/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0379 - accuracy: 0.9844 - val_loss: 0.1386 - val_accuracy: 0.9617\n",
      "Epoch 285/700\n",
      "7352/7352 [==============================] - 2s 338us/sample - loss: 0.0299 - accuracy: 0.9886 - val_loss: 0.1578 - val_accuracy: 0.9579\n",
      "Epoch 286/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0326 - accuracy: 0.9871 - val_loss: 0.1971 - val_accuracy: 0.9596\n",
      "Epoch 287/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0284 - accuracy: 0.9879 - val_loss: 0.1830 - val_accuracy: 0.9606\n",
      "Epoch 288/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0285 - accuracy: 0.9882 - val_loss: 0.1611 - val_accuracy: 0.9620\n",
      "Epoch 289/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.1590 - val_accuracy: 0.9617\n",
      "Epoch 290/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0306 - accuracy: 0.9875 - val_loss: 0.2348 - val_accuracy: 0.9515\n",
      "Epoch 291/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0304 - accuracy: 0.9886 - val_loss: 0.1747 - val_accuracy: 0.9583\n",
      "Epoch 292/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0295 - accuracy: 0.9869 - val_loss: 0.1829 - val_accuracy: 0.9572\n",
      "Epoch 293/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0279 - accuracy: 0.9893 - val_loss: 0.1977 - val_accuracy: 0.9555\n",
      "Epoch 294/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0278 - accuracy: 0.9893 - val_loss: 0.1926 - val_accuracy: 0.9569\n",
      "Epoch 295/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0262 - accuracy: 0.9890 - val_loss: 0.1939 - val_accuracy: 0.9603\n",
      "Epoch 296/700\n",
      "7352/7352 [==============================] - 2s 336us/sample - loss: 0.0254 - accuracy: 0.9905 - val_loss: 0.1896 - val_accuracy: 0.9593\n",
      "Epoch 297/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0248 - accuracy: 0.9908 - val_loss: 0.1829 - val_accuracy: 0.9623\n",
      "Epoch 298/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0262 - accuracy: 0.9888 - val_loss: 0.1899 - val_accuracy: 0.9552\n",
      "Epoch 299/700\n",
      "7352/7352 [==============================] - 3s 344us/sample - loss: 0.0254 - accuracy: 0.9893 - val_loss: 0.1827 - val_accuracy: 0.9549\n",
      "Epoch 300/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0255 - accuracy: 0.9898 - val_loss: 0.2076 - val_accuracy: 0.9491\n",
      "Epoch 301/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0304 - accuracy: 0.9879 - val_loss: 0.1908 - val_accuracy: 0.9552\n",
      "Epoch 302/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0278 - accuracy: 0.9893 - val_loss: 0.1653 - val_accuracy: 0.9620\n",
      "Epoch 303/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0448 - accuracy: 0.9820 - val_loss: 0.1736 - val_accuracy: 0.9555\n",
      "Epoch 304/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.1525 - val_accuracy: 0.9603\n",
      "Epoch 305/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0253 - accuracy: 0.9909 - val_loss: 0.1445 - val_accuracy: 0.9596\n",
      "Epoch 306/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0257 - accuracy: 0.9909 - val_loss: 0.1489 - val_accuracy: 0.9630\n",
      "Epoch 307/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0261 - accuracy: 0.9903 - val_loss: 0.1530 - val_accuracy: 0.9606\n",
      "Epoch 308/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0244 - accuracy: 0.9902 - val_loss: 0.1395 - val_accuracy: 0.9650\n",
      "Epoch 309/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0206 - accuracy: 0.9928 - val_loss: 0.1519 - val_accuracy: 0.9569\n",
      "Epoch 310/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0265 - accuracy: 0.9901 - val_loss: 0.1763 - val_accuracy: 0.9562\n",
      "Epoch 311/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.1405 - val_accuracy: 0.9647\n",
      "Epoch 312/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0263 - accuracy: 0.9893 - val_loss: 0.1315 - val_accuracy: 0.9678\n",
      "Epoch 313/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0353 - accuracy: 0.9852 - val_loss: 0.1423 - val_accuracy: 0.9634\n",
      "Epoch 314/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0300 - accuracy: 0.9893 - val_loss: 0.2026 - val_accuracy: 0.9494\n",
      "Epoch 315/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0224 - accuracy: 0.9913 - val_loss: 0.2033 - val_accuracy: 0.9498\n",
      "Epoch 316/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0208 - accuracy: 0.9918 - val_loss: 0.1826 - val_accuracy: 0.9596\n",
      "Epoch 317/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0296 - accuracy: 0.9887 - val_loss: 0.1908 - val_accuracy: 0.9555\n",
      "Epoch 318/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.2040 - val_accuracy: 0.9498\n",
      "Epoch 319/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0245 - accuracy: 0.9897 - val_loss: 0.1985 - val_accuracy: 0.9552\n",
      "Epoch 320/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.1626 - val_accuracy: 0.9593\n",
      "Epoch 321/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.1566 - val_accuracy: 0.9586\n",
      "Epoch 322/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0242 - accuracy: 0.9909 - val_loss: 0.1596 - val_accuracy: 0.9545\n",
      "Epoch 323/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.1858 - val_accuracy: 0.9545\n",
      "Epoch 324/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0218 - accuracy: 0.9914 - val_loss: 0.1647 - val_accuracy: 0.9593\n",
      "Epoch 325/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0302 - accuracy: 0.9897 - val_loss: 0.1419 - val_accuracy: 0.9545\n",
      "Epoch 326/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.1460 - val_accuracy: 0.9555\n",
      "Epoch 327/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0277 - accuracy: 0.9895 - val_loss: 0.1470 - val_accuracy: 0.9657\n",
      "Epoch 328/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.1543 - val_accuracy: 0.9620\n",
      "Epoch 329/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0183 - accuracy: 0.9929 - val_loss: 0.1813 - val_accuracy: 0.9535\n",
      "Epoch 330/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0262 - accuracy: 0.9895 - val_loss: 0.1571 - val_accuracy: 0.9562\n",
      "Epoch 331/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0232 - accuracy: 0.9906 - val_loss: 0.1576 - val_accuracy: 0.9600\n",
      "Epoch 332/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0212 - accuracy: 0.9925 - val_loss: 0.1517 - val_accuracy: 0.9576\n",
      "Epoch 333/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.1622 - val_accuracy: 0.9576\n",
      "Epoch 334/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0236 - accuracy: 0.9910 - val_loss: 0.1548 - val_accuracy: 0.9603\n",
      "Epoch 335/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.2028 - val_accuracy: 0.9528\n",
      "Epoch 336/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0227 - accuracy: 0.9916 - val_loss: 0.2057 - val_accuracy: 0.9562\n",
      "Epoch 337/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.1796 - val_accuracy: 0.9610\n",
      "Epoch 338/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0179 - accuracy: 0.9931 - val_loss: 0.2215 - val_accuracy: 0.9528\n",
      "Epoch 339/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0218 - accuracy: 0.9914 - val_loss: 0.1675 - val_accuracy: 0.9640\n",
      "Epoch 340/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.1872 - val_accuracy: 0.9596\n",
      "Epoch 341/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0210 - accuracy: 0.9914 - val_loss: 0.1702 - val_accuracy: 0.9630\n",
      "Epoch 342/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0234 - accuracy: 0.9912 - val_loss: 0.1731 - val_accuracy: 0.9620\n",
      "Epoch 343/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0235 - accuracy: 0.9902 - val_loss: 0.1588 - val_accuracy: 0.9640\n",
      "Epoch 344/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0269 - accuracy: 0.9906 - val_loss: 0.1463 - val_accuracy: 0.9640\n",
      "Epoch 345/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.1552 - val_accuracy: 0.9617\n",
      "Epoch 346/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0228 - accuracy: 0.9916 - val_loss: 0.1312 - val_accuracy: 0.9705\n",
      "Epoch 347/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0311 - accuracy: 0.9882 - val_loss: 0.1591 - val_accuracy: 0.9576\n",
      "Epoch 348/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0210 - accuracy: 0.9925 - val_loss: 0.1569 - val_accuracy: 0.9583\n",
      "Epoch 349/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0188 - accuracy: 0.9929 - val_loss: 0.1628 - val_accuracy: 0.9542\n",
      "Epoch 350/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.1628 - val_accuracy: 0.9555\n",
      "Epoch 351/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0218 - accuracy: 0.9920 - val_loss: 0.1716 - val_accuracy: 0.9583\n",
      "Epoch 352/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.1852 - val_accuracy: 0.9549\n",
      "Epoch 353/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0215 - accuracy: 0.9924 - val_loss: 0.1596 - val_accuracy: 0.9576\n",
      "Epoch 354/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.1695 - val_accuracy: 0.9596\n",
      "Epoch 355/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0172 - accuracy: 0.9943 - val_loss: 0.1623 - val_accuracy: 0.9589\n",
      "Epoch 356/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.1465 - val_accuracy: 0.9610\n",
      "Epoch 357/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.1523 - val_accuracy: 0.9613\n",
      "Epoch 358/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0223 - accuracy: 0.9906 - val_loss: 0.1170 - val_accuracy: 0.9650\n",
      "Epoch 359/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.1442 - val_accuracy: 0.9603\n",
      "Epoch 360/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0208 - accuracy: 0.9921 - val_loss: 0.1193 - val_accuracy: 0.9630\n",
      "Epoch 361/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0185 - accuracy: 0.9931 - val_loss: 0.1191 - val_accuracy: 0.9627\n",
      "Epoch 362/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0230 - accuracy: 0.9910 - val_loss: 0.1730 - val_accuracy: 0.9613\n",
      "Epoch 363/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0190 - accuracy: 0.9931 - val_loss: 0.1380 - val_accuracy: 0.9712\n",
      "Epoch 364/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0182 - accuracy: 0.9936 - val_loss: 0.1456 - val_accuracy: 0.9650\n",
      "Epoch 365/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0181 - accuracy: 0.9933 - val_loss: 0.1701 - val_accuracy: 0.9610\n",
      "Epoch 366/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0189 - accuracy: 0.9924 - val_loss: 0.1748 - val_accuracy: 0.9606\n",
      "Epoch 367/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0197 - accuracy: 0.9925 - val_loss: 0.1695 - val_accuracy: 0.9613\n",
      "Epoch 368/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.1432 - val_accuracy: 0.9630\n",
      "Epoch 369/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.1869 - val_accuracy: 0.9539\n",
      "Epoch 370/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0185 - accuracy: 0.9925 - val_loss: 0.1768 - val_accuracy: 0.9589\n",
      "Epoch 371/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0208 - accuracy: 0.9925 - val_loss: 0.1837 - val_accuracy: 0.9542\n",
      "Epoch 372/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.1972 - val_accuracy: 0.9532\n",
      "Epoch 373/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0165 - accuracy: 0.9925 - val_loss: 0.2002 - val_accuracy: 0.9525\n",
      "Epoch 374/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0365 - accuracy: 0.9837 - val_loss: 0.1692 - val_accuracy: 0.9589\n",
      "Epoch 375/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0197 - accuracy: 0.9931 - val_loss: 0.1667 - val_accuracy: 0.9600\n",
      "Epoch 376/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0183 - accuracy: 0.9928 - val_loss: 0.1641 - val_accuracy: 0.9634\n",
      "Epoch 377/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.1812 - val_accuracy: 0.9613\n",
      "Epoch 378/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0196 - accuracy: 0.9927 - val_loss: 0.1998 - val_accuracy: 0.9613\n",
      "Epoch 379/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.1984 - val_accuracy: 0.9634\n",
      "Epoch 380/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0180 - accuracy: 0.9939 - val_loss: 0.1870 - val_accuracy: 0.9620\n",
      "Epoch 381/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0162 - accuracy: 0.9939 - val_loss: 0.1621 - val_accuracy: 0.9698\n",
      "Epoch 382/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.1690 - val_accuracy: 0.9606\n",
      "Epoch 383/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.1558 - val_accuracy: 0.9647\n",
      "Epoch 384/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0202 - accuracy: 0.9922 - val_loss: 0.1738 - val_accuracy: 0.9555\n",
      "Epoch 385/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.1384 - val_accuracy: 0.9620\n",
      "Epoch 386/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0176 - accuracy: 0.9942 - val_loss: 0.1396 - val_accuracy: 0.9586\n",
      "Epoch 387/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.1226 - val_accuracy: 0.9674\n",
      "Epoch 388/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.1231 - val_accuracy: 0.9681\n",
      "Epoch 389/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0237 - accuracy: 0.9913 - val_loss: 0.1503 - val_accuracy: 0.9684\n",
      "Epoch 390/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.1345 - val_accuracy: 0.9617\n",
      "Epoch 391/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.1625 - val_accuracy: 0.9610\n",
      "Epoch 392/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.1370 - val_accuracy: 0.9634\n",
      "Epoch 393/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0199 - accuracy: 0.9927 - val_loss: 0.1654 - val_accuracy: 0.9555\n",
      "Epoch 394/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0219 - accuracy: 0.9912 - val_loss: 0.1774 - val_accuracy: 0.9576\n",
      "Epoch 395/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0180 - accuracy: 0.9929 - val_loss: 0.1490 - val_accuracy: 0.9586\n",
      "Epoch 396/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0201 - accuracy: 0.9925 - val_loss: 0.1480 - val_accuracy: 0.9579\n",
      "Epoch 397/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0262 - accuracy: 0.9897 - val_loss: 0.1477 - val_accuracy: 0.9583\n",
      "Epoch 398/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0191 - accuracy: 0.9927 - val_loss: 0.1282 - val_accuracy: 0.9674\n",
      "Epoch 399/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.1128 - val_accuracy: 0.9678\n",
      "Epoch 400/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.1463 - val_accuracy: 0.9640\n",
      "Epoch 401/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0218 - accuracy: 0.9914 - val_loss: 0.1535 - val_accuracy: 0.9650\n",
      "Epoch 402/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0158 - accuracy: 0.9943 - val_loss: 0.1348 - val_accuracy: 0.9681\n",
      "Epoch 403/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.1431 - val_accuracy: 0.9650\n",
      "Epoch 404/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.1587 - val_accuracy: 0.9650\n",
      "Epoch 405/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0163 - accuracy: 0.9940 - val_loss: 0.1592 - val_accuracy: 0.9644\n",
      "Epoch 406/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0202 - accuracy: 0.9925 - val_loss: 0.1411 - val_accuracy: 0.9708\n",
      "Epoch 407/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.1473 - val_accuracy: 0.9695\n",
      "Epoch 408/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.1637 - val_accuracy: 0.9637\n",
      "Epoch 409/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.1659 - val_accuracy: 0.9671\n",
      "Epoch 410/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0183 - accuracy: 0.9933 - val_loss: 0.1569 - val_accuracy: 0.9627\n",
      "Epoch 411/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.1465 - val_accuracy: 0.9664\n",
      "Epoch 412/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.1516 - val_accuracy: 0.9667\n",
      "Epoch 413/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0145 - accuracy: 0.9944 - val_loss: 0.1405 - val_accuracy: 0.9701\n",
      "Epoch 414/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.1702 - val_accuracy: 0.9600\n",
      "Epoch 415/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.1752 - val_accuracy: 0.9610\n",
      "Epoch 416/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0138 - accuracy: 0.9954 - val_loss: 0.1811 - val_accuracy: 0.9634\n",
      "Epoch 417/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.1685 - val_accuracy: 0.9613\n",
      "Epoch 418/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0129 - accuracy: 0.9961 - val_loss: 0.1721 - val_accuracy: 0.9634\n",
      "Epoch 419/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.1621 - val_accuracy: 0.9661\n",
      "Epoch 420/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0156 - accuracy: 0.9940 - val_loss: 0.1709 - val_accuracy: 0.9634\n",
      "Epoch 421/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0173 - accuracy: 0.9946 - val_loss: 0.1707 - val_accuracy: 0.9657\n",
      "Epoch 422/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0180 - accuracy: 0.9927 - val_loss: 0.1761 - val_accuracy: 0.9600\n",
      "Epoch 423/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0145 - accuracy: 0.9940 - val_loss: 0.1559 - val_accuracy: 0.9695\n",
      "Epoch 424/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0154 - accuracy: 0.9947 - val_loss: 0.2045 - val_accuracy: 0.9600\n",
      "Epoch 425/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0140 - accuracy: 0.9947 - val_loss: 0.1874 - val_accuracy: 0.9634\n",
      "Epoch 426/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.1662 - val_accuracy: 0.9681\n",
      "Epoch 427/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.1898 - val_accuracy: 0.9661\n",
      "Epoch 428/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.1366 - val_accuracy: 0.9742\n",
      "Epoch 429/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0150 - accuracy: 0.9940 - val_loss: 0.1657 - val_accuracy: 0.9630\n",
      "Epoch 430/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.1654 - val_accuracy: 0.9681\n",
      "Epoch 431/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.1423 - val_accuracy: 0.9712\n",
      "Epoch 432/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1542 - val_accuracy: 0.9664\n",
      "Epoch 433/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.1596 - val_accuracy: 0.9681\n",
      "Epoch 434/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0188 - accuracy: 0.9927 - val_loss: 0.1635 - val_accuracy: 0.9644\n",
      "Epoch 435/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0155 - accuracy: 0.9952 - val_loss: 0.1480 - val_accuracy: 0.9688\n",
      "Epoch 436/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0185 - accuracy: 0.9922 - val_loss: 0.1831 - val_accuracy: 0.9688\n",
      "Epoch 437/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.1792 - val_accuracy: 0.9667\n",
      "Epoch 438/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.1357 - val_accuracy: 0.9684\n",
      "Epoch 439/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0230 - accuracy: 0.9908 - val_loss: 0.1321 - val_accuracy: 0.9661\n",
      "Epoch 440/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0265 - accuracy: 0.9899 - val_loss: 0.1706 - val_accuracy: 0.9620\n",
      "Epoch 441/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.1558 - val_accuracy: 0.9667\n",
      "Epoch 442/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.1318 - val_accuracy: 0.9691\n",
      "Epoch 443/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.1330 - val_accuracy: 0.9678\n",
      "Epoch 444/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0212 - accuracy: 0.9924 - val_loss: 0.1318 - val_accuracy: 0.9698\n",
      "Epoch 445/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.1267 - val_accuracy: 0.9712\n",
      "Epoch 446/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.1138 - val_accuracy: 0.9705\n",
      "Epoch 447/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.1258 - val_accuracy: 0.9729\n",
      "Epoch 448/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.1403 - val_accuracy: 0.9657\n",
      "Epoch 449/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0123 - accuracy: 0.9958 - val_loss: 0.1219 - val_accuracy: 0.9667\n",
      "Epoch 450/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0208 - accuracy: 0.9918 - val_loss: 0.1338 - val_accuracy: 0.9671\n",
      "Epoch 451/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0215 - accuracy: 0.9920 - val_loss: 0.1315 - val_accuracy: 0.9650\n",
      "Epoch 452/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.1559 - val_accuracy: 0.9671\n",
      "Epoch 453/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0148 - accuracy: 0.9948 - val_loss: 0.1568 - val_accuracy: 0.9654\n",
      "Epoch 454/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.1413 - val_accuracy: 0.9661\n",
      "Epoch 455/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.1489 - val_accuracy: 0.9661\n",
      "Epoch 456/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0158 - accuracy: 0.9935 - val_loss: 0.1491 - val_accuracy: 0.9661\n",
      "Epoch 457/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.1324 - val_accuracy: 0.9688\n",
      "Epoch 458/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0135 - accuracy: 0.9946 - val_loss: 0.1467 - val_accuracy: 0.9664\n",
      "Epoch 459/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.1308 - val_accuracy: 0.9684\n",
      "Epoch 460/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.1439 - val_accuracy: 0.9661\n",
      "Epoch 461/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.1818 - val_accuracy: 0.9606\n",
      "Epoch 462/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.1674 - val_accuracy: 0.9654\n",
      "Epoch 463/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.1299 - val_accuracy: 0.9688\n",
      "Epoch 464/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.1356 - val_accuracy: 0.9684\n",
      "Epoch 465/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.1223 - val_accuracy: 0.9698\n",
      "Epoch 466/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0139 - accuracy: 0.9952 - val_loss: 0.1257 - val_accuracy: 0.9691\n",
      "Epoch 467/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.1296 - val_accuracy: 0.9678\n",
      "Epoch 468/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0126 - accuracy: 0.9952 - val_loss: 0.1584 - val_accuracy: 0.9627\n",
      "Epoch 469/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.1244 - val_accuracy: 0.9691\n",
      "Epoch 470/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.1329 - val_accuracy: 0.9661\n",
      "Epoch 471/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.1574 - val_accuracy: 0.9664\n",
      "Epoch 472/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.1270 - val_accuracy: 0.9684\n",
      "Epoch 473/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.1332 - val_accuracy: 0.9698\n",
      "Epoch 474/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.1260 - val_accuracy: 0.9695\n",
      "Epoch 475/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.1628 - val_accuracy: 0.9623\n",
      "Epoch 476/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0142 - accuracy: 0.9944 - val_loss: 0.1640 - val_accuracy: 0.9661\n",
      "Epoch 477/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0126 - accuracy: 0.9959 - val_loss: 0.1779 - val_accuracy: 0.9552\n",
      "Epoch 478/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.1566 - val_accuracy: 0.9647\n",
      "Epoch 479/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.1554 - val_accuracy: 0.9623\n",
      "Epoch 480/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.1541 - val_accuracy: 0.9593\n",
      "Epoch 481/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0141 - accuracy: 0.9942 - val_loss: 0.1341 - val_accuracy: 0.9667\n",
      "Epoch 482/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.1302 - val_accuracy: 0.9681\n",
      "Epoch 483/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.1568 - val_accuracy: 0.9657\n",
      "Epoch 484/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.1407 - val_accuracy: 0.9671\n",
      "Epoch 485/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.1301 - val_accuracy: 0.9718\n",
      "Epoch 486/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0143 - accuracy: 0.9944 - val_loss: 0.1474 - val_accuracy: 0.9695\n",
      "Epoch 487/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.1945 - val_accuracy: 0.9586\n",
      "Epoch 488/700\n",
      "7352/7352 [==============================] - 3s 366us/sample - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.1798 - val_accuracy: 0.9593\n",
      "Epoch 489/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.1780 - val_accuracy: 0.9623\n",
      "Epoch 490/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0151 - accuracy: 0.9947 - val_loss: 0.1618 - val_accuracy: 0.9657\n",
      "Epoch 491/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0175 - accuracy: 0.9936 - val_loss: 0.1695 - val_accuracy: 0.9667\n",
      "Epoch 492/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0125 - accuracy: 0.9948 - val_loss: 0.1389 - val_accuracy: 0.9715\n",
      "Epoch 493/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.0120 - accuracy: 0.9966 - val_loss: 0.1559 - val_accuracy: 0.9657\n",
      "Epoch 494/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0135 - accuracy: 0.9948 - val_loss: 0.1460 - val_accuracy: 0.9661\n",
      "Epoch 495/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.1564 - val_accuracy: 0.9644\n",
      "Epoch 496/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.1566 - val_accuracy: 0.9678\n",
      "Epoch 497/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.1744 - val_accuracy: 0.9623\n",
      "Epoch 498/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.1563 - val_accuracy: 0.9644\n",
      "Epoch 499/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.1567 - val_accuracy: 0.9664\n",
      "Epoch 500/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.1481 - val_accuracy: 0.9671\n",
      "Epoch 501/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.1919 - val_accuracy: 0.9569\n",
      "Epoch 502/700\n",
      "7352/7352 [==============================] - 2s 336us/sample - loss: 0.0121 - accuracy: 0.9955 - val_loss: 0.1564 - val_accuracy: 0.9678\n",
      "Epoch 503/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.1552 - val_accuracy: 0.9664\n",
      "Epoch 504/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.1481 - val_accuracy: 0.9688\n",
      "Epoch 505/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.1499 - val_accuracy: 0.9674\n",
      "Epoch 506/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0117 - accuracy: 0.9967 - val_loss: 0.1449 - val_accuracy: 0.9715\n",
      "Epoch 507/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.1699 - val_accuracy: 0.9661\n",
      "Epoch 508/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.1401 - val_accuracy: 0.9708\n",
      "Epoch 509/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.1622 - val_accuracy: 0.9684\n",
      "Epoch 510/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.1769 - val_accuracy: 0.9637\n",
      "Epoch 511/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0103 - accuracy: 0.9958 - val_loss: 0.1781 - val_accuracy: 0.9603\n",
      "Epoch 512/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0136 - accuracy: 0.9947 - val_loss: 0.1917 - val_accuracy: 0.9640\n",
      "Epoch 513/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0150 - accuracy: 0.9944 - val_loss: 0.1604 - val_accuracy: 0.9712\n",
      "Epoch 514/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0143 - accuracy: 0.9944 - val_loss: 0.2158 - val_accuracy: 0.9644\n",
      "Epoch 515/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.2139 - val_accuracy: 0.9634\n",
      "Epoch 516/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.2109 - val_accuracy: 0.9630\n",
      "Epoch 517/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.1945 - val_accuracy: 0.9644\n",
      "Epoch 518/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0184 - accuracy: 0.9927 - val_loss: 0.2256 - val_accuracy: 0.9589\n",
      "Epoch 519/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.1993 - val_accuracy: 0.9620\n",
      "Epoch 520/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.1913 - val_accuracy: 0.9630\n",
      "Epoch 521/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0105 - accuracy: 0.9962 - val_loss: 0.2021 - val_accuracy: 0.9613\n",
      "Epoch 522/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.1967 - val_accuracy: 0.9640\n",
      "Epoch 523/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0125 - accuracy: 0.9947 - val_loss: 0.2223 - val_accuracy: 0.9603\n",
      "Epoch 524/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0128 - accuracy: 0.9950 - val_loss: 0.2073 - val_accuracy: 0.9617\n",
      "Epoch 525/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.1912 - val_accuracy: 0.9640\n",
      "Epoch 526/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0184 - accuracy: 0.9929 - val_loss: 0.1940 - val_accuracy: 0.9600\n",
      "Epoch 527/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0175 - accuracy: 0.9925 - val_loss: 0.2065 - val_accuracy: 0.9589\n",
      "Epoch 528/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.1989 - val_accuracy: 0.9606\n",
      "Epoch 529/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0146 - accuracy: 0.9948 - val_loss: 0.1986 - val_accuracy: 0.9627\n",
      "Epoch 530/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.2036 - val_accuracy: 0.9617\n",
      "Epoch 531/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0086 - accuracy: 0.9971 - val_loss: 0.2086 - val_accuracy: 0.9634\n",
      "Epoch 532/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0105 - accuracy: 0.9955 - val_loss: 0.2251 - val_accuracy: 0.9606\n",
      "Epoch 533/700\n",
      "7352/7352 [==============================] - 3s 344us/sample - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.2211 - val_accuracy: 0.9634\n",
      "Epoch 534/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.2148 - val_accuracy: 0.9647\n",
      "Epoch 535/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.2188 - val_accuracy: 0.9644\n",
      "Epoch 536/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.1880 - val_accuracy: 0.9664\n",
      "Epoch 537/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.1884 - val_accuracy: 0.9667\n",
      "Epoch 538/700\n",
      "7352/7352 [==============================] - 2s 337us/sample - loss: 0.0164 - accuracy: 0.9929 - val_loss: 0.2119 - val_accuracy: 0.9549\n",
      "Epoch 539/700\n",
      "7352/7352 [==============================] - 2s 340us/sample - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.1639 - val_accuracy: 0.9664\n",
      "Epoch 540/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1744 - val_accuracy: 0.9661\n",
      "Epoch 541/700\n",
      "7352/7352 [==============================] - 2s 336us/sample - loss: 0.0179 - accuracy: 0.9924 - val_loss: 0.1566 - val_accuracy: 0.9691\n",
      "Epoch 542/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0206 - accuracy: 0.9916 - val_loss: 0.1657 - val_accuracy: 0.9674\n",
      "Epoch 543/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0123 - accuracy: 0.9947 - val_loss: 0.1681 - val_accuracy: 0.9667\n",
      "Epoch 544/700\n",
      "7352/7352 [==============================] - 3s 378us/sample - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.1635 - val_accuracy: 0.9661\n",
      "Epoch 545/700\n",
      "7352/7352 [==============================] - 3s 340us/sample - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.1650 - val_accuracy: 0.9667\n",
      "Epoch 546/700\n",
      "7352/7352 [==============================] - 3s 343us/sample - loss: 0.0209 - accuracy: 0.9922 - val_loss: 0.1489 - val_accuracy: 0.9691\n",
      "Epoch 547/700\n",
      "7352/7352 [==============================] - 3s 342us/sample - loss: 0.0131 - accuracy: 0.9956 - val_loss: 0.1245 - val_accuracy: 0.9698\n",
      "Epoch 548/700\n",
      "7352/7352 [==============================] - 2s 336us/sample - loss: 0.0130 - accuracy: 0.9959 - val_loss: 0.1945 - val_accuracy: 0.9654\n",
      "Epoch 549/700\n",
      "7352/7352 [==============================] - 3s 361us/sample - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.1850 - val_accuracy: 0.9620\n",
      "Epoch 550/700\n",
      "7352/7352 [==============================] - 3s 347us/sample - loss: 0.0122 - accuracy: 0.9954 - val_loss: 0.1898 - val_accuracy: 0.9623\n",
      "Epoch 551/700\n",
      "7352/7352 [==============================] - 2s 340us/sample - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1959 - val_accuracy: 0.9650\n",
      "Epoch 552/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0103 - accuracy: 0.9959 - val_loss: 0.1842 - val_accuracy: 0.9681\n",
      "Epoch 553/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1913 - val_accuracy: 0.9667\n",
      "Epoch 554/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.1821 - val_accuracy: 0.9630\n",
      "Epoch 555/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.2166 - val_accuracy: 0.9525\n",
      "Epoch 556/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.1807 - val_accuracy: 0.9630\n",
      "Epoch 557/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.1797 - val_accuracy: 0.9613\n",
      "Epoch 558/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0122 - accuracy: 0.9952 - val_loss: 0.2312 - val_accuracy: 0.9511\n",
      "Epoch 559/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.2061 - val_accuracy: 0.9620\n",
      "Epoch 560/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.2652 - val_accuracy: 0.9589\n",
      "Epoch 561/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.2432 - val_accuracy: 0.9603\n",
      "Epoch 562/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.2150 - val_accuracy: 0.9678\n",
      "Epoch 563/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0097 - accuracy: 0.9967 - val_loss: 0.1669 - val_accuracy: 0.9712\n",
      "Epoch 564/700\n",
      "7352/7352 [==============================] - 2s 338us/sample - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.1734 - val_accuracy: 0.9644\n",
      "Epoch 565/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.2009 - val_accuracy: 0.9630\n",
      "Epoch 566/700\n",
      "7352/7352 [==============================] - 2s 340us/sample - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.1927 - val_accuracy: 0.9603\n",
      "Epoch 567/700\n",
      "7352/7352 [==============================] - 2s 334us/sample - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.2145 - val_accuracy: 0.9593\n",
      "Epoch 568/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.1910 - val_accuracy: 0.9637\n",
      "Epoch 569/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.1823 - val_accuracy: 0.9640\n",
      "Epoch 570/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.1937 - val_accuracy: 0.9617\n",
      "Epoch 571/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.1631 - val_accuracy: 0.9678\n",
      "Epoch 572/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.1751 - val_accuracy: 0.9664\n",
      "Epoch 573/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0145 - accuracy: 0.9943 - val_loss: 0.1848 - val_accuracy: 0.9657\n",
      "Epoch 574/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0153 - accuracy: 0.9933 - val_loss: 0.1530 - val_accuracy: 0.9674\n",
      "Epoch 575/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.1363 - val_accuracy: 0.9695\n",
      "Epoch 576/700\n",
      "7352/7352 [==============================] - 2s 337us/sample - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.1238 - val_accuracy: 0.9684\n",
      "Epoch 577/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.1214 - val_accuracy: 0.9722\n",
      "Epoch 578/700\n",
      "7352/7352 [==============================] - 3s 346us/sample - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.1492 - val_accuracy: 0.9640\n",
      "Epoch 579/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.1533 - val_accuracy: 0.9667\n",
      "Epoch 580/700\n",
      "7352/7352 [==============================] - 3s 365us/sample - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.1441 - val_accuracy: 0.9681\n",
      "Epoch 581/700\n",
      "7352/7352 [==============================] - 3s 396us/sample - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.1491 - val_accuracy: 0.9684\n",
      "Epoch 582/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0113 - accuracy: 0.9956 - val_loss: 0.1552 - val_accuracy: 0.9634\n",
      "Epoch 583/700\n",
      "7352/7352 [==============================] - 3s 374us/sample - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.1778 - val_accuracy: 0.9610\n",
      "Epoch 584/700\n",
      "7352/7352 [==============================] - 3s 376us/sample - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.1935 - val_accuracy: 0.9562\n",
      "Epoch 585/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0154 - accuracy: 0.9943 - val_loss: 0.1613 - val_accuracy: 0.9637\n",
      "Epoch 586/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.1288 - val_accuracy: 0.9671\n",
      "Epoch 587/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.1299 - val_accuracy: 0.9701\n",
      "Epoch 588/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.1284 - val_accuracy: 0.9695\n",
      "Epoch 589/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1330 - val_accuracy: 0.9691\n",
      "Epoch 590/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.1460 - val_accuracy: 0.9667\n",
      "Epoch 591/700\n",
      "7352/7352 [==============================] - 2s 314us/sample - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.1412 - val_accuracy: 0.9695\n",
      "Epoch 592/700\n",
      "7352/7352 [==============================] - 2s 315us/sample - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.1403 - val_accuracy: 0.9708\n",
      "Epoch 593/700\n",
      "7352/7352 [==============================] - 2s 316us/sample - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.1399 - val_accuracy: 0.9688\n",
      "Epoch 594/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.1461 - val_accuracy: 0.9674\n",
      "Epoch 595/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1397 - val_accuracy: 0.9681\n",
      "Epoch 596/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.1359 - val_accuracy: 0.9674\n",
      "Epoch 597/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.1487 - val_accuracy: 0.9681\n",
      "Epoch 598/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0088 - accuracy: 0.9965 - val_loss: 0.1387 - val_accuracy: 0.9684\n",
      "Epoch 599/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.1316 - val_accuracy: 0.9688\n",
      "Epoch 600/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.1940 - val_accuracy: 0.9691\n",
      "Epoch 601/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.1961 - val_accuracy: 0.9681\n",
      "Epoch 602/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.2086 - val_accuracy: 0.9644\n",
      "Epoch 603/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.2304 - val_accuracy: 0.9610\n",
      "Epoch 604/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0161 - accuracy: 0.9936 - val_loss: 0.2057 - val_accuracy: 0.9593\n",
      "Epoch 605/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.2237 - val_accuracy: 0.9579\n",
      "Epoch 606/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.2210 - val_accuracy: 0.9596\n",
      "Epoch 607/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.2227 - val_accuracy: 0.9603\n",
      "Epoch 608/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.2134 - val_accuracy: 0.9600\n",
      "Epoch 609/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.2233 - val_accuracy: 0.9623\n",
      "Epoch 610/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.2166 - val_accuracy: 0.9610\n",
      "Epoch 611/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.2376 - val_accuracy: 0.9576\n",
      "Epoch 612/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0121 - accuracy: 0.9954 - val_loss: 0.2226 - val_accuracy: 0.9613\n",
      "Epoch 613/700\n",
      "7352/7352 [==============================] - 3s 361us/sample - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.2243 - val_accuracy: 0.9600\n",
      "Epoch 614/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.2178 - val_accuracy: 0.9620\n",
      "Epoch 615/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0093 - accuracy: 0.9962 - val_loss: 0.2242 - val_accuracy: 0.9596\n",
      "Epoch 616/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.2093 - val_accuracy: 0.9613\n",
      "Epoch 617/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0076 - accuracy: 0.9970 - val_loss: 0.1946 - val_accuracy: 0.9637\n",
      "Epoch 618/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.2095 - val_accuracy: 0.9610\n",
      "Epoch 619/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.2134 - val_accuracy: 0.9610\n",
      "Epoch 620/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.2333 - val_accuracy: 0.9586\n",
      "Epoch 621/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0088 - accuracy: 0.9965 - val_loss: 0.2370 - val_accuracy: 0.9586\n",
      "Epoch 622/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.2086 - val_accuracy: 0.9634\n",
      "Epoch 623/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.2063 - val_accuracy: 0.9610\n",
      "Epoch 624/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.1983 - val_accuracy: 0.9627\n",
      "Epoch 625/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.2011 - val_accuracy: 0.9617\n",
      "Epoch 626/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0130 - accuracy: 0.9950 - val_loss: 0.1917 - val_accuracy: 0.9600\n",
      "Epoch 627/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.1797 - val_accuracy: 0.9620\n",
      "Epoch 628/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.1735 - val_accuracy: 0.9664\n",
      "Epoch 629/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.1816 - val_accuracy: 0.9634\n",
      "Epoch 630/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.1938 - val_accuracy: 0.9634\n",
      "Epoch 631/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0078 - accuracy: 0.9967 - val_loss: 0.1688 - val_accuracy: 0.9664\n",
      "Epoch 632/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1638 - val_accuracy: 0.9664\n",
      "Epoch 633/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.1673 - val_accuracy: 0.9664\n",
      "Epoch 634/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.1498 - val_accuracy: 0.9650\n",
      "Epoch 635/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.1384 - val_accuracy: 0.9674\n",
      "Epoch 636/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0095 - accuracy: 0.9958 - val_loss: 0.1457 - val_accuracy: 0.9664\n",
      "Epoch 637/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.1454 - val_accuracy: 0.9664\n",
      "Epoch 638/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.1479 - val_accuracy: 0.9644\n",
      "Epoch 639/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.1426 - val_accuracy: 0.9654\n",
      "Epoch 640/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0075 - accuracy: 0.9970 - val_loss: 0.1491 - val_accuracy: 0.9634\n",
      "Epoch 641/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.1584 - val_accuracy: 0.9617\n",
      "Epoch 642/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.1473 - val_accuracy: 0.9664\n",
      "Epoch 643/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1384 - val_accuracy: 0.9661\n",
      "Epoch 644/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0082 - accuracy: 0.9962 - val_loss: 0.1465 - val_accuracy: 0.9654\n",
      "Epoch 645/700\n",
      "7352/7352 [==============================] - 2s 338us/sample - loss: 0.0084 - accuracy: 0.9962 - val_loss: 0.1488 - val_accuracy: 0.9661\n",
      "Epoch 646/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.1300 - val_accuracy: 0.9691\n",
      "Epoch 647/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.1364 - val_accuracy: 0.9667\n",
      "Epoch 648/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.1596 - val_accuracy: 0.9640\n",
      "Epoch 649/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.1687 - val_accuracy: 0.9613\n",
      "Epoch 650/700\n",
      "7352/7352 [==============================] - 3s 342us/sample - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.1643 - val_accuracy: 0.9637\n",
      "Epoch 651/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.1442 - val_accuracy: 0.9671\n",
      "Epoch 652/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.1554 - val_accuracy: 0.9640\n",
      "Epoch 653/700\n",
      "7352/7352 [==============================] - 3s 356us/sample - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1569 - val_accuracy: 0.9640\n",
      "Epoch 654/700\n",
      "7352/7352 [==============================] - 4s 523us/sample - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.1692 - val_accuracy: 0.9617\n",
      "Epoch 655/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0102 - accuracy: 0.9961 - val_loss: 0.1607 - val_accuracy: 0.9640\n",
      "Epoch 656/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0087 - accuracy: 0.9963 - val_loss: 0.1520 - val_accuracy: 0.9647\n",
      "Epoch 657/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.1671 - val_accuracy: 0.9654\n",
      "Epoch 658/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0081 - accuracy: 0.9967 - val_loss: 0.1307 - val_accuracy: 0.9715\n",
      "Epoch 659/700\n",
      "7352/7352 [==============================] - 3s 356us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1429 - val_accuracy: 0.9671\n",
      "Epoch 660/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0102 - accuracy: 0.9959 - val_loss: 0.1597 - val_accuracy: 0.9630\n",
      "Epoch 661/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0110 - accuracy: 0.9942 - val_loss: 0.1585 - val_accuracy: 0.9650\n",
      "Epoch 662/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.1438 - val_accuracy: 0.9657\n",
      "Epoch 663/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.1194 - val_accuracy: 0.9725\n",
      "Epoch 664/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.1164 - val_accuracy: 0.9705\n",
      "Epoch 665/700\n",
      "7352/7352 [==============================] - 3s 364us/sample - loss: 0.0083 - accuracy: 0.9970 - val_loss: 0.1199 - val_accuracy: 0.9701\n",
      "Epoch 666/700\n",
      "7352/7352 [==============================] - 3s 381us/sample - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.1151 - val_accuracy: 0.9739\n",
      "Epoch 667/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.1225 - val_accuracy: 0.9739\n",
      "Epoch 668/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.1279 - val_accuracy: 0.9701\n",
      "Epoch 669/700\n",
      "7352/7352 [==============================] - 3s 359us/sample - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.1207 - val_accuracy: 0.9681\n",
      "Epoch 670/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.1175 - val_accuracy: 0.9732\n",
      "Epoch 671/700\n",
      "7352/7352 [==============================] - 3s 348us/sample - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.1265 - val_accuracy: 0.9684\n",
      "Epoch 672/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.1111 - val_accuracy: 0.9732\n",
      "Epoch 673/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1091 - val_accuracy: 0.9752\n",
      "Epoch 674/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.1236 - val_accuracy: 0.9715\n",
      "Epoch 675/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.1115 - val_accuracy: 0.9722\n",
      "Epoch 676/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.1138 - val_accuracy: 0.9715\n",
      "Epoch 677/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1230 - val_accuracy: 0.9705\n",
      "Epoch 678/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.1347 - val_accuracy: 0.9701\n",
      "Epoch 679/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.1221 - val_accuracy: 0.9725\n",
      "Epoch 680/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.1231 - val_accuracy: 0.9712\n",
      "Epoch 681/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0086 - accuracy: 0.9963 - val_loss: 0.1099 - val_accuracy: 0.9725\n",
      "Epoch 682/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1293 - val_accuracy: 0.9722\n",
      "Epoch 683/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1313 - val_accuracy: 0.9718\n",
      "Epoch 684/700\n",
      "7352/7352 [==============================] - 2s 337us/sample - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.1276 - val_accuracy: 0.9739\n",
      "Epoch 685/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.1243 - val_accuracy: 0.9725\n",
      "Epoch 686/700\n",
      "7352/7352 [==============================] - 3s 364us/sample - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.1374 - val_accuracy: 0.9674\n",
      "Epoch 687/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0085 - accuracy: 0.9962 - val_loss: 0.1483 - val_accuracy: 0.9684\n",
      "Epoch 688/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.1352 - val_accuracy: 0.9698\n",
      "Epoch 689/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0074 - accuracy: 0.9984 - val_loss: 0.1373 - val_accuracy: 0.9691\n",
      "Epoch 690/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.1457 - val_accuracy: 0.9701\n",
      "Epoch 691/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1497 - val_accuracy: 0.9684\n",
      "Epoch 692/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0079 - accuracy: 0.9971 - val_loss: 0.1411 - val_accuracy: 0.9695\n",
      "Epoch 693/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.1486 - val_accuracy: 0.9695\n",
      "Epoch 694/700\n",
      "7352/7352 [==============================] - 2s 336us/sample - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.1434 - val_accuracy: 0.9695\n",
      "Epoch 695/700\n",
      "7352/7352 [==============================] - 3s 362us/sample - loss: 0.0090 - accuracy: 0.9974 - val_loss: 0.1500 - val_accuracy: 0.9691\n",
      "Epoch 696/700\n",
      "7352/7352 [==============================] - 3s 341us/sample - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1674 - val_accuracy: 0.9681\n",
      "Epoch 697/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.1375 - val_accuracy: 0.9695\n",
      "Epoch 698/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.1493 - val_accuracy: 0.9698\n",
      "Epoch 699/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0081 - accuracy: 0.9970 - val_loss: 0.1480 - val_accuracy: 0.9705\n",
      "Epoch 700/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.1521 - val_accuracy: 0.9705\n",
      "------------------------ 测试中---------------------------\n",
      "2947/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 245us/sample - loss: 0.0761 - accuracy: 0.9705\n",
      "Baseline Error: 2.95%\n",
      "Size of the unpruned model before compression: 2.71 Mb\n",
      "Size of the unpruned model after compression: 2.44 Mb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import csv\n",
    "import tempfile\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.keras import backend as K\n",
    "from utils.utilities import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(813306)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allocator_type = 'BFC'  # A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "#config.gpu_options.allow_growth = True\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "#构建数据集 channel_last\n",
    "#构建数据集 channel_last\n",
    "def load_data():    \n",
    "    X_train, labels_train, list_ch_train = read_data(data_path=\"../data/HAR_Dataset\", split=\"train\") # train\n",
    "    X_test, labels_test, list_ch_test = read_data(data_path=\"../data/HAR_Dataset\", split=\"test\") # test\n",
    "    assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "    x_train = X_train[:,:,np.newaxis,:]\n",
    "    x_val = X_test[:,:,np.newaxis,:]\n",
    "    y_train = to_categorical(labels_train)\n",
    "    y_val = to_categorical(labels_test)\n",
    "    return (x_train,y_train),(x_val,y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_resnet(input_shape, n_feature_maps, nb_classes, dropout):\n",
    "    print('build conv_x')\n",
    "    x = Input(shape=(input_shape))\n",
    "\n",
    "    x_total = keras.layers.Conv2D(10, (17, 1),strides = (1,1), padding='same')(x)\n",
    "    conv_x = keras.layers.BatchNormalization()(x_total)  # 853\n",
    "\n",
    " \n",
    "    conv_x = keras.layers.Conv2D(n_feature_maps, (17, 1), padding='same')(conv_x)  # input size == ouput size\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "\n",
    "    print('build conv_y')\n",
    "    conv_y = keras.layers.Conv2D(n_feature_maps * 2, (17, 1), padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "\n",
    "    conv_y = Dropout(dropout)(conv_y)\n",
    "    print('build conv_z')\n",
    "    conv_z = keras.layers.Conv2D(n_feature_maps, (9, 1), padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps)  # 若当前输出和跨层连接的x，通道数不同，则采用1*1卷积使得通道数相同\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = keras.layers.Conv2D(n_feature_maps, (1, 1), padding='same')(x_total)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = keras.layers.BatchNormalization()(x_total)\n",
    "\n",
    "    print('Merging skip connection')\n",
    "    # y = merge([shortcut_y, conv_z], mode='sum')\n",
    "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "\n",
    "    full = keras.layers.GlobalAveragePooling2D()(y)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    print('        -- model was built.')\n",
    "    return x, out\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = 6\n",
    "    channels = 3\n",
    "    dropout = 0.2\n",
    "    nb_epochs = 700\n",
    "    batch_size = 50\n",
    "    data_row = 128\n",
    "    data_column = 1\n",
    "    trainpath = r'./data'\n",
    "\n",
    "    (x_train,y_train),(x_val,y_val) = load_data()\n",
    "\n",
    "\n",
    "    tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "    input_shape = (data_row, data_column,channels)\n",
    "\n",
    "    print('train dataset size:',x_train.shape[0])\n",
    "    print('validation dataset size:',x_val.shape[0])\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    x, y = build_resnet(input_shape, 64, num, dropout)  # 建立resnet只考虑了单个example\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.9,\n",
    "                                  patience=20, min_lr=0.00005)\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n",
    "                     verbose=1, validation_data=(x_val, y_val), callbacks=[reduce_lr])  # 回调函数会在训练的时候适当被调用\n",
    "\n",
    "\n",
    "    # 测试\n",
    "    print(\"------------------------ 测试中---------------------------\")\n",
    "    #evaluation of the model\n",
    "    scores = model.evaluate(x_val,y_val)\n",
    "    print('Baseline Error: %.2f%%'%(100 * (1 - scores[1])))\n",
    "    keras.models.save_model(model, '../model/HAR.h5')\n",
    "    keras_file = '../model/HAR.h5'\n",
    "    _, zip1 = tempfile.mkstemp('.zip') \n",
    "    with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(keras_file)\n",
    "    print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "          (os.path.getsize(keras_file) / float(2**20)))\n",
    "    print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "          (os.path.getsize(zip1) / float(2**20)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "压缩网络 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 7352\n",
      "validation dataset size: 2947\n",
      "build conv_x\n",
      "build conv_z\n",
      "        -- model was built.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 1, 9)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 128, 1)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128, 1, 1)    0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 128, 1, 1)    0           tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 128, 1, 1)    0           tf_op_layer_strided_slice_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 128, 1, 1)    0           tf_op_layer_strided_slice_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 128, 1, 1)    0           tf_op_layer_strided_slice_4[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 128, 1, 1)    0           tf_op_layer_strided_slice_5[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 128, 1, 1)    0           tf_op_layer_strided_slice_6[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 128, 1, 1)    0           tf_op_layer_strided_slice_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 128, 1, 1)    0           tf_op_layer_strided_slice_8[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 1, 16)   272         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 1, 16)   272         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 1, 16)   272         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 1, 16)   272         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 1, 16)   272         reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 128, 1, 16)   272         reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 128, 1, 16)   272         reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 128, 1, 16)   272         reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 1, 16)   272         reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 43, 1, 16)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 43, 1, 16)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 43, 1, 16)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 43, 1, 16)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 43, 1, 16)    0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 43, 1, 16)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 43, 1, 16)    0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 43, 1, 16)    0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 43, 1, 16)    0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 43, 1, 16)    64          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 43, 1, 16)    64          average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 43, 1, 16)    64          average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 43, 1, 16)    64          average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 43, 1, 16)    64          average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 43, 1, 16)    64          average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 43, 1, 16)    64          average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 43, 1, 16)    64          average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 43, 1, 16)    64          average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 43, 1, 16)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 43, 1, 16)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 43, 1, 16)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 43, 1, 16)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 43, 1, 16)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 43, 1, 16)    0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 43, 1, 16)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 43, 1, 16)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 43, 1, 16)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 43, 1, 32)    8224        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 43, 1, 32)    8224        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 43, 1, 32)    8224        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 43, 1, 32)    8224        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 43, 1, 32)    8224        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 43, 1, 32)    8224        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 43, 1, 32)    8224        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 43, 1, 32)    8224        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 43, 1, 32)    8224        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 15, 1, 32)    0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 15, 1, 32)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 15, 1, 32)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 15, 1, 32)    0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 15, 1, 32)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 15, 1, 32)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 15, 1, 32)    0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 15, 1, 32)    0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 15, 1, 32)    0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 15, 1, 32)    128         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 1, 32)    128         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 1, 32)    128         average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 15, 1, 32)    128         average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 15, 1, 32)    128         average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 15, 1, 32)    128         average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 15, 1, 32)    128         average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 15, 1, 32)    128         average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 15, 1, 32)    128         average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 15, 1, 32)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 1, 32)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 1, 32)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 15, 1, 32)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 15, 1, 32)    0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 15, 1, 32)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 15, 1, 32)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 15, 1, 32)    0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 15, 1, 32)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 15, 1, 16)    8208        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 15, 1, 16)    8208        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 15, 1, 16)    8208        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 15, 1, 16)    8208        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 15, 1, 16)    8208        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 15, 1, 16)    8208        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 15, 1, 16)    8208        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 15, 1, 16)    8208        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 15, 1, 16)    8208        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 1, 16)     0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 8, 1, 16)     0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 8, 1, 16)     0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 8, 1, 16)     0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 8, 1, 16)     0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 8, 1, 16)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 8, 1, 16)     0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 8, 1, 16)     0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_34 (AveragePo (None, 8, 1, 16)     0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 8, 1, 16)     64          average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8, 1, 16)     64          average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_34[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 8, 1, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 8, 1, 16)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 1, 16)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 1, 16)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 1, 16)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 1, 16)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 1, 16)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 8, 1, 16)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 8, 1, 16)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 1, 16)     4112        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 1, 16)     4112        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 1, 16)     4112        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 1, 16)     4112        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 1, 16)     4112        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 1, 16)     4112        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 1, 16)     4112        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 8, 1, 16)     4112        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 1, 16)     4112        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 1, 16)     0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 4, 1, 16)     0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 4, 1, 16)     0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 4, 1, 16)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 4, 1, 16)     0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 4, 1, 16)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 4, 1, 16)     0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 4, 1, 16)     0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_35 (AveragePo (None, 4, 1, 16)     0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 4, 1, 16)     64          average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 4, 1, 16)     64          average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_35[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 4, 1, 16)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 4, 1, 16)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 4, 1, 16)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 1, 16)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 4, 1, 16)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 4, 1, 16)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 1, 16)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 1, 16)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 1, 16)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 1, 1)      129         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 4, 1, 1)      129         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 1, 1)      129         activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 1, 1)      129         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 1, 1)      129         activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 1, 1)      129         activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 4, 1, 1)      129         activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 4, 1, 1)      129         activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 1, 1)      129         activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, 4, 1, 9)]    0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "                                                                 conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 4, 1, 9)      36          tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 4, 1, 64)     9280        batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 4, 1, 64)     256         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 1, 64)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 4, 1, 64)     640         tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 4, 1, 64)     32832       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 4, 1, 64)     0           conv2d_47[0][0]                  \n",
      "                                                                 conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 4, 1, 64)     256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 4, 1, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 7)            455         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 235,140\n",
      "Trainable params: 233,426\n",
      "Non-trainable params: 1,714\n",
      "__________________________________________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/700\n",
      "7352/7352 [==============================] - 24s 3ms/sample - loss: 0.2968 - accuracy: 0.9064 - val_loss: 2.1924 - val_accuracy: 0.2457\n",
      "Epoch 2/700\n",
      "7352/7352 [==============================] - 7s 933us/sample - loss: 0.1617 - accuracy: 0.9414 - val_loss: 2.1510 - val_accuracy: 0.4656\n",
      "Epoch 3/700\n",
      "7352/7352 [==============================] - 7s 989us/sample - loss: 0.1141 - accuracy: 0.9580 - val_loss: 0.6512 - val_accuracy: 0.7764\n",
      "Epoch 4/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.1047 - accuracy: 0.9589 - val_loss: 0.2356 - val_accuracy: 0.9220\n",
      "Epoch 5/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.1004 - accuracy: 0.9640 - val_loss: 0.2564 - val_accuracy: 0.8941\n",
      "Epoch 6/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0904 - accuracy: 0.9644 - val_loss: 0.1210 - val_accuracy: 0.9552\n",
      "Epoch 7/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0801 - accuracy: 0.9676 - val_loss: 0.3395 - val_accuracy: 0.8999\n",
      "Epoch 8/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0763 - accuracy: 0.9737 - val_loss: 0.4776 - val_accuracy: 0.8571\n",
      "Epoch 9/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0891 - accuracy: 0.9669 - val_loss: 0.2220 - val_accuracy: 0.9179\n",
      "Epoch 10/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0699 - accuracy: 0.9744 - val_loss: 0.1461 - val_accuracy: 0.9528\n",
      "Epoch 11/700\n",
      "7352/7352 [==============================] - 11s 2ms/sample - loss: 0.0797 - accuracy: 0.9698 - val_loss: 0.5752 - val_accuracy: 0.8534\n",
      "Epoch 12/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0666 - accuracy: 0.9735 - val_loss: 0.4039 - val_accuracy: 0.8789\n",
      "Epoch 13/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0668 - accuracy: 0.9743 - val_loss: 1.2953 - val_accuracy: 0.7553\n",
      "Epoch 14/700\n",
      "7352/7352 [==============================] - 7s 890us/sample - loss: 0.0600 - accuracy: 0.9770 - val_loss: 0.0935 - val_accuracy: 0.9630\n",
      "Epoch 15/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0525 - accuracy: 0.9804 - val_loss: 0.0867 - val_accuracy: 0.9695\n",
      "Epoch 16/700\n",
      "7352/7352 [==============================] - 6s 878us/sample - loss: 0.0612 - accuracy: 0.9778 - val_loss: 0.9352 - val_accuracy: 0.8436\n",
      "Epoch 17/700\n",
      "7352/7352 [==============================] - 7s 889us/sample - loss: 0.0725 - accuracy: 0.9716 - val_loss: 0.1426 - val_accuracy: 0.9413\n",
      "Epoch 18/700\n",
      "7352/7352 [==============================] - 6s 878us/sample - loss: 0.0662 - accuracy: 0.9754 - val_loss: 0.5041 - val_accuracy: 0.8741\n",
      "Epoch 19/700\n",
      "7352/7352 [==============================] - 7s 901us/sample - loss: 0.0692 - accuracy: 0.9751 - val_loss: 0.1277 - val_accuracy: 0.9630\n",
      "Epoch 20/700\n",
      "7352/7352 [==============================] - 7s 898us/sample - loss: 0.0625 - accuracy: 0.9765 - val_loss: 0.1208 - val_accuracy: 0.9525\n",
      "Epoch 21/700\n",
      "7352/7352 [==============================] - 6s 872us/sample - loss: 0.0567 - accuracy: 0.9766 - val_loss: 0.1594 - val_accuracy: 0.9420\n",
      "Epoch 22/700\n",
      "7352/7352 [==============================] - 7s 913us/sample - loss: 0.0612 - accuracy: 0.9754 - val_loss: 0.0967 - val_accuracy: 0.9600\n",
      "Epoch 23/700\n",
      "7352/7352 [==============================] - 7s 914us/sample - loss: 0.0512 - accuracy: 0.9789 - val_loss: 0.1829 - val_accuracy: 0.9250\n",
      "Epoch 24/700\n",
      "7352/7352 [==============================] - 6s 876us/sample - loss: 0.0568 - accuracy: 0.9781 - val_loss: 0.1034 - val_accuracy: 0.9576\n",
      "Epoch 25/700\n",
      "7352/7352 [==============================] - 6s 882us/sample - loss: 0.0595 - accuracy: 0.9776 - val_loss: 0.1425 - val_accuracy: 0.9539\n",
      "Epoch 26/700\n",
      "7352/7352 [==============================] - 6s 878us/sample - loss: 0.0468 - accuracy: 0.9816 - val_loss: 0.1380 - val_accuracy: 0.9491\n",
      "Epoch 27/700\n",
      "7352/7352 [==============================] - 7s 897us/sample - loss: 0.0899 - accuracy: 0.9634 - val_loss: 0.1731 - val_accuracy: 0.9287\n",
      "Epoch 28/700\n",
      "7352/7352 [==============================] - 7s 886us/sample - loss: 0.0754 - accuracy: 0.9693 - val_loss: 0.1179 - val_accuracy: 0.9589\n",
      "Epoch 29/700\n",
      "7352/7352 [==============================] - 7s 893us/sample - loss: 0.0686 - accuracy: 0.9729 - val_loss: 0.8692 - val_accuracy: 0.7482\n",
      "Epoch 30/700\n",
      "7352/7352 [==============================] - 6s 881us/sample - loss: 0.0662 - accuracy: 0.9750 - val_loss: 0.1355 - val_accuracy: 0.9474\n",
      "Epoch 31/700\n",
      "7352/7352 [==============================] - 6s 866us/sample - loss: 0.0424 - accuracy: 0.9833 - val_loss: 0.0807 - val_accuracy: 0.9695\n",
      "Epoch 32/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0445 - accuracy: 0.9827 - val_loss: 0.0841 - val_accuracy: 0.9691\n",
      "Epoch 33/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0566 - accuracy: 0.9804 - val_loss: 0.1037 - val_accuracy: 0.9566\n",
      "Epoch 34/700\n",
      "7352/7352 [==============================] - 7s 998us/sample - loss: 0.0469 - accuracy: 0.9826 - val_loss: 0.1523 - val_accuracy: 0.9572\n",
      "Epoch 35/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0400 - accuracy: 0.9839 - val_loss: 0.3664 - val_accuracy: 0.8884\n",
      "Epoch 36/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0445 - accuracy: 0.9819 - val_loss: 0.2227 - val_accuracy: 0.9338\n",
      "Epoch 37/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0470 - accuracy: 0.9822 - val_loss: 0.0696 - val_accuracy: 0.9739\n",
      "Epoch 38/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0424 - accuracy: 0.9822 - val_loss: 0.0859 - val_accuracy: 0.9650\n",
      "Epoch 39/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0383 - accuracy: 0.9844 - val_loss: 0.1816 - val_accuracy: 0.9352\n",
      "Epoch 40/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0388 - accuracy: 0.9853 - val_loss: 0.1796 - val_accuracy: 0.9515\n",
      "Epoch 41/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0406 - accuracy: 0.9852 - val_loss: 0.1815 - val_accuracy: 0.9491\n",
      "Epoch 42/700\n",
      "7352/7352 [==============================] - 7s 947us/sample - loss: 0.0409 - accuracy: 0.9831 - val_loss: 0.1593 - val_accuracy: 0.9535\n",
      "Epoch 43/700\n",
      "7352/7352 [==============================] - 7s 997us/sample - loss: 0.0420 - accuracy: 0.9844 - val_loss: 0.0804 - val_accuracy: 0.9688\n",
      "Epoch 44/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0437 - accuracy: 0.9830 - val_loss: 0.1178 - val_accuracy: 0.9640\n",
      "Epoch 45/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0499 - accuracy: 0.9825 - val_loss: 0.1342 - val_accuracy: 0.9610\n",
      "Epoch 46/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0362 - accuracy: 0.9872 - val_loss: 0.1429 - val_accuracy: 0.9552\n",
      "Epoch 47/700\n",
      "7352/7352 [==============================] - 7s 940us/sample - loss: 0.0369 - accuracy: 0.9860 - val_loss: 0.0616 - val_accuracy: 0.9766\n",
      "Epoch 48/700\n",
      "7352/7352 [==============================] - 7s 990us/sample - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.1382 - val_accuracy: 0.9488\n",
      "Epoch 49/700\n",
      "7352/7352 [==============================] - 7s 952us/sample - loss: 0.0431 - accuracy: 0.9837 - val_loss: 0.0939 - val_accuracy: 0.9667\n",
      "Epoch 50/700\n",
      "7352/7352 [==============================] - 7s 938us/sample - loss: 0.0541 - accuracy: 0.9795 - val_loss: 0.1633 - val_accuracy: 0.9484\n",
      "Epoch 51/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0472 - accuracy: 0.9825 - val_loss: 0.1612 - val_accuracy: 0.9369\n",
      "Epoch 52/700\n",
      "7352/7352 [==============================] - 7s 948us/sample - loss: 0.0357 - accuracy: 0.9857 - val_loss: 0.1217 - val_accuracy: 0.9637\n",
      "Epoch 53/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0314 - accuracy: 0.9883 - val_loss: 0.1004 - val_accuracy: 0.9657\n",
      "Epoch 54/700\n",
      "7352/7352 [==============================] - 7s 946us/sample - loss: 0.0515 - accuracy: 0.9801 - val_loss: 0.1825 - val_accuracy: 0.9464\n",
      "Epoch 55/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0492 - accuracy: 0.9814 - val_loss: 0.1108 - val_accuracy: 0.9606\n",
      "Epoch 56/700\n",
      "7352/7352 [==============================] - 7s 920us/sample - loss: 0.0391 - accuracy: 0.9853 - val_loss: 0.1723 - val_accuracy: 0.9481\n",
      "Epoch 57/700\n",
      "7352/7352 [==============================] - 7s 947us/sample - loss: 0.0448 - accuracy: 0.9831 - val_loss: 0.1993 - val_accuracy: 0.9396\n",
      "Epoch 58/700\n",
      "7352/7352 [==============================] - 7s 928us/sample - loss: 0.0432 - accuracy: 0.9820 - val_loss: 0.0866 - val_accuracy: 0.9688\n",
      "Epoch 59/700\n",
      "7352/7352 [==============================] - 7s 935us/sample - loss: 0.0441 - accuracy: 0.9837 - val_loss: 0.1615 - val_accuracy: 0.9410\n",
      "Epoch 60/700\n",
      "7352/7352 [==============================] - 7s 957us/sample - loss: 0.0341 - accuracy: 0.9882 - val_loss: 0.1011 - val_accuracy: 0.9627\n",
      "Epoch 61/700\n",
      "7352/7352 [==============================] - 7s 966us/sample - loss: 0.0394 - accuracy: 0.9845 - val_loss: 0.2055 - val_accuracy: 0.9396\n",
      "Epoch 62/700\n",
      "7352/7352 [==============================] - 7s 963us/sample - loss: 0.0433 - accuracy: 0.9829 - val_loss: 0.4077 - val_accuracy: 0.8968\n",
      "Epoch 63/700\n",
      "7352/7352 [==============================] - 7s 937us/sample - loss: 0.0351 - accuracy: 0.9853 - val_loss: 0.0656 - val_accuracy: 0.9742\n",
      "Epoch 64/700\n",
      "7352/7352 [==============================] - 7s 950us/sample - loss: 0.0367 - accuracy: 0.9857 - val_loss: 0.0748 - val_accuracy: 0.9718\n",
      "Epoch 65/700\n",
      "7352/7352 [==============================] - 7s 936us/sample - loss: 0.0321 - accuracy: 0.9883 - val_loss: 0.4099 - val_accuracy: 0.9002\n",
      "Epoch 66/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0312 - accuracy: 0.9874 - val_loss: 0.2528 - val_accuracy: 0.9342\n",
      "Epoch 67/700\n",
      "7352/7352 [==============================] - 7s 962us/sample - loss: 0.0416 - accuracy: 0.9839 - val_loss: 0.1827 - val_accuracy: 0.9501\n",
      "Epoch 68/700\n",
      "7352/7352 [==============================] - 7s 930us/sample - loss: 0.0312 - accuracy: 0.9872 - val_loss: 0.0858 - val_accuracy: 0.9688\n",
      "Epoch 69/700\n",
      "7352/7352 [==============================] - 7s 946us/sample - loss: 0.0314 - accuracy: 0.9894 - val_loss: 0.1668 - val_accuracy: 0.9545\n",
      "Epoch 70/700\n",
      "7352/7352 [==============================] - 7s 993us/sample - loss: 0.0310 - accuracy: 0.9890 - val_loss: 0.0939 - val_accuracy: 0.9657\n",
      "Epoch 71/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0452 - accuracy: 0.9818 - val_loss: 0.3120 - val_accuracy: 0.9189\n",
      "Epoch 72/700\n",
      "7352/7352 [==============================] - 7s 967us/sample - loss: 0.0353 - accuracy: 0.9861 - val_loss: 0.0766 - val_accuracy: 0.9705\n",
      "Epoch 73/700\n",
      "7352/7352 [==============================] - 7s 940us/sample - loss: 0.0310 - accuracy: 0.9880 - val_loss: 0.0809 - val_accuracy: 0.9698\n",
      "Epoch 74/700\n",
      "7352/7352 [==============================] - 7s 989us/sample - loss: 0.0417 - accuracy: 0.9853 - val_loss: 0.1001 - val_accuracy: 0.9627\n",
      "Epoch 75/700\n",
      "7352/7352 [==============================] - 7s 948us/sample - loss: 0.0425 - accuracy: 0.9822 - val_loss: 0.0960 - val_accuracy: 0.9644\n",
      "Epoch 76/700\n",
      "7352/7352 [==============================] - 7s 944us/sample - loss: 0.0315 - accuracy: 0.9894 - val_loss: 0.0918 - val_accuracy: 0.9667\n",
      "Epoch 77/700\n",
      "7352/7352 [==============================] - 7s 997us/sample - loss: 0.0337 - accuracy: 0.9868 - val_loss: 0.3576 - val_accuracy: 0.9114\n",
      "Epoch 78/700\n",
      "7352/7352 [==============================] - 7s 946us/sample - loss: 0.0313 - accuracy: 0.9879 - val_loss: 0.0939 - val_accuracy: 0.9688\n",
      "Epoch 79/700\n",
      "7352/7352 [==============================] - 7s 951us/sample - loss: 0.0270 - accuracy: 0.9903 - val_loss: 0.0927 - val_accuracy: 0.9623\n",
      "Epoch 80/700\n",
      "7352/7352 [==============================] - 7s 949us/sample - loss: 0.0311 - accuracy: 0.9888 - val_loss: 0.3026 - val_accuracy: 0.9315\n",
      "Epoch 81/700\n",
      "7352/7352 [==============================] - 7s 946us/sample - loss: 0.0339 - accuracy: 0.9867 - val_loss: 0.1445 - val_accuracy: 0.9511\n",
      "Epoch 82/700\n",
      "7352/7352 [==============================] - 7s 953us/sample - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.4507 - val_accuracy: 0.9091\n",
      "Epoch 83/700\n",
      "7352/7352 [==============================] - 7s 945us/sample - loss: 0.0324 - accuracy: 0.9871 - val_loss: 0.1017 - val_accuracy: 0.9630\n",
      "Epoch 84/700\n",
      "7352/7352 [==============================] - 7s 941us/sample - loss: 0.0274 - accuracy: 0.9895 - val_loss: 0.1272 - val_accuracy: 0.9542\n",
      "Epoch 85/700\n",
      "7352/7352 [==============================] - 7s 967us/sample - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.0939 - val_accuracy: 0.9650\n",
      "Epoch 86/700\n",
      "7352/7352 [==============================] - 7s 935us/sample - loss: 0.0351 - accuracy: 0.9865 - val_loss: 0.1694 - val_accuracy: 0.9501\n",
      "Epoch 87/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0278 - accuracy: 0.9898 - val_loss: 0.1821 - val_accuracy: 0.9484\n",
      "Epoch 88/700\n",
      "7352/7352 [==============================] - 7s 944us/sample - loss: 0.0263 - accuracy: 0.9898 - val_loss: 0.0985 - val_accuracy: 0.9678\n",
      "Epoch 89/700\n",
      "7352/7352 [==============================] - 7s 909us/sample - loss: 0.0274 - accuracy: 0.9898 - val_loss: 0.3662 - val_accuracy: 0.9182\n",
      "Epoch 90/700\n",
      "7352/7352 [==============================] - 7s 951us/sample - loss: 0.0277 - accuracy: 0.9894 - val_loss: 0.2713 - val_accuracy: 0.9179\n",
      "Epoch 91/700\n",
      "7352/7352 [==============================] - 7s 931us/sample - loss: 0.0331 - accuracy: 0.9883 - val_loss: 0.1958 - val_accuracy: 0.9444\n",
      "Epoch 92/700\n",
      "7352/7352 [==============================] - 7s 929us/sample - loss: 0.0324 - accuracy: 0.9878 - val_loss: 0.1284 - val_accuracy: 0.9539\n",
      "Epoch 93/700\n",
      "7352/7352 [==============================] - 7s 933us/sample - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.0944 - val_accuracy: 0.9661\n",
      "Epoch 94/700\n",
      "7352/7352 [==============================] - 7s 944us/sample - loss: 0.0322 - accuracy: 0.9880 - val_loss: 0.3991 - val_accuracy: 0.9128\n",
      "Epoch 95/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0284 - accuracy: 0.9890 - val_loss: 0.1397 - val_accuracy: 0.9606\n",
      "Epoch 96/700\n",
      "7352/7352 [==============================] - 7s 973us/sample - loss: 0.0298 - accuracy: 0.9883 - val_loss: 0.1501 - val_accuracy: 0.9613\n",
      "Epoch 97/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0300 - accuracy: 0.9880 - val_loss: 0.2465 - val_accuracy: 0.9379\n",
      "Epoch 98/700\n",
      "7352/7352 [==============================] - 10s 1ms/sample - loss: 0.0315 - accuracy: 0.9876 - val_loss: 0.1544 - val_accuracy: 0.9606\n",
      "Epoch 99/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0389 - accuracy: 0.9849 - val_loss: 0.1162 - val_accuracy: 0.9593\n",
      "Epoch 100/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.3493 - val_accuracy: 0.9220\n",
      "Epoch 101/700\n",
      "7352/7352 [==============================] - 7s 969us/sample - loss: 0.0391 - accuracy: 0.9852 - val_loss: 0.3641 - val_accuracy: 0.9121\n",
      "Epoch 102/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0298 - accuracy: 0.9888 - val_loss: 0.3325 - val_accuracy: 0.9264\n",
      "Epoch 103/700\n",
      "7352/7352 [==============================] - 7s 964us/sample - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.3048 - val_accuracy: 0.9141\n",
      "Epoch 104/700\n",
      "7352/7352 [==============================] - 7s 972us/sample - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.3264 - val_accuracy: 0.9141\n",
      "Epoch 105/700\n",
      "7352/7352 [==============================] - 7s 920us/sample - loss: 0.0403 - accuracy: 0.9863 - val_loss: 0.1239 - val_accuracy: 0.9532\n",
      "Epoch 106/700\n",
      "7352/7352 [==============================] - 7s 932us/sample - loss: 0.0222 - accuracy: 0.9917 - val_loss: 0.2579 - val_accuracy: 0.9365\n",
      "Epoch 107/700\n",
      "7352/7352 [==============================] - 7s 929us/sample - loss: 0.0234 - accuracy: 0.9909 - val_loss: 0.1237 - val_accuracy: 0.9593\n",
      "Epoch 108/700\n",
      "7352/7352 [==============================] - 7s 975us/sample - loss: 0.0225 - accuracy: 0.9909 - val_loss: 0.0959 - val_accuracy: 0.9678\n",
      "Epoch 109/700\n",
      "7352/7352 [==============================] - 7s 926us/sample - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.1358 - val_accuracy: 0.9610\n",
      "Epoch 110/700\n",
      "7352/7352 [==============================] - 7s 937us/sample - loss: 0.0205 - accuracy: 0.9921 - val_loss: 0.2452 - val_accuracy: 0.9406\n",
      "Epoch 111/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0269 - accuracy: 0.9897 - val_loss: 0.4881 - val_accuracy: 0.8894\n",
      "Epoch 112/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0274 - accuracy: 0.9895 - val_loss: 0.1984 - val_accuracy: 0.9335\n",
      "Epoch 113/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.5182 - val_accuracy: 0.8660\n",
      "Epoch 114/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0332 - accuracy: 0.9875 - val_loss: 0.3122 - val_accuracy: 0.9277\n",
      "Epoch 115/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0292 - accuracy: 0.9893 - val_loss: 0.1398 - val_accuracy: 0.9501\n",
      "Epoch 116/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.4525 - val_accuracy: 0.8894\n",
      "Epoch 117/700\n",
      "7352/7352 [==============================] - 7s 938us/sample - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.2636 - val_accuracy: 0.9352\n",
      "Epoch 118/700\n",
      "7352/7352 [==============================] - 7s 962us/sample - loss: 0.0945 - accuracy: 0.9638 - val_loss: 0.1647 - val_accuracy: 0.9460\n",
      "Epoch 119/700\n",
      "7352/7352 [==============================] - 7s 943us/sample - loss: 0.0626 - accuracy: 0.9743 - val_loss: 0.1599 - val_accuracy: 0.9559\n",
      "Epoch 120/700\n",
      "7352/7352 [==============================] - 7s 957us/sample - loss: 0.0646 - accuracy: 0.9727 - val_loss: 0.1596 - val_accuracy: 0.9579\n",
      "Epoch 121/700\n",
      "7352/7352 [==============================] - 7s 985us/sample - loss: 0.0542 - accuracy: 0.9784 - val_loss: 0.1793 - val_accuracy: 0.9433\n",
      "Epoch 122/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0456 - accuracy: 0.9826 - val_loss: 0.1595 - val_accuracy: 0.9566\n",
      "Epoch 123/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0371 - accuracy: 0.9834 - val_loss: 0.1547 - val_accuracy: 0.9606\n",
      "Epoch 124/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0382 - accuracy: 0.9835 - val_loss: 0.1550 - val_accuracy: 0.9525\n",
      "Epoch 125/700\n",
      "7352/7352 [==============================] - 7s 933us/sample - loss: 0.0402 - accuracy: 0.9827 - val_loss: 0.2528 - val_accuracy: 0.9352\n",
      "Epoch 126/700\n",
      "7352/7352 [==============================] - 7s 961us/sample - loss: 0.0369 - accuracy: 0.9875 - val_loss: 0.2286 - val_accuracy: 0.9423\n",
      "Epoch 127/700\n",
      "7352/7352 [==============================] - 7s 934us/sample - loss: 0.0314 - accuracy: 0.9891 - val_loss: 0.1893 - val_accuracy: 0.9460\n",
      "Epoch 128/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0316 - accuracy: 0.9886 - val_loss: 0.2477 - val_accuracy: 0.9355\n",
      "Epoch 129/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.1395 - val_accuracy: 0.9650\n",
      "Epoch 130/700\n",
      "7352/7352 [==============================] - 7s 965us/sample - loss: 0.0310 - accuracy: 0.9899 - val_loss: 0.1576 - val_accuracy: 0.9522\n",
      "Epoch 131/700\n",
      "7352/7352 [==============================] - 7s 972us/sample - loss: 0.0258 - accuracy: 0.9901 - val_loss: 0.1445 - val_accuracy: 0.9501\n",
      "Epoch 132/700\n",
      "7352/7352 [==============================] - 7s 988us/sample - loss: 0.0208 - accuracy: 0.9924 - val_loss: 0.0969 - val_accuracy: 0.9664\n",
      "Epoch 133/700\n",
      "7352/7352 [==============================] - 7s 912us/sample - loss: 0.0204 - accuracy: 0.9922 - val_loss: 0.1157 - val_accuracy: 0.9613\n",
      "Epoch 134/700\n",
      "7352/7352 [==============================] - 7s 909us/sample - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.1118 - val_accuracy: 0.9657\n",
      "Epoch 135/700\n",
      "7352/7352 [==============================] - 7s 921us/sample - loss: 0.0219 - accuracy: 0.9921 - val_loss: 0.1424 - val_accuracy: 0.9610\n",
      "Epoch 136/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0192 - accuracy: 0.9929 - val_loss: 0.2862 - val_accuracy: 0.9264\n",
      "Epoch 137/700\n",
      "7352/7352 [==============================] - 7s 943us/sample - loss: 0.0182 - accuracy: 0.9935 - val_loss: 0.1508 - val_accuracy: 0.9552\n",
      "Epoch 138/700\n",
      "7352/7352 [==============================] - 7s 965us/sample - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.1441 - val_accuracy: 0.9542\n",
      "Epoch 139/700\n",
      "7352/7352 [==============================] - 7s 913us/sample - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0852 - val_accuracy: 0.9715\n",
      "Epoch 140/700\n",
      "7352/7352 [==============================] - 7s 946us/sample - loss: 0.0292 - accuracy: 0.9894 - val_loss: 0.0858 - val_accuracy: 0.9735\n",
      "Epoch 141/700\n",
      "7352/7352 [==============================] - 7s 940us/sample - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.1305 - val_accuracy: 0.9586\n",
      "Epoch 142/700\n",
      "7352/7352 [==============================] - 7s 926us/sample - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0901 - val_accuracy: 0.9732\n",
      "Epoch 143/700\n",
      "7352/7352 [==============================] - 7s 920us/sample - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.0939 - val_accuracy: 0.9637\n",
      "Epoch 144/700\n",
      "7352/7352 [==============================] - 7s 931us/sample - loss: 0.0144 - accuracy: 0.9947 - val_loss: 0.1259 - val_accuracy: 0.9644\n",
      "Epoch 145/700\n",
      "7352/7352 [==============================] - 7s 939us/sample - loss: 0.0125 - accuracy: 0.9950 - val_loss: 0.1209 - val_accuracy: 0.9647\n",
      "Epoch 146/700\n",
      "7352/7352 [==============================] - 7s 946us/sample - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.1494 - val_accuracy: 0.9576\n",
      "Epoch 147/700\n",
      "7352/7352 [==============================] - 7s 932us/sample - loss: 0.0191 - accuracy: 0.9921 - val_loss: 0.5074 - val_accuracy: 0.8789\n",
      "Epoch 148/700\n",
      "7352/7352 [==============================] - 7s 917us/sample - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.1318 - val_accuracy: 0.9613\n",
      "Epoch 149/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.0896 - val_accuracy: 0.9729\n",
      "Epoch 150/700\n",
      "7352/7352 [==============================] - 7s 958us/sample - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.1092 - val_accuracy: 0.9650\n",
      "Epoch 151/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0160 - accuracy: 0.9942 - val_loss: 0.2551 - val_accuracy: 0.9362\n",
      "Epoch 152/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.1324 - val_accuracy: 0.9667\n",
      "Epoch 153/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.1648 - val_accuracy: 0.9566\n",
      "Epoch 154/700\n",
      "7352/7352 [==============================] - 7s 907us/sample - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.3152 - val_accuracy: 0.9253\n",
      "Epoch 155/700\n",
      "7352/7352 [==============================] - 7s 948us/sample - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.2182 - val_accuracy: 0.9471\n",
      "Epoch 156/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0168 - accuracy: 0.9936 - val_loss: 0.1004 - val_accuracy: 0.9725\n",
      "Epoch 157/700\n",
      "7352/7352 [==============================] - 7s 940us/sample - loss: 0.0186 - accuracy: 0.9922 - val_loss: 0.1504 - val_accuracy: 0.9640\n",
      "Epoch 158/700\n",
      "7352/7352 [==============================] - 7s 962us/sample - loss: 0.0151 - accuracy: 0.9952 - val_loss: 0.1775 - val_accuracy: 0.9494\n",
      "Epoch 159/700\n",
      "7352/7352 [==============================] - 7s 926us/sample - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.1013 - val_accuracy: 0.9739\n",
      "Epoch 160/700\n",
      "7352/7352 [==============================] - 7s 935us/sample - loss: 0.0133 - accuracy: 0.9946 - val_loss: 0.1245 - val_accuracy: 0.9678\n",
      "Epoch 161/700\n",
      "7352/7352 [==============================] - 7s 931us/sample - loss: 0.0168 - accuracy: 0.9935 - val_loss: 0.2945 - val_accuracy: 0.9359\n",
      "Epoch 162/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0164 - accuracy: 0.9936 - val_loss: 0.2241 - val_accuracy: 0.9454\n",
      "Epoch 163/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.0791 - val_accuracy: 0.9715\n",
      "Epoch 164/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0199 - accuracy: 0.9921 - val_loss: 0.2395 - val_accuracy: 0.9365\n",
      "Epoch 165/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0168 - accuracy: 0.9939 - val_loss: 0.3149 - val_accuracy: 0.9257\n",
      "Epoch 166/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.3843 - val_accuracy: 0.9250\n",
      "Epoch 167/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.2023 - val_accuracy: 0.9518\n",
      "Epoch 168/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0157 - accuracy: 0.9954 - val_loss: 0.1513 - val_accuracy: 0.9579\n",
      "Epoch 169/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0183 - accuracy: 0.9931 - val_loss: 0.1776 - val_accuracy: 0.9562\n",
      "Epoch 170/700\n",
      "7352/7352 [==============================] - 7s 940us/sample - loss: 0.0180 - accuracy: 0.9921 - val_loss: 0.1295 - val_accuracy: 0.9623\n",
      "Epoch 171/700\n",
      "7352/7352 [==============================] - 7s 930us/sample - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.1249 - val_accuracy: 0.9644\n",
      "Epoch 172/700\n",
      "7352/7352 [==============================] - 7s 996us/sample - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.1006 - val_accuracy: 0.9691\n",
      "Epoch 173/700\n",
      "7352/7352 [==============================] - 7s 954us/sample - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.3368 - val_accuracy: 0.9284\n",
      "Epoch 174/700\n",
      "7352/7352 [==============================] - 7s 940us/sample - loss: 0.0145 - accuracy: 0.9943 - val_loss: 0.1838 - val_accuracy: 0.9494\n",
      "Epoch 175/700\n",
      "7352/7352 [==============================] - 6s 873us/sample - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0922 - val_accuracy: 0.9732\n",
      "Epoch 176/700\n",
      "7352/7352 [==============================] - 7s 900us/sample - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.1206 - val_accuracy: 0.9701\n",
      "Epoch 177/700\n",
      "7352/7352 [==============================] - 6s 874us/sample - loss: 0.0114 - accuracy: 0.9956 - val_loss: 0.1080 - val_accuracy: 0.9735\n",
      "Epoch 178/700\n",
      "7352/7352 [==============================] - 7s 884us/sample - loss: 0.0119 - accuracy: 0.9955 - val_loss: 0.8390 - val_accuracy: 0.8839\n",
      "Epoch 179/700\n",
      "7352/7352 [==============================] - 7s 904us/sample - loss: 0.0150 - accuracy: 0.9939 - val_loss: 0.3119 - val_accuracy: 0.9284\n",
      "Epoch 180/700\n",
      "7352/7352 [==============================] - 7s 954us/sample - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.1256 - val_accuracy: 0.9650\n",
      "Epoch 181/700\n",
      "7352/7352 [==============================] - 7s 986us/sample - loss: 0.0208 - accuracy: 0.9922 - val_loss: 0.1307 - val_accuracy: 0.9603\n",
      "Epoch 182/700\n",
      "7352/7352 [==============================] - 7s 969us/sample - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.2323 - val_accuracy: 0.9484\n",
      "Epoch 183/700\n",
      "7352/7352 [==============================] - 7s 980us/sample - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.1445 - val_accuracy: 0.9623\n",
      "Epoch 184/700\n",
      "7352/7352 [==============================] - 7s 903us/sample - loss: 0.0141 - accuracy: 0.9942 - val_loss: 0.1071 - val_accuracy: 0.9705\n",
      "Epoch 185/700\n",
      "7352/7352 [==============================] - 7s 901us/sample - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.0935 - val_accuracy: 0.9752\n",
      "Epoch 186/700\n",
      "7352/7352 [==============================] - 6s 881us/sample - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.1825 - val_accuracy: 0.9583\n",
      "Epoch 187/700\n",
      "7352/7352 [==============================] - 7s 897us/sample - loss: 0.0437 - accuracy: 0.9838 - val_loss: 0.2678 - val_accuracy: 0.9386\n",
      "Epoch 188/700\n",
      "7352/7352 [==============================] - 7s 961us/sample - loss: 0.0218 - accuracy: 0.9927 - val_loss: 0.1479 - val_accuracy: 0.9634\n",
      "Epoch 189/700\n",
      "7352/7352 [==============================] - 7s 968us/sample - loss: 0.0171 - accuracy: 0.9935 - val_loss: 0.1363 - val_accuracy: 0.9617\n",
      "Epoch 190/700\n",
      "7352/7352 [==============================] - 7s 969us/sample - loss: 0.0175 - accuracy: 0.9932 - val_loss: 0.0951 - val_accuracy: 0.9742\n",
      "Epoch 191/700\n",
      "7352/7352 [==============================] - 7s 907us/sample - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.2885 - val_accuracy: 0.9335\n",
      "Epoch 192/700\n",
      "7352/7352 [==============================] - 7s 897us/sample - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.1019 - val_accuracy: 0.9732\n",
      "Epoch 193/700\n",
      "7352/7352 [==============================] - 7s 916us/sample - loss: 0.0166 - accuracy: 0.9936 - val_loss: 0.0903 - val_accuracy: 0.9756\n",
      "Epoch 194/700\n",
      "7352/7352 [==============================] - 7s 945us/sample - loss: 0.0145 - accuracy: 0.9929 - val_loss: 0.2151 - val_accuracy: 0.9440\n",
      "Epoch 195/700\n",
      "7352/7352 [==============================] - 7s 973us/sample - loss: 0.0117 - accuracy: 0.9952 - val_loss: 0.1443 - val_accuracy: 0.9678\n",
      "Epoch 196/700\n",
      "7352/7352 [==============================] - 7s 991us/sample - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.1136 - val_accuracy: 0.9708\n",
      "Epoch 197/700\n",
      "7352/7352 [==============================] - 7s 953us/sample - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.0997 - val_accuracy: 0.9715\n",
      "Epoch 198/700\n",
      "7352/7352 [==============================] - 7s 958us/sample - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.2375 - val_accuracy: 0.9416\n",
      "Epoch 199/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0108 - accuracy: 0.9956 - val_loss: 0.1095 - val_accuracy: 0.9729\n",
      "Epoch 200/700\n",
      "7352/7352 [==============================] - 7s 969us/sample - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.2192 - val_accuracy: 0.9522\n",
      "Epoch 201/700\n",
      "7352/7352 [==============================] - 7s 888us/sample - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.1543 - val_accuracy: 0.9576\n",
      "Epoch 202/700\n",
      "7352/7352 [==============================] - 7s 913us/sample - loss: 0.0128 - accuracy: 0.9963 - val_loss: 0.1096 - val_accuracy: 0.9661\n",
      "Epoch 203/700\n",
      "7352/7352 [==============================] - 7s 937us/sample - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.1432 - val_accuracy: 0.9623\n",
      "Epoch 204/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0120 - accuracy: 0.9956 - val_loss: 0.1290 - val_accuracy: 0.9671\n",
      "Epoch 205/700\n",
      "7352/7352 [==============================] - 7s 946us/sample - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.2497 - val_accuracy: 0.9501\n",
      "Epoch 206/700\n",
      "7352/7352 [==============================] - 7s 988us/sample - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.1255 - val_accuracy: 0.9701\n",
      "Epoch 207/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0121 - accuracy: 0.9952 - val_loss: 0.2050 - val_accuracy: 0.9549\n",
      "Epoch 208/700\n",
      "7352/7352 [==============================] - 7s 927us/sample - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.1407 - val_accuracy: 0.9705\n",
      "Epoch 209/700\n",
      "7352/7352 [==============================] - 7s 922us/sample - loss: 0.0109 - accuracy: 0.9967 - val_loss: 0.0846 - val_accuracy: 0.9779\n",
      "Epoch 210/700\n",
      "7352/7352 [==============================] - 7s 997us/sample - loss: 0.0090 - accuracy: 0.9963 - val_loss: 0.2672 - val_accuracy: 0.9498\n",
      "Epoch 211/700\n",
      "7352/7352 [==============================] - 7s 910us/sample - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.2353 - val_accuracy: 0.9501\n",
      "Epoch 212/700\n",
      "7352/7352 [==============================] - 7s 977us/sample - loss: 0.0125 - accuracy: 0.9954 - val_loss: 0.1410 - val_accuracy: 0.9667\n",
      "Epoch 213/700\n",
      "7352/7352 [==============================] - 7s 923us/sample - loss: 0.0121 - accuracy: 0.9952 - val_loss: 0.1538 - val_accuracy: 0.9657\n",
      "Epoch 214/700\n",
      "7352/7352 [==============================] - 6s 880us/sample - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1508 - val_accuracy: 0.9634\n",
      "Epoch 215/700\n",
      "7352/7352 [==============================] - 7s 889us/sample - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1081 - val_accuracy: 0.9712\n",
      "Epoch 216/700\n",
      "7352/7352 [==============================] - 6s 882us/sample - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.3025 - val_accuracy: 0.9427\n",
      "Epoch 217/700\n",
      "7352/7352 [==============================] - 7s 903us/sample - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.3704 - val_accuracy: 0.9345\n",
      "Epoch 218/700\n",
      "7352/7352 [==============================] - 7s 909us/sample - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.1164 - val_accuracy: 0.9640\n",
      "Epoch 219/700\n",
      "7352/7352 [==============================] - 7s 974us/sample - loss: 0.0152 - accuracy: 0.9942 - val_loss: 0.1868 - val_accuracy: 0.9576\n",
      "Epoch 220/700\n",
      "7352/7352 [==============================] - 7s 963us/sample - loss: 0.0124 - accuracy: 0.9952 - val_loss: 0.3234 - val_accuracy: 0.9342\n",
      "Epoch 221/700\n",
      "7352/7352 [==============================] - 7s 973us/sample - loss: 0.0123 - accuracy: 0.9959 - val_loss: 0.1273 - val_accuracy: 0.9667\n",
      "Epoch 222/700\n",
      "7352/7352 [==============================] - 7s 944us/sample - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.1380 - val_accuracy: 0.9671\n",
      "Epoch 223/700\n",
      "7352/7352 [==============================] - 7s 943us/sample - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.1433 - val_accuracy: 0.9681\n",
      "Epoch 224/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.1933 - val_accuracy: 0.9545\n",
      "Epoch 225/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.2179 - val_accuracy: 0.9488\n",
      "Epoch 226/700\n",
      "7352/7352 [==============================] - 7s 908us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.1993 - val_accuracy: 0.9566\n",
      "Epoch 227/700\n",
      "7352/7352 [==============================] - 7s 918us/sample - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.4747 - val_accuracy: 0.9199\n",
      "Epoch 228/700\n",
      "7352/7352 [==============================] - 7s 897us/sample - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.0984 - val_accuracy: 0.9735\n",
      "Epoch 229/700\n",
      "7352/7352 [==============================] - 7s 932us/sample - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.1199 - val_accuracy: 0.9752\n",
      "Epoch 230/700\n",
      "7352/7352 [==============================] - 7s 891us/sample - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.1675 - val_accuracy: 0.9576\n",
      "Epoch 231/700\n",
      "7352/7352 [==============================] - 7s 933us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.2203 - val_accuracy: 0.9566\n",
      "Epoch 232/700\n",
      "7352/7352 [==============================] - 7s 899us/sample - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.1486 - val_accuracy: 0.9735\n",
      "Epoch 233/700\n",
      "7352/7352 [==============================] - 6s 875us/sample - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.1468 - val_accuracy: 0.9664\n",
      "Epoch 234/700\n",
      "7352/7352 [==============================] - 6s 882us/sample - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.1344 - val_accuracy: 0.9715\n",
      "Epoch 235/700\n",
      "7352/7352 [==============================] - 7s 933us/sample - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.1166 - val_accuracy: 0.9705\n",
      "Epoch 236/700\n",
      "7352/7352 [==============================] - 7s 888us/sample - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.1278 - val_accuracy: 0.9678\n",
      "Epoch 237/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0091 - accuracy: 0.9965 - val_loss: 0.1186 - val_accuracy: 0.9752\n",
      "Epoch 238/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.2145 - val_accuracy: 0.9518\n",
      "Epoch 239/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.2833 - val_accuracy: 0.9423\n",
      "Epoch 240/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.1373 - val_accuracy: 0.9722\n",
      "Epoch 241/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0090 - accuracy: 0.9967 - val_loss: 0.2178 - val_accuracy: 0.9542\n",
      "Epoch 242/700\n",
      "7352/7352 [==============================] - 7s 925us/sample - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.1344 - val_accuracy: 0.9667\n",
      "Epoch 243/700\n",
      "7352/7352 [==============================] - 7s 925us/sample - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.1462 - val_accuracy: 0.9623\n",
      "Epoch 244/700\n",
      "7352/7352 [==============================] - 7s 898us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1538 - val_accuracy: 0.9600\n",
      "Epoch 245/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1897 - val_accuracy: 0.9634\n",
      "Epoch 246/700\n",
      "7352/7352 [==============================] - 7s 905us/sample - loss: 0.0084 - accuracy: 0.9965 - val_loss: 0.1750 - val_accuracy: 0.9681\n",
      "Epoch 247/700\n",
      "7352/7352 [==============================] - 6s 875us/sample - loss: 0.0082 - accuracy: 0.9967 - val_loss: 0.1748 - val_accuracy: 0.9695\n",
      "Epoch 248/700\n",
      "7352/7352 [==============================] - 7s 965us/sample - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.2386 - val_accuracy: 0.9549\n",
      "Epoch 249/700\n",
      "7352/7352 [==============================] - 6s 875us/sample - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.1191 - val_accuracy: 0.9701\n",
      "Epoch 250/700\n",
      "7352/7352 [==============================] - 7s 913us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.1051 - val_accuracy: 0.9691\n",
      "Epoch 251/700\n",
      "7352/7352 [==============================] - 6s 868us/sample - loss: 0.0092 - accuracy: 0.9967 - val_loss: 0.1064 - val_accuracy: 0.9718\n",
      "Epoch 252/700\n",
      "7352/7352 [==============================] - 6s 871us/sample - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1138 - val_accuracy: 0.9705\n",
      "Epoch 253/700\n",
      "7352/7352 [==============================] - 6s 870us/sample - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.1219 - val_accuracy: 0.9722\n",
      "Epoch 254/700\n",
      "7352/7352 [==============================] - 6s 879us/sample - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.2177 - val_accuracy: 0.9535\n",
      "Epoch 255/700\n",
      "7352/7352 [==============================] - 6s 877us/sample - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.1283 - val_accuracy: 0.9644\n",
      "Epoch 256/700\n",
      "7352/7352 [==============================] - 7s 895us/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1149 - val_accuracy: 0.9681\n",
      "Epoch 257/700\n",
      "7352/7352 [==============================] - 7s 901us/sample - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.1667 - val_accuracy: 0.9644\n",
      "Epoch 258/700\n",
      "7352/7352 [==============================] - 7s 895us/sample - loss: 0.0136 - accuracy: 0.9959 - val_loss: 0.3091 - val_accuracy: 0.9359\n",
      "Epoch 259/700\n",
      "7352/7352 [==============================] - 7s 891us/sample - loss: 0.0093 - accuracy: 0.9965 - val_loss: 0.1510 - val_accuracy: 0.9647\n",
      "Epoch 260/700\n",
      "7352/7352 [==============================] - 7s 929us/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1018 - val_accuracy: 0.9725\n",
      "Epoch 261/700\n",
      "7352/7352 [==============================] - 7s 901us/sample - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.4365 - val_accuracy: 0.9260\n",
      "Epoch 262/700\n",
      "7352/7352 [==============================] - 7s 910us/sample - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1062 - val_accuracy: 0.9759\n",
      "Epoch 263/700\n",
      "7352/7352 [==============================] - 6s 880us/sample - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.1131 - val_accuracy: 0.9705\n",
      "Epoch 264/700\n",
      "7352/7352 [==============================] - 6s 869us/sample - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1518 - val_accuracy: 0.9589\n",
      "Epoch 265/700\n",
      "7352/7352 [==============================] - 7s 959us/sample - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.1787 - val_accuracy: 0.9630\n",
      "Epoch 266/700\n",
      "7352/7352 [==============================] - 7s 912us/sample - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.2538 - val_accuracy: 0.9491\n",
      "Epoch 267/700\n",
      "7352/7352 [==============================] - 7s 892us/sample - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.1162 - val_accuracy: 0.9725\n",
      "Epoch 268/700\n",
      "7352/7352 [==============================] - 6s 868us/sample - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.2674 - val_accuracy: 0.9488\n",
      "Epoch 269/700\n",
      "7352/7352 [==============================] - 6s 869us/sample - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.1252 - val_accuracy: 0.9708\n",
      "Epoch 270/700\n",
      "7352/7352 [==============================] - 6s 869us/sample - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.2388 - val_accuracy: 0.9491\n",
      "Epoch 271/700\n",
      "7352/7352 [==============================] - 6s 863us/sample - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.1773 - val_accuracy: 0.9630\n",
      "Epoch 272/700\n",
      "7352/7352 [==============================] - 6s 863us/sample - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.1230 - val_accuracy: 0.9664\n",
      "Epoch 273/700\n",
      "7352/7352 [==============================] - 6s 864us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1098 - val_accuracy: 0.9762\n",
      "Epoch 274/700\n",
      "7352/7352 [==============================] - 7s 905us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.1237 - val_accuracy: 0.9715\n",
      "Epoch 275/700\n",
      "7352/7352 [==============================] - 7s 902us/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1954 - val_accuracy: 0.9603\n",
      "Epoch 276/700\n",
      "7352/7352 [==============================] - 7s 977us/sample - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1010 - val_accuracy: 0.9725\n",
      "Epoch 277/700\n",
      "7352/7352 [==============================] - 7s 905us/sample - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.1546 - val_accuracy: 0.9647\n",
      "Epoch 278/700\n",
      "7352/7352 [==============================] - 7s 947us/sample - loss: 0.0100 - accuracy: 0.9962 - val_loss: 0.1745 - val_accuracy: 0.9613\n",
      "Epoch 279/700\n",
      "7352/7352 [==============================] - 7s 914us/sample - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.1121 - val_accuracy: 0.9708\n",
      "Epoch 280/700\n",
      "7352/7352 [==============================] - 7s 961us/sample - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1310 - val_accuracy: 0.9722\n",
      "Epoch 281/700\n",
      "7352/7352 [==============================] - 7s 972us/sample - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1385 - val_accuracy: 0.9695\n",
      "Epoch 282/700\n",
      "7352/7352 [==============================] - 7s 936us/sample - loss: 0.0060 - accuracy: 0.9977 - val_loss: 0.1121 - val_accuracy: 0.9742\n",
      "Epoch 283/700\n",
      "7352/7352 [==============================] - 7s 973us/sample - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.1019 - val_accuracy: 0.9759\n",
      "Epoch 284/700\n",
      "7352/7352 [==============================] - 7s 932us/sample - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1891 - val_accuracy: 0.9576\n",
      "Epoch 285/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.1347 - val_accuracy: 0.9698\n",
      "Epoch 286/700\n",
      "7352/7352 [==============================] - 7s 893us/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.1114 - val_accuracy: 0.9742\n",
      "Epoch 287/700\n",
      "7352/7352 [==============================] - 7s 885us/sample - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.1431 - val_accuracy: 0.9691\n",
      "Epoch 288/700\n",
      "7352/7352 [==============================] - 7s 902us/sample - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.1103 - val_accuracy: 0.9708\n",
      "Epoch 289/700\n",
      "7352/7352 [==============================] - 7s 885us/sample - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1168 - val_accuracy: 0.9732\n",
      "Epoch 290/700\n",
      "7352/7352 [==============================] - 7s 911us/sample - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1699 - val_accuracy: 0.9589\n",
      "Epoch 291/700\n",
      "7352/7352 [==============================] - 7s 886us/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.1843 - val_accuracy: 0.9559\n",
      "Epoch 292/700\n",
      "7352/7352 [==============================] - 7s 894us/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.1439 - val_accuracy: 0.9671\n",
      "Epoch 293/700\n",
      "7352/7352 [==============================] - 7s 910us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.1323 - val_accuracy: 0.9684\n",
      "Epoch 294/700\n",
      "7352/7352 [==============================] - 7s 977us/sample - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1390 - val_accuracy: 0.9701\n",
      "Epoch 295/700\n",
      "7352/7352 [==============================] - 7s 926us/sample - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1382 - val_accuracy: 0.9698\n",
      "Epoch 296/700\n",
      "7352/7352 [==============================] - 7s 946us/sample - loss: 0.0060 - accuracy: 0.9974 - val_loss: 0.1465 - val_accuracy: 0.9634\n",
      "Epoch 297/700\n",
      "7352/7352 [==============================] - 7s 906us/sample - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.1753 - val_accuracy: 0.9650\n",
      "Epoch 298/700\n",
      "7352/7352 [==============================] - 7s 955us/sample - loss: 0.0038 - accuracy: 0.9984 - val_loss: 0.1272 - val_accuracy: 0.9746\n",
      "Epoch 299/700\n",
      "7352/7352 [==============================] - 7s 992us/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1178 - val_accuracy: 0.9746\n",
      "Epoch 300/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1258 - val_accuracy: 0.9739\n",
      "Epoch 301/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.1790 - val_accuracy: 0.9647\n",
      "Epoch 302/700\n",
      "7352/7352 [==============================] - 7s 910us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.3399 - val_accuracy: 0.9437\n",
      "Epoch 303/700\n",
      "7352/7352 [==============================] - 6s 871us/sample - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.1339 - val_accuracy: 0.9691\n",
      "Epoch 304/700\n",
      "7352/7352 [==============================] - 7s 924us/sample - loss: 0.0081 - accuracy: 0.9977 - val_loss: 0.2624 - val_accuracy: 0.9539\n",
      "Epoch 305/700\n",
      "7352/7352 [==============================] - 6s 879us/sample - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.1910 - val_accuracy: 0.9627\n",
      "Epoch 306/700\n",
      "7352/7352 [==============================] - 6s 878us/sample - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.2946 - val_accuracy: 0.9444\n",
      "Epoch 307/700\n",
      "7352/7352 [==============================] - 6s 877us/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0976 - val_accuracy: 0.9762\n",
      "Epoch 308/700\n",
      "7352/7352 [==============================] - 7s 885us/sample - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1630 - val_accuracy: 0.9678\n",
      "Epoch 309/700\n",
      "7352/7352 [==============================] - 7s 906us/sample - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.1216 - val_accuracy: 0.9735\n",
      "Epoch 310/700\n",
      "7352/7352 [==============================] - 6s 883us/sample - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.1069 - val_accuracy: 0.9756\n",
      "Epoch 311/700\n",
      "7352/7352 [==============================] - 6s 879us/sample - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.1118 - val_accuracy: 0.9739\n",
      "Epoch 312/700\n",
      "7352/7352 [==============================] - 6s 876us/sample - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.1214 - val_accuracy: 0.9718\n",
      "Epoch 313/700\n",
      "7352/7352 [==============================] - 7s 988us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1821 - val_accuracy: 0.9657\n",
      "Epoch 314/700\n",
      "7352/7352 [==============================] - 7s 925us/sample - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.1246 - val_accuracy: 0.9735\n",
      "Epoch 315/700\n",
      "7352/7352 [==============================] - 7s 934us/sample - loss: 0.0055 - accuracy: 0.9985 - val_loss: 0.1791 - val_accuracy: 0.9650\n",
      "Epoch 316/700\n",
      "7352/7352 [==============================] - 7s 970us/sample - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.1047 - val_accuracy: 0.9742\n",
      "Epoch 317/700\n",
      "7352/7352 [==============================] - 7s 950us/sample - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1275 - val_accuracy: 0.9735\n",
      "Epoch 318/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1542 - val_accuracy: 0.9681\n",
      "Epoch 319/700\n",
      "7352/7352 [==============================] - 7s 969us/sample - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.1548 - val_accuracy: 0.9705\n",
      "Epoch 320/700\n",
      "7352/7352 [==============================] - 7s 987us/sample - loss: 0.0051 - accuracy: 0.9982 - val_loss: 0.1144 - val_accuracy: 0.9739\n",
      "Epoch 321/700\n",
      "7352/7352 [==============================] - 7s 921us/sample - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.1295 - val_accuracy: 0.9746\n",
      "Epoch 322/700\n",
      "7352/7352 [==============================] - 7s 913us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.1520 - val_accuracy: 0.9729\n",
      "Epoch 323/700\n",
      "7352/7352 [==============================] - 6s 878us/sample - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.1195 - val_accuracy: 0.9742\n",
      "Epoch 324/700\n",
      "7352/7352 [==============================] - 7s 962us/sample - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.1183 - val_accuracy: 0.9735\n",
      "Epoch 325/700\n",
      "7352/7352 [==============================] - 6s 876us/sample - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.2223 - val_accuracy: 0.9515\n",
      "Epoch 326/700\n",
      "7352/7352 [==============================] - 7s 901us/sample - loss: 0.0057 - accuracy: 0.9976 - val_loss: 0.2108 - val_accuracy: 0.9549\n",
      "Epoch 327/700\n",
      "7352/7352 [==============================] - 6s 880us/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1037 - val_accuracy: 0.9722\n",
      "Epoch 328/700\n",
      "7352/7352 [==============================] - 7s 897us/sample - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.1537 - val_accuracy: 0.9640\n",
      "Epoch 329/700\n",
      "7352/7352 [==============================] - 6s 881us/sample - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.1502 - val_accuracy: 0.9664\n",
      "Epoch 330/700\n",
      "7352/7352 [==============================] - 6s 876us/sample - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.1137 - val_accuracy: 0.9735\n",
      "Epoch 331/700\n",
      "7352/7352 [==============================] - 7s 966us/sample - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1101 - val_accuracy: 0.9752\n",
      "Epoch 332/700\n",
      "7352/7352 [==============================] - 7s 936us/sample - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1352 - val_accuracy: 0.9705\n",
      "Epoch 333/700\n",
      "7352/7352 [==============================] - 7s 914us/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1308 - val_accuracy: 0.9701\n",
      "Epoch 334/700\n",
      "7352/7352 [==============================] - 7s 957us/sample - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.1208 - val_accuracy: 0.9735\n",
      "Epoch 335/700\n",
      "7352/7352 [==============================] - 7s 956us/sample - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.1253 - val_accuracy: 0.9722\n",
      "Epoch 336/700\n",
      "7352/7352 [==============================] - 7s 974us/sample - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.1236 - val_accuracy: 0.9715\n",
      "Epoch 337/700\n",
      "7352/7352 [==============================] - 7s 932us/sample - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.1458 - val_accuracy: 0.9650\n",
      "Epoch 338/700\n",
      "7352/7352 [==============================] - 7s 973us/sample - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.1152 - val_accuracy: 0.9729\n",
      "Epoch 339/700\n",
      "7352/7352 [==============================] - 7s 948us/sample - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.1261 - val_accuracy: 0.9684\n",
      "Epoch 340/700\n",
      "7352/7352 [==============================] - 7s 944us/sample - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.1215 - val_accuracy: 0.9732\n",
      "Epoch 341/700\n",
      "7352/7352 [==============================] - 6s 874us/sample - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.1179 - val_accuracy: 0.9732\n",
      "Epoch 342/700\n",
      "7352/7352 [==============================] - 7s 907us/sample - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.1749 - val_accuracy: 0.9664\n",
      "Epoch 343/700\n",
      "7352/7352 [==============================] - 7s 926us/sample - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.1526 - val_accuracy: 0.9695\n",
      "Epoch 344/700\n",
      "7352/7352 [==============================] - 7s 979us/sample - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1504 - val_accuracy: 0.9695\n",
      "Epoch 345/700\n",
      "7352/7352 [==============================] - 7s 930us/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.2199 - val_accuracy: 0.9606\n",
      "Epoch 346/700\n",
      "7352/7352 [==============================] - 7s 950us/sample - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.1257 - val_accuracy: 0.9729\n",
      "Epoch 347/700\n",
      "7352/7352 [==============================] - 7s 935us/sample - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1039 - val_accuracy: 0.9762\n",
      "Epoch 348/700\n",
      "7352/7352 [==============================] - 6s 874us/sample - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.1130 - val_accuracy: 0.9742\n",
      "Epoch 349/700\n",
      "7352/7352 [==============================] - 7s 902us/sample - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.1145 - val_accuracy: 0.9739\n",
      "Epoch 350/700\n",
      "7352/7352 [==============================] - 6s 868us/sample - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1400 - val_accuracy: 0.9729\n",
      "Epoch 351/700\n",
      "7352/7352 [==============================] - 6s 872us/sample - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.3295 - val_accuracy: 0.9576\n",
      "Epoch 352/700\n",
      "7352/7352 [==============================] - 7s 905us/sample - loss: 0.0097 - accuracy: 0.9970 - val_loss: 0.1841 - val_accuracy: 0.9654\n",
      "Epoch 353/700\n",
      "7352/7352 [==============================] - 7s 888us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.1918 - val_accuracy: 0.9667\n",
      "Epoch 354/700\n",
      "7352/7352 [==============================] - 6s 880us/sample - loss: 0.0051 - accuracy: 0.9980 - val_loss: 0.1941 - val_accuracy: 0.9627\n",
      "Epoch 355/700\n",
      "7352/7352 [==============================] - 6s 882us/sample - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.1492 - val_accuracy: 0.9712\n",
      "Epoch 356/700\n",
      "7352/7352 [==============================] - 6s 878us/sample - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.3597 - val_accuracy: 0.9420\n",
      "Epoch 357/700\n",
      "7352/7352 [==============================] - 7s 938us/sample - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.1366 - val_accuracy: 0.9688\n",
      "Epoch 358/700\n",
      "7352/7352 [==============================] - 7s 975us/sample - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.1363 - val_accuracy: 0.9708\n",
      "Epoch 359/700\n",
      "7352/7352 [==============================] - 6s 883us/sample - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1509 - val_accuracy: 0.9681\n",
      "Epoch 360/700\n",
      "7352/7352 [==============================] - 7s 911us/sample - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.2538 - val_accuracy: 0.9525\n",
      "Epoch 361/700\n",
      "7352/7352 [==============================] - 7s 888us/sample - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.1437 - val_accuracy: 0.9718\n",
      "Epoch 362/700\n",
      "7352/7352 [==============================] - 7s 902us/sample - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.2540 - val_accuracy: 0.9566\n",
      "Epoch 363/700\n",
      "7352/7352 [==============================] - 7s 887us/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1193 - val_accuracy: 0.9735\n",
      "Epoch 364/700\n",
      "7352/7352 [==============================] - 6s 882us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1320 - val_accuracy: 0.9729\n",
      "Epoch 365/700\n",
      "7352/7352 [==============================] - 6s 867us/sample - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.2216 - val_accuracy: 0.9555\n",
      "Epoch 366/700\n",
      "7352/7352 [==============================] - 6s 872us/sample - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1095 - val_accuracy: 0.9776\n",
      "Epoch 367/700\n",
      "7352/7352 [==============================] - 7s 910us/sample - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.1138 - val_accuracy: 0.9776\n",
      "Epoch 368/700\n",
      "7352/7352 [==============================] - 6s 877us/sample - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.1554 - val_accuracy: 0.9722\n",
      "Epoch 369/700\n",
      "7352/7352 [==============================] - 7s 903us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1679 - val_accuracy: 0.9681\n",
      "Epoch 370/700\n",
      "7352/7352 [==============================] - 6s 881us/sample - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.3137 - val_accuracy: 0.9460\n",
      "Epoch 371/700\n",
      "7352/7352 [==============================] - 6s 879us/sample - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.2147 - val_accuracy: 0.9583\n",
      "Epoch 372/700\n",
      "7352/7352 [==============================] - 7s 936us/sample - loss: 0.0036 - accuracy: 0.9984 - val_loss: 0.1781 - val_accuracy: 0.9600\n",
      "Epoch 373/700\n",
      "7352/7352 [==============================] - 7s 913us/sample - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.1330 - val_accuracy: 0.9739\n",
      "Epoch 374/700\n",
      "7352/7352 [==============================] - 7s 959us/sample - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.5182 - val_accuracy: 0.9287\n",
      "Epoch 375/700\n",
      "7352/7352 [==============================] - 7s 885us/sample - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.1557 - val_accuracy: 0.9627\n",
      "Epoch 376/700\n",
      "7352/7352 [==============================] - 7s 938us/sample - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.1715 - val_accuracy: 0.9657\n",
      "Epoch 377/700\n",
      "7352/7352 [==============================] - 7s 901us/sample - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1254 - val_accuracy: 0.9746\n",
      "Epoch 378/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1583 - val_accuracy: 0.9698\n",
      "Epoch 379/700\n",
      "7352/7352 [==============================] - 7s 958us/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1597 - val_accuracy: 0.9708\n",
      "Epoch 380/700\n",
      "7352/7352 [==============================] - 7s 950us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.1716 - val_accuracy: 0.9684\n",
      "Epoch 381/700\n",
      "7352/7352 [==============================] - 7s 936us/sample - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.1503 - val_accuracy: 0.9718\n",
      "Epoch 382/700\n",
      "7352/7352 [==============================] - 7s 931us/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1492 - val_accuracy: 0.9718\n",
      "Epoch 383/700\n",
      "7352/7352 [==============================] - 7s 895us/sample - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.2995 - val_accuracy: 0.9440\n",
      "Epoch 384/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0043 - accuracy: 0.9982 - val_loss: 0.3089 - val_accuracy: 0.9420\n",
      "Epoch 385/700\n",
      "7352/7352 [==============================] - 7s 906us/sample - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1333 - val_accuracy: 0.9749\n",
      "Epoch 386/700\n",
      "7352/7352 [==============================] - 6s 880us/sample - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.1360 - val_accuracy: 0.9701\n",
      "Epoch 387/700\n",
      "7352/7352 [==============================] - 6s 874us/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.2578 - val_accuracy: 0.9505\n",
      "Epoch 388/700\n",
      "7352/7352 [==============================] - 7s 886us/sample - loss: 0.0044 - accuracy: 0.9981 - val_loss: 0.1632 - val_accuracy: 0.9688\n",
      "Epoch 389/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.1222 - val_accuracy: 0.9735\n",
      "Epoch 390/700\n",
      "7352/7352 [==============================] - 7s 1ms/sample - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1195 - val_accuracy: 0.9718\n",
      "Epoch 391/700\n",
      "7352/7352 [==============================] - 7s 926us/sample - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.1404 - val_accuracy: 0.9739\n",
      "Epoch 392/700\n",
      "7352/7352 [==============================] - 7s 952us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.1633 - val_accuracy: 0.9684\n",
      "Epoch 393/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.1318 - val_accuracy: 0.9712\n",
      "Epoch 394/700\n",
      "7352/7352 [==============================] - 7s 958us/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1115 - val_accuracy: 0.9725\n",
      "Epoch 395/700\n",
      "7352/7352 [==============================] - 9s 1ms/sample - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1273 - val_accuracy: 0.9698\n",
      "Epoch 396/700\n",
      "3550/7352 [=============>................] - ETA: 3s - loss: 0.0031 - accuracy: 0.9994 ETA: 4s - loss: 0.0033 - accura"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6f2c3809d332>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    172\u001b[0m                                   patience=20, min_lr=0.00005)\n\u001b[0;32m    173\u001b[0m     hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n\u001b[1;32m--> 174\u001b[1;33m                      verbose=1, validation_data=(x_val, y_val), callbacks=[reduce_lr])  # 回调函数会在训练的时候适当被调用\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\programdata\\anaconda3\\envs\\tf20\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import csv\n",
    "import tempfile\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.keras import backend as K\n",
    "from utils.utilities import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(813306)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allocator_type = 'BFC'  # A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "#config.gpu_options.allow_growth = True\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "#构建数据集 channel_last\n",
    "#构建数据集 channel_last\n",
    "def load_data():    \n",
    "    X_train, labels_train, list_ch_train = read_data(data_path=\"../data/HAR_Dataset\", split=\"train\") # train\n",
    "    X_test, labels_test, list_ch_test = read_data(data_path=\"../data/HAR_Dataset\", split=\"test\") # test\n",
    "    assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "    x_train = X_train[:,:,np.newaxis,:]\n",
    "    x_val = X_test[:,:,np.newaxis,:]\n",
    "    y_train = to_categorical(labels_train)\n",
    "    y_val = to_categorical(labels_test)\n",
    "    return (x_train,y_train),(x_val,y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_resnet(input_shape, n_feature_maps, nb_classes, dropout):\n",
    "    print('build conv_x')\n",
    "    x = Input(shape=(input_shape))\n",
    "    x_total = []\n",
    "    for i in range(input_shape[-1]):\n",
    "        x_temp = Reshape((input_shape[0],1,1))(x[:,:,:,i])\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(3, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(32, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(3, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "#         x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "#         x_temp = keras.layers.AveragePooling2D(pool_size=(3, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "#         x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "#         x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "#         x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "#         x_temp = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "#         x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "#         x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(1, (8, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        \n",
    "        \n",
    "        x_total.append(x_temp)\n",
    "\n",
    "    \n",
    "    x_total = K.concatenate(x_total , axis=-1)\n",
    "    conv_x = keras.layers.BatchNormalization()(x_total)  # 853\n",
    "    \n",
    "    # channel attention here\n",
    "    '''\n",
    "    x = keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = keras.layers.Dense(int(x.shape[-1]) // self.reduction, use_bias=False,activation=keras.activations.relu)(x)\n",
    "    x = keras.layers.Dense(int(inputs.shape[-1]), use_bias=False,activation=keras.activations.hard_sigmoid)(x)\n",
    "    x = keras.layers.Multiply()([inputs,x])\n",
    "    '''\n",
    " \n",
    "    conv_x = keras.layers.Conv2D(n_feature_maps, (16, 1), padding='same')(conv_x)  # input size == ouput size\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    print('build conv_y')\n",
    "    conv_y = keras.layers.Conv2D(n_feature_maps * 2, (16, 1), padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "\n",
    "    conv_y = Dropout(dropout)(conv_y)\n",
    "    '''\n",
    "    print('build conv_z')\n",
    "    conv_z = keras.layers.Conv2D(n_feature_maps, (8, 1), padding='same')(conv_x)\n",
    "    #conv_z = keras.layers.BatchNormalization()(conv_x)\n",
    "\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps)  # 若当前输出和跨层连接的x，通道数不同，则采用1*1卷积使得通道数相同\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = keras.layers.Conv2D(n_feature_maps, (1, 1), padding='same')(x_total)\n",
    "        #shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = x_total#keras.layers.BatchNormalization()(x_total)\n",
    "\n",
    "    #print('Merging skip connection')\n",
    "    # y = merge([shortcut_y, conv_z], mode='sum')\n",
    "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
    "    y = keras.layers.BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "\n",
    "    full = keras.layers.GlobalAveragePooling2D()(y)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    print('        -- model was built.')\n",
    "    return x, out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = 6\n",
    "    channels = 9\n",
    "    dropout = 0.2\n",
    "    nb_epochs = 700\n",
    "    batch_size = 50\n",
    "    data_row = 128\n",
    "    data_column = 1\n",
    "    trainpath = r'./data'\n",
    "\n",
    "    (x_train,y_train),(x_val,y_val) = load_data()\n",
    "\n",
    "\n",
    "    tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "    input_shape = (data_row, data_column,channels)\n",
    "\n",
    "    print('train dataset size:',x_train.shape[0])\n",
    "    print('validation dataset size:',x_val.shape[0])\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    x, y = build_resnet(input_shape, 64, num, dropout)  # 建立resnet只考虑了单个example\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.9,\n",
    "                                  patience=20, min_lr=0.00005)\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n",
    "                     verbose=1, validation_data=(x_val, y_val), callbacks=[reduce_lr])  # 回调函数会在训练的时候适当被调用\n",
    "\n",
    "\n",
    "    # 测试\n",
    "    print(\"------------------------ 测试中---------------------------\")\n",
    "    #evaluation of the model\n",
    "    scores = model.evaluate(x_val,y_val)\n",
    "    print('Baseline Error: %.2f%%'%(100 * (1 - scores[1])))\n",
    "    keras.models.save_model(model, '../model/test_resnet_v4.h5')\n",
    "    keras_file = '../model/test_resnet_v4.h5'\n",
    "    _, zip1 = tempfile.mkstemp('.zip') \n",
    "    with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(keras_file)\n",
    "    print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "          (os.path.getsize(keras_file) / float(2**20)))\n",
    "    print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "          (os.path.getsize(zip1) / float(2**20)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3-6 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 7352\n",
      "validation dataset size: 2947\n",
      "build conv_x\n",
      "build conv_y\n",
      "build conv_z\n",
      "Merging skip connection\n",
      "        -- model was built.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 1, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 128, 1, 10)   520         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 1, 10)   40          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 1, 64)   10944       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 1, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 1, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 1, 128)  139392      activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 1, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 1, 128)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 1, 128)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 1, 64)   704         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 1, 64)   73792       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 1, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 1, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 1, 64)   0           batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 1, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 7)            455         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 227,127\n",
      "Trainable params: 226,467\n",
      "Non-trainable params: 660\n",
      "__________________________________________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/700\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001600415A620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x000001600415A620> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "7352/7352 [==============================] - 6s 811us/sample - loss: 0.7684 - accuracy: 0.6342 - val_loss: 1.1706 - val_accuracy: 0.4710\n",
      "Epoch 2/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.6072 - accuracy: 0.6956 - val_loss: 0.6924 - val_accuracy: 0.6868\n",
      "Epoch 3/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.5471 - accuracy: 0.7274 - val_loss: 0.7009 - val_accuracy: 0.6400\n",
      "Epoch 4/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.5363 - accuracy: 0.7459 - val_loss: 0.7184 - val_accuracy: 0.7499\n",
      "Epoch 5/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.5043 - accuracy: 0.7684 - val_loss: 0.6138 - val_accuracy: 0.7343\n",
      "Epoch 6/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.4874 - accuracy: 0.7798 - val_loss: 0.6001 - val_accuracy: 0.7618\n",
      "Epoch 7/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.4698 - accuracy: 0.7873 - val_loss: 0.5884 - val_accuracy: 0.7180\n",
      "Epoch 8/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.4833 - accuracy: 0.7862 - val_loss: 0.5525 - val_accuracy: 0.7628\n",
      "Epoch 9/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.4470 - accuracy: 0.7969 - val_loss: 0.7207 - val_accuracy: 0.7513\n",
      "Epoch 10/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.4632 - accuracy: 0.7913 - val_loss: 0.6157 - val_accuracy: 0.7336\n",
      "Epoch 11/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.4351 - accuracy: 0.8105 - val_loss: 0.5841 - val_accuracy: 0.7530\n",
      "Epoch 12/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.4206 - accuracy: 0.8128 - val_loss: 0.8513 - val_accuracy: 0.7170\n",
      "Epoch 13/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.4445 - accuracy: 0.7990 - val_loss: 0.6624 - val_accuracy: 0.7475\n",
      "Epoch 14/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.4320 - accuracy: 0.8101 - val_loss: 0.5441 - val_accuracy: 0.7927\n",
      "Epoch 15/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.4036 - accuracy: 0.8248 - val_loss: 0.6012 - val_accuracy: 0.7743\n",
      "Epoch 16/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.4243 - accuracy: 0.8166 - val_loss: 0.6983 - val_accuracy: 0.6732\n",
      "Epoch 17/700\n",
      "7352/7352 [==============================] - 3s 343us/sample - loss: 0.3864 - accuracy: 0.8358 - val_loss: 0.5218 - val_accuracy: 0.8001\n",
      "Epoch 18/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.3886 - accuracy: 0.8349 - val_loss: 0.6512 - val_accuracy: 0.7723\n",
      "Epoch 19/700\n",
      "7352/7352 [==============================] - 3s 345us/sample - loss: 0.3784 - accuracy: 0.8387 - val_loss: 0.5294 - val_accuracy: 0.8008\n",
      "Epoch 20/700\n",
      "7352/7352 [==============================] - 3s 341us/sample - loss: 0.3817 - accuracy: 0.8365 - val_loss: 0.7643 - val_accuracy: 0.7536\n",
      "Epoch 21/700\n",
      "7352/7352 [==============================] - 3s 344us/sample - loss: 0.3590 - accuracy: 0.8464 - val_loss: 0.5488 - val_accuracy: 0.7883\n",
      "Epoch 22/700\n",
      "7352/7352 [==============================] - 3s 343us/sample - loss: 0.3879 - accuracy: 0.8399 - val_loss: 0.5665 - val_accuracy: 0.7710\n",
      "Epoch 23/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.3815 - accuracy: 0.8364 - val_loss: 0.9614 - val_accuracy: 0.6854\n",
      "Epoch 24/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.3547 - accuracy: 0.8504 - val_loss: 0.5016 - val_accuracy: 0.7978oss: 0.3541 \n",
      "Epoch 25/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.3406 - accuracy: 0.8610 - val_loss: 0.5003 - val_accuracy: 0.7947\n",
      "Epoch 26/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.3399 - accuracy: 0.8591 - val_loss: 0.6511 - val_accuracy: 0.7815\n",
      "Epoch 27/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.3389 - accuracy: 0.8581 - val_loss: 0.6275 - val_accuracy: 0.7652\n",
      "Epoch 28/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.3309 - accuracy: 0.8599 - val_loss: 0.6123 - val_accuracy: 0.7723\n",
      "Epoch 29/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.3400 - accuracy: 0.8557 - val_loss: 0.5895 - val_accuracy: 0.7862\n",
      "Epoch 30/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.3125 - accuracy: 0.8734 - val_loss: 0.5400 - val_accuracy: 0.7842\n",
      "Epoch 31/700\n",
      "7352/7352 [==============================] - 2s 339us/sample - loss: 0.3114 - accuracy: 0.8730 - val_loss: 0.6368 - val_accuracy: 0.7842\n",
      "Epoch 32/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.3238 - accuracy: 0.8656 - val_loss: 0.4749 - val_accuracy: 0.8076\n",
      "Epoch 33/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.3048 - accuracy: 0.8753 - val_loss: 0.4900 - val_accuracy: 0.7964\n",
      "Epoch 34/700\n",
      "7352/7352 [==============================] - 3s 350us/sample - loss: 0.2894 - accuracy: 0.8814 - val_loss: 0.4097 - val_accuracy: 0.8453\n",
      "Epoch 35/700\n",
      "7352/7352 [==============================] - 3s 349us/sample - loss: 0.2827 - accuracy: 0.8874 - val_loss: 0.4383 - val_accuracy: 0.8429\n",
      "Epoch 36/700\n",
      "7352/7352 [==============================] - 3s 348us/sample - loss: 0.2873 - accuracy: 0.8832 - val_loss: 0.4582 - val_accuracy: 0.8212\n",
      "Epoch 37/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.2969 - accuracy: 0.8779 - val_loss: 0.8937 - val_accuracy: 0.7679\n",
      "Epoch 38/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.2851 - accuracy: 0.8855 - val_loss: 0.3959 - val_accuracy: 0.8337\n",
      "Epoch 39/700\n",
      "7352/7352 [==============================] - 3s 346us/sample - loss: 0.2896 - accuracy: 0.8836 - val_loss: 0.5451 - val_accuracy: 0.8062\n",
      "Epoch 40/700\n",
      "7352/7352 [==============================] - 2s 337us/sample - loss: 0.2818 - accuracy: 0.8860 - val_loss: 0.5570 - val_accuracy: 0.7995\n",
      "Epoch 41/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.2727 - accuracy: 0.8900 - val_loss: 0.4720 - val_accuracy: 0.8276\n",
      "Epoch 42/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.2676 - accuracy: 0.8946 - val_loss: 0.4208 - val_accuracy: 0.8456\n",
      "Epoch 43/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.2625 - accuracy: 0.8965 - val_loss: 0.5187 - val_accuracy: 0.8066\n",
      "Epoch 44/700\n",
      "7352/7352 [==============================] - 3s 358us/sample - loss: 0.2614 - accuracy: 0.8942 - val_loss: 1.4302 - val_accuracy: 0.6851\n",
      "Epoch 45/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.2727 - accuracy: 0.8908 - val_loss: 0.6006 - val_accuracy: 0.7879\n",
      "Epoch 46/700\n",
      "7352/7352 [==============================] - 3s 344us/sample - loss: 0.2691 - accuracy: 0.8924 - val_loss: 0.4025 - val_accuracy: 0.8459\n",
      "Epoch 47/700\n",
      "7352/7352 [==============================] - 2s 340us/sample - loss: 0.2507 - accuracy: 0.9015 - val_loss: 0.4294 - val_accuracy: 0.8283\n",
      "Epoch 48/700\n",
      "7352/7352 [==============================] - 3s 348us/sample - loss: 0.2540 - accuracy: 0.8991 - val_loss: 0.6404 - val_accuracy: 0.7458\n",
      "Epoch 49/700\n",
      "7352/7352 [==============================] - 3s 343us/sample - loss: 0.2545 - accuracy: 0.8969 - val_loss: 0.5619 - val_accuracy: 0.7828\n",
      "Epoch 50/700\n",
      "7352/7352 [==============================] - 2s 335us/sample - loss: 0.3272 - accuracy: 0.8681 - val_loss: 1.0726 - val_accuracy: 0.7553\n",
      "Epoch 51/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.2745 - accuracy: 0.8909 - val_loss: 0.6002 - val_accuracy: 0.7699\n",
      "Epoch 52/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.2553 - accuracy: 0.8977 - val_loss: 0.3766 - val_accuracy: 0.8517\n",
      "Epoch 53/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.2573 - accuracy: 0.9021 - val_loss: 0.5945 - val_accuracy: 0.7978\n",
      "Epoch 54/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.2430 - accuracy: 0.9010 - val_loss: 0.6295 - val_accuracy: 0.7723\n",
      "Epoch 55/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2475 - accuracy: 0.9021 - val_loss: 0.5411 - val_accuracy: 0.7883\n",
      "Epoch 56/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.2398 - accuracy: 0.9066 - val_loss: 0.4919 - val_accuracy: 0.8171\n",
      "Epoch 57/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2350 - accuracy: 0.9067 - val_loss: 0.6925 - val_accuracy: 0.7598\n",
      "Epoch 58/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.2546 - accuracy: 0.8984 - val_loss: 0.4956 - val_accuracy: 0.8140\n",
      "Epoch 59/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2344 - accuracy: 0.9083 - val_loss: 0.3738 - val_accuracy: 0.8551\n",
      "Epoch 60/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.2359 - accuracy: 0.9060 - val_loss: 0.4879 - val_accuracy: 0.8205\n",
      "Epoch 61/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.2333 - accuracy: 0.9081 - val_loss: 0.5911 - val_accuracy: 0.7781\n",
      "Epoch 62/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.2274 - accuracy: 0.9105 - val_loss: 0.3833 - val_accuracy: 0.8605\n",
      "Epoch 63/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.2245 - accuracy: 0.9138 - val_loss: 0.4144 - val_accuracy: 0.8514\n",
      "Epoch 64/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.2395 - accuracy: 0.9051 - val_loss: 0.9728 - val_accuracy: 0.7693\n",
      "Epoch 65/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2422 - accuracy: 0.9030 - val_loss: 0.5944 - val_accuracy: 0.7740\n",
      "Epoch 66/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2412 - accuracy: 0.9082 - val_loss: 0.4186 - val_accuracy: 0.8514\n",
      "Epoch 67/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2268 - accuracy: 0.9086 - val_loss: 0.4412 - val_accuracy: 0.8490\n",
      "Epoch 68/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2142 - accuracy: 0.9185 - val_loss: 0.4161 - val_accuracy: 0.8449\n",
      "Epoch 69/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.2100 - accuracy: 0.9153 - val_loss: 0.3782 - val_accuracy: 0.8510\n",
      "Epoch 70/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2095 - accuracy: 0.9187 - val_loss: 0.7049 - val_accuracy: 0.7750\n",
      "Epoch 71/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2304 - accuracy: 0.9085 - val_loss: 0.6221 - val_accuracy: 0.7750\n",
      "Epoch 72/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.2081 - accuracy: 0.9157 - val_loss: 0.5416 - val_accuracy: 0.8124\n",
      "Epoch 73/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2094 - accuracy: 0.9183 - val_loss: 0.4931 - val_accuracy: 0.8239\n",
      "Epoch 74/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.2009 - accuracy: 0.9217 - val_loss: 0.6148 - val_accuracy: 0.7845\n",
      "Epoch 75/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.2125 - accuracy: 0.9172 - val_loss: 0.9503 - val_accuracy: 0.7496\n",
      "Epoch 76/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1958 - accuracy: 0.9242 - val_loss: 0.4398 - val_accuracy: 0.8276\n",
      "Epoch 77/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.2286 - accuracy: 0.9116 - val_loss: 0.8964 - val_accuracy: 0.7642\n",
      "Epoch 78/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1977 - accuracy: 0.9202 - val_loss: 0.4225 - val_accuracy: 0.8412\n",
      "Epoch 79/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.2217 - accuracy: 0.9113 - val_loss: 1.0415 - val_accuracy: 0.7438\n",
      "Epoch 80/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.2249 - accuracy: 0.9110 - val_loss: 0.4022 - val_accuracy: 0.8456\n",
      "Epoch 81/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.2077 - accuracy: 0.9200 - val_loss: 0.4163 - val_accuracy: 0.8293\n",
      "Epoch 82/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1884 - accuracy: 0.9291 - val_loss: 0.6822 - val_accuracy: 0.7676\n",
      "Epoch 83/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1923 - accuracy: 0.9242 - val_loss: 0.3643 - val_accuracy: 0.8568\n",
      "Epoch 84/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1975 - accuracy: 0.9204 - val_loss: 0.5703 - val_accuracy: 0.7954\n",
      "Epoch 85/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1964 - accuracy: 0.9233 - val_loss: 0.3607 - val_accuracy: 0.8595\n",
      "Epoch 86/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1957 - accuracy: 0.9263 - val_loss: 0.9284 - val_accuracy: 0.7669\n",
      "Epoch 87/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1899 - accuracy: 0.9295 - val_loss: 0.3549 - val_accuracy: 0.8578\n",
      "Epoch 88/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1944 - accuracy: 0.9230 - val_loss: 0.5068 - val_accuracy: 0.8364\n",
      "Epoch 89/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1862 - accuracy: 0.9246 - val_loss: 0.3818 - val_accuracy: 0.8524\n",
      "Epoch 90/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1899 - accuracy: 0.9240 - val_loss: 0.4818 - val_accuracy: 0.8368\n",
      "Epoch 91/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.2004 - accuracy: 0.9218 - val_loss: 0.6694 - val_accuracy: 0.7984\n",
      "Epoch 92/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1860 - accuracy: 0.9261 - val_loss: 0.4508 - val_accuracy: 0.8358\n",
      "Epoch 93/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.2009 - accuracy: 0.9207 - val_loss: 0.4461 - val_accuracy: 0.8429\n",
      "Epoch 94/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.2043 - accuracy: 0.9212 - val_loss: 0.7572 - val_accuracy: 0.7509\n",
      "Epoch 95/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2013 - accuracy: 0.9189 - val_loss: 0.9859 - val_accuracy: 0.7621\n",
      "Epoch 96/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1837 - accuracy: 0.9293 - val_loss: 0.4183 - val_accuracy: 0.8561\n",
      "Epoch 97/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1819 - accuracy: 0.9261 - val_loss: 0.6460 - val_accuracy: 0.7896\n",
      "Epoch 98/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1869 - accuracy: 0.9245 - val_loss: 0.5549 - val_accuracy: 0.8073\n",
      "Epoch 99/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1834 - accuracy: 0.9245 - val_loss: 0.4774 - val_accuracy: 0.8222\n",
      "Epoch 100/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1967 - accuracy: 0.9252 - val_loss: 0.4027 - val_accuracy: 0.8599\n",
      "Epoch 101/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.2239 - accuracy: 0.9138 - val_loss: 0.4064 - val_accuracy: 0.8395\n",
      "Epoch 102/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1908 - accuracy: 0.9237 - val_loss: 0.4171 - val_accuracy: 0.8510\n",
      "Epoch 103/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2074 - accuracy: 0.9184 - val_loss: 0.5844 - val_accuracy: 0.7883\n",
      "Epoch 104/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2236 - accuracy: 0.9142 - val_loss: 0.4008 - val_accuracy: 0.8619\n",
      "Epoch 105/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2095 - accuracy: 0.9183 - val_loss: 1.1832 - val_accuracy: 0.7133\n",
      "Epoch 106/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1824 - accuracy: 0.9300 - val_loss: 0.3714 - val_accuracy: 0.8626\n",
      "Epoch 107/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1742 - accuracy: 0.9343 - val_loss: 0.6162 - val_accuracy: 0.8056\n",
      "Epoch 108/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.2335 - accuracy: 0.9071 - val_loss: 0.4010 - val_accuracy: 0.8476\n",
      "Epoch 109/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1962 - accuracy: 0.9252 - val_loss: 0.4964 - val_accuracy: 0.8354\n",
      "Epoch 110/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1826 - accuracy: 0.9282 - val_loss: 0.4490 - val_accuracy: 0.8378\n",
      "Epoch 111/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1794 - accuracy: 0.9295 - val_loss: 0.5611 - val_accuracy: 0.8168\n",
      "Epoch 112/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1972 - accuracy: 0.9242 - val_loss: 0.5510 - val_accuracy: 0.8208\n",
      "Epoch 113/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1898 - accuracy: 0.9249 - val_loss: 0.8120 - val_accuracy: 0.7937\n",
      "Epoch 114/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1749 - accuracy: 0.9302 - val_loss: 0.4095 - val_accuracy: 0.8551\n",
      "Epoch 115/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.2414 - accuracy: 0.9078 - val_loss: 0.7297 - val_accuracy: 0.7988\n",
      "Epoch 116/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1972 - accuracy: 0.9214 - val_loss: 0.6307 - val_accuracy: 0.7940\n",
      "Epoch 117/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.2951 - accuracy: 0.8900 - val_loss: 0.4454 - val_accuracy: 0.8493\n",
      "Epoch 118/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2160 - accuracy: 0.9151 - val_loss: 0.9992 - val_accuracy: 0.7401\n",
      "Epoch 119/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1941 - accuracy: 0.9266 - val_loss: 0.4891 - val_accuracy: 0.8157\n",
      "Epoch 120/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1847 - accuracy: 0.9270 - val_loss: 0.4297 - val_accuracy: 0.8276\n",
      "Epoch 121/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1884 - accuracy: 0.9260 - val_loss: 0.7454 - val_accuracy: 0.7679\n",
      "Epoch 122/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2167 - accuracy: 0.9195 - val_loss: 0.4548 - val_accuracy: 0.8273\n",
      "Epoch 123/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1851 - accuracy: 0.9289 - val_loss: 0.5889 - val_accuracy: 0.7849\n",
      "Epoch 124/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1749 - accuracy: 0.9358 - val_loss: 0.5837 - val_accuracy: 0.8144\n",
      "Epoch 125/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1660 - accuracy: 0.9339 - val_loss: 0.5160 - val_accuracy: 0.8232\n",
      "Epoch 126/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1666 - accuracy: 0.9362 - val_loss: 0.4391 - val_accuracy: 0.8490\n",
      "Epoch 127/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1748 - accuracy: 0.9304 - val_loss: 0.4205 - val_accuracy: 0.8585\n",
      "Epoch 128/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1723 - accuracy: 0.9369 - val_loss: 0.4126 - val_accuracy: 0.8575\n",
      "Epoch 129/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1753 - accuracy: 0.9344 - val_loss: 0.4244 - val_accuracy: 0.8527\n",
      "Epoch 130/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1600 - accuracy: 0.9382 - val_loss: 0.4734 - val_accuracy: 0.8331\n",
      "Epoch 131/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1629 - accuracy: 0.9361 - val_loss: 1.4250 - val_accuracy: 0.6807\n",
      "Epoch 132/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.1714 - accuracy: 0.9327 - val_loss: 0.5224 - val_accuracy: 0.8286\n",
      "Epoch 133/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1620 - accuracy: 0.9381 - val_loss: 1.2101 - val_accuracy: 0.7353\n",
      "Epoch 134/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1730 - accuracy: 0.9327 - val_loss: 0.5858 - val_accuracy: 0.8093\n",
      "Epoch 135/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1576 - accuracy: 0.9395 - val_loss: 0.5157 - val_accuracy: 0.8174\n",
      "Epoch 136/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1588 - accuracy: 0.9377 - val_loss: 1.1172 - val_accuracy: 0.7255\n",
      "Epoch 137/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.2268 - accuracy: 0.9093 - val_loss: 0.7875 - val_accuracy: 0.7526\n",
      "Epoch 138/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1683 - accuracy: 0.9357 - val_loss: 0.6921 - val_accuracy: 0.7862\n",
      "Epoch 139/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1775 - accuracy: 0.9320 - val_loss: 1.1980 - val_accuracy: 0.7051\n",
      "Epoch 140/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1661 - accuracy: 0.9336 - val_loss: 0.8289 - val_accuracy: 0.7923\n",
      "Epoch 141/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1738 - accuracy: 0.9309 - val_loss: 0.7031 - val_accuracy: 0.7743\n",
      "Epoch 142/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1680 - accuracy: 0.9327 - val_loss: 1.1880 - val_accuracy: 0.7397\n",
      "Epoch 143/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1597 - accuracy: 0.9374 - val_loss: 0.6162 - val_accuracy: 0.8073\n",
      "Epoch 144/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1612 - accuracy: 0.9400 - val_loss: 0.5107 - val_accuracy: 0.8429\n",
      "Epoch 145/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.1662 - accuracy: 0.9369 - val_loss: 0.8283 - val_accuracy: 0.7981\n",
      "Epoch 146/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1531 - accuracy: 0.9425 - val_loss: 1.0674 - val_accuracy: 0.7306\n",
      "Epoch 147/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.2091 - accuracy: 0.9187 - val_loss: 0.4893 - val_accuracy: 0.8300\n",
      "Epoch 148/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1627 - accuracy: 0.9347 - val_loss: 0.6510 - val_accuracy: 0.7967\n",
      "Epoch 149/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1799 - accuracy: 0.9306 - val_loss: 0.4709 - val_accuracy: 0.8388\n",
      "Epoch 150/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.2587 - accuracy: 0.9015 - val_loss: 0.6416 - val_accuracy: 0.7967\n",
      "Epoch 151/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1936 - accuracy: 0.9260 - val_loss: 0.4588 - val_accuracy: 0.8375\n",
      "Epoch 152/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.2026 - accuracy: 0.9195 - val_loss: 0.5721 - val_accuracy: 0.8171\n",
      "Epoch 153/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1733 - accuracy: 0.9313 - val_loss: 0.4749 - val_accuracy: 0.8324\n",
      "Epoch 154/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1667 - accuracy: 0.9338 - val_loss: 0.5781 - val_accuracy: 0.8154\n",
      "Epoch 155/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1695 - accuracy: 0.9317 - val_loss: 1.1084 - val_accuracy: 0.7567\n",
      "Epoch 156/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1621 - accuracy: 0.9384 - val_loss: 0.7046 - val_accuracy: 0.8022\n",
      "Epoch 157/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1759 - accuracy: 0.9294 - val_loss: 0.3658 - val_accuracy: 0.8656\n",
      "Epoch 158/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1802 - accuracy: 0.9291 - val_loss: 0.4027 - val_accuracy: 0.8622\n",
      "Epoch 159/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1781 - accuracy: 0.9328 - val_loss: 0.4393 - val_accuracy: 0.8381\n",
      "Epoch 160/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1656 - accuracy: 0.9353 - val_loss: 0.4593 - val_accuracy: 0.8470\n",
      "Epoch 161/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.1711 - accuracy: 0.9342 - val_loss: 0.5292 - val_accuracy: 0.8164\n",
      "Epoch 162/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1505 - accuracy: 0.9403 - val_loss: 0.6362 - val_accuracy: 0.7927\n",
      "Epoch 163/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1619 - accuracy: 0.9395 - val_loss: 0.7238 - val_accuracy: 0.7815\n",
      "Epoch 164/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1491 - accuracy: 0.9425 - val_loss: 0.3934 - val_accuracy: 0.8683\n",
      "Epoch 165/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1447 - accuracy: 0.9452 - val_loss: 0.6653 - val_accuracy: 0.8191\n",
      "Epoch 166/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1539 - accuracy: 0.9382 - val_loss: 0.5350 - val_accuracy: 0.8310\n",
      "Epoch 167/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1598 - accuracy: 0.9391 - val_loss: 0.5286 - val_accuracy: 0.8334\n",
      "Epoch 168/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1655 - accuracy: 0.9350 - val_loss: 0.6461 - val_accuracy: 0.7815\n",
      "Epoch 169/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1541 - accuracy: 0.9404 - val_loss: 0.3865 - val_accuracy: 0.8656\n",
      "Epoch 170/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1614 - accuracy: 0.9396 - val_loss: 0.6085 - val_accuracy: 0.8042\n",
      "Epoch 171/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1523 - accuracy: 0.9430 - val_loss: 0.4976 - val_accuracy: 0.8405\n",
      "Epoch 172/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1982 - accuracy: 0.9261 - val_loss: 0.5703 - val_accuracy: 0.7920\n",
      "Epoch 173/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.2048 - accuracy: 0.9192 - val_loss: 0.5648 - val_accuracy: 0.8083\n",
      "Epoch 174/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1544 - accuracy: 0.9422 - val_loss: 0.4803 - val_accuracy: 0.8334\n",
      "Epoch 175/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1798 - accuracy: 0.9290 - val_loss: 0.3911 - val_accuracy: 0.8571\n",
      "Epoch 176/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1513 - accuracy: 0.9410 - val_loss: 0.5070 - val_accuracy: 0.8249\n",
      "Epoch 177/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1433 - accuracy: 0.9438 - val_loss: 0.5321 - val_accuracy: 0.8127\n",
      "Epoch 178/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1594 - accuracy: 0.9384 - val_loss: 0.7247 - val_accuracy: 0.7791\n",
      "Epoch 179/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1484 - accuracy: 0.9421 - val_loss: 0.5044 - val_accuracy: 0.8256\n",
      "Epoch 180/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1390 - accuracy: 0.9457 - val_loss: 0.5385 - val_accuracy: 0.8235\n",
      "Epoch 181/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1425 - accuracy: 0.9444 - val_loss: 0.4430 - val_accuracy: 0.8636\n",
      "Epoch 182/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1401 - accuracy: 0.9475 - val_loss: 0.6376 - val_accuracy: 0.7940\n",
      "Epoch 183/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1987 - accuracy: 0.9259 - val_loss: 0.5639 - val_accuracy: 0.8198\n",
      "Epoch 184/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1651 - accuracy: 0.9361 - val_loss: 0.6182 - val_accuracy: 0.8056\n",
      "Epoch 185/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.1576 - accuracy: 0.9404 - val_loss: 0.7847 - val_accuracy: 0.7760\n",
      "Epoch 186/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1498 - accuracy: 0.9441 - val_loss: 0.4444 - val_accuracy: 0.8524\n",
      "Epoch 187/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1735 - accuracy: 0.9320 - val_loss: 0.6337 - val_accuracy: 0.7866\n",
      "Epoch 188/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1617 - accuracy: 0.9354 - val_loss: 0.7653 - val_accuracy: 0.7872\n",
      "Epoch 189/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1389 - accuracy: 0.9482 - val_loss: 0.5569 - val_accuracy: 0.8252\n",
      "Epoch 190/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1853 - accuracy: 0.9317 - val_loss: 0.5543 - val_accuracy: 0.8157\n",
      "Epoch 191/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1617 - accuracy: 0.9425 - val_loss: 0.6462 - val_accuracy: 0.7967\n",
      "Epoch 192/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1468 - accuracy: 0.9460 - val_loss: 0.4522 - val_accuracy: 0.8480\n",
      "Epoch 193/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1570 - accuracy: 0.9372 - val_loss: 1.3712 - val_accuracy: 0.7109\n",
      "Epoch 194/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1835 - accuracy: 0.9274 - val_loss: 0.8619 - val_accuracy: 0.7822\n",
      "Epoch 195/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1430 - accuracy: 0.9455 - val_loss: 0.4209 - val_accuracy: 0.8728\n",
      "Epoch 196/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.2143 - accuracy: 0.9162 - val_loss: 0.4452 - val_accuracy: 0.8558\n",
      "Epoch 197/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1705 - accuracy: 0.9347 - val_loss: 0.7326 - val_accuracy: 0.7883\n",
      "Epoch 198/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1640 - accuracy: 0.9354 - val_loss: 0.4436 - val_accuracy: 0.8592\n",
      "Epoch 199/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1460 - accuracy: 0.9434 - val_loss: 0.8502 - val_accuracy: 0.7628\n",
      "Epoch 200/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1495 - accuracy: 0.9430 - val_loss: 0.4372 - val_accuracy: 0.8490\n",
      "Epoch 201/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1906 - accuracy: 0.9283 - val_loss: 0.4651 - val_accuracy: 0.8331\n",
      "Epoch 202/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1509 - accuracy: 0.9430 - val_loss: 0.7360 - val_accuracy: 0.7699\n",
      "Epoch 203/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1437 - accuracy: 0.9464 - val_loss: 0.3785 - val_accuracy: 0.8714\n",
      "Epoch 204/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1416 - accuracy: 0.9446 - val_loss: 0.4960 - val_accuracy: 0.8266\n",
      "Epoch 205/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1330 - accuracy: 0.9518 - val_loss: 0.5841 - val_accuracy: 0.8239\n",
      "Epoch 206/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1376 - accuracy: 0.9467 - val_loss: 0.4736 - val_accuracy: 0.8432\n",
      "Epoch 207/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1425 - accuracy: 0.9470 - val_loss: 0.5418 - val_accuracy: 0.8110\n",
      "Epoch 208/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1412 - accuracy: 0.9446 - val_loss: 0.4630 - val_accuracy: 0.8334\n",
      "Epoch 209/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1351 - accuracy: 0.9483 - val_loss: 0.4874 - val_accuracy: 0.8419\n",
      "Epoch 210/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1378 - accuracy: 0.9467 - val_loss: 0.7937 - val_accuracy: 0.7699\n",
      "Epoch 211/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.1388 - accuracy: 0.9441 - val_loss: 0.6252 - val_accuracy: 0.7988\n",
      "Epoch 212/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1486 - accuracy: 0.9450 - val_loss: 0.5328 - val_accuracy: 0.8134\n",
      "Epoch 213/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1396 - accuracy: 0.9479 - val_loss: 0.4229 - val_accuracy: 0.8633\n",
      "Epoch 214/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1439 - accuracy: 0.9476 - val_loss: 0.5688 - val_accuracy: 0.8422\n",
      "Epoch 215/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1455 - accuracy: 0.9449 - val_loss: 0.4376 - val_accuracy: 0.8476\n",
      "Epoch 216/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1379 - accuracy: 0.9468 - val_loss: 0.6875 - val_accuracy: 0.7872\n",
      "Epoch 217/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1420 - accuracy: 0.9442 - val_loss: 0.5788 - val_accuracy: 0.8103\n",
      "Epoch 218/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1618 - accuracy: 0.9384 - val_loss: 0.4720 - val_accuracy: 0.8344\n",
      "Epoch 219/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1437 - accuracy: 0.9436 - val_loss: 0.4929 - val_accuracy: 0.8361\n",
      "Epoch 220/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1544 - accuracy: 0.9406 - val_loss: 1.3463 - val_accuracy: 0.6994\n",
      "Epoch 221/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1343 - accuracy: 0.9476 - val_loss: 0.5342 - val_accuracy: 0.8242\n",
      "Epoch 222/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1468 - accuracy: 0.9448 - val_loss: 0.6170 - val_accuracy: 0.8147\n",
      "Epoch 223/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.1350 - accuracy: 0.9499 - val_loss: 1.3525 - val_accuracy: 0.6939\n",
      "Epoch 224/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1619 - accuracy: 0.9362 - val_loss: 0.5073 - val_accuracy: 0.8337\n",
      "Epoch 225/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1419 - accuracy: 0.9467 - val_loss: 0.4847 - val_accuracy: 0.8293\n",
      "Epoch 226/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1585 - accuracy: 0.9414 - val_loss: 0.4856 - val_accuracy: 0.8358\n",
      "Epoch 227/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1330 - accuracy: 0.9465 - val_loss: 0.4763 - val_accuracy: 0.8398\n",
      "Epoch 228/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1377 - accuracy: 0.9475 - val_loss: 0.7186 - val_accuracy: 0.7638\n",
      "Epoch 229/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1491 - accuracy: 0.9404 - val_loss: 0.6223 - val_accuracy: 0.8205\n",
      "Epoch 230/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1450 - accuracy: 0.9456 - val_loss: 0.4248 - val_accuracy: 0.8639\n",
      "Epoch 231/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1297 - accuracy: 0.9508 - val_loss: 0.5081 - val_accuracy: 0.8361\n",
      "Epoch 232/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1482 - accuracy: 0.9429 - val_loss: 0.4314 - val_accuracy: 0.8592\n",
      "Epoch 233/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.1291 - accuracy: 0.9520 - val_loss: 0.3950 - val_accuracy: 0.8639\n",
      "Epoch 234/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1464 - accuracy: 0.9418 - val_loss: 0.5877 - val_accuracy: 0.8052s: 0.1451 \n",
      "Epoch 235/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1347 - accuracy: 0.9480 - val_loss: 0.4342 - val_accuracy: 0.8527\n",
      "Epoch 236/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1243 - accuracy: 0.9538 - val_loss: 0.5904 - val_accuracy: 0.8093\n",
      "Epoch 237/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1452 - accuracy: 0.9467 - val_loss: 1.2617 - val_accuracy: 0.7414\n",
      "Epoch 238/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1279 - accuracy: 0.9508 - val_loss: 0.4626 - val_accuracy: 0.8395\n",
      "Epoch 239/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1363 - accuracy: 0.9491 - val_loss: 0.4582 - val_accuracy: 0.8371\n",
      "Epoch 240/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1279 - accuracy: 0.9520 - val_loss: 0.6632 - val_accuracy: 0.7896\n",
      "Epoch 241/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1343 - accuracy: 0.9483 - val_loss: 0.3783 - val_accuracy: 0.8707\n",
      "Epoch 242/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1519 - accuracy: 0.9434 - val_loss: 0.4549 - val_accuracy: 0.8558\n",
      "Epoch 243/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1403 - accuracy: 0.9493 - val_loss: 0.4096 - val_accuracy: 0.8626\n",
      "Epoch 244/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1255 - accuracy: 0.9529 - val_loss: 0.7656 - val_accuracy: 0.7845\n",
      "Epoch 245/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1288 - accuracy: 0.9497 - val_loss: 0.5702 - val_accuracy: 0.8205\n",
      "Epoch 246/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1273 - accuracy: 0.9510 - val_loss: 0.9020 - val_accuracy: 0.8096\n",
      "Epoch 247/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1422 - accuracy: 0.9472 - val_loss: 0.5650 - val_accuracy: 0.8100\n",
      "Epoch 248/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1359 - accuracy: 0.9468 - val_loss: 0.4185 - val_accuracy: 0.8568\n",
      "Epoch 249/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1225 - accuracy: 0.9543 - val_loss: 0.7018 - val_accuracy: 0.7981\n",
      "Epoch 250/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1216 - accuracy: 0.9529 - val_loss: 1.5735 - val_accuracy: 0.7194\n",
      "Epoch 251/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1275 - accuracy: 0.9502 - val_loss: 0.6107 - val_accuracy: 0.8073\n",
      "Epoch 252/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1496 - accuracy: 0.9425 - val_loss: 0.4222 - val_accuracy: 0.8561\n",
      "Epoch 253/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1288 - accuracy: 0.9506 - val_loss: 0.4205 - val_accuracy: 0.8473\n",
      "Epoch 254/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1221 - accuracy: 0.9555 - val_loss: 0.8693 - val_accuracy: 0.7577\n",
      "Epoch 255/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1304 - accuracy: 0.9478 - val_loss: 0.9511 - val_accuracy: 0.7910\n",
      "Epoch 256/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1341 - accuracy: 0.9474 - val_loss: 0.8200 - val_accuracy: 0.7686\n",
      "Epoch 257/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1278 - accuracy: 0.9495 - val_loss: 0.9562 - val_accuracy: 0.7855\n",
      "Epoch 258/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1332 - accuracy: 0.9483 - val_loss: 0.5692 - val_accuracy: 0.8181\n",
      "Epoch 259/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1371 - accuracy: 0.9480 - val_loss: 1.1734 - val_accuracy: 0.7421\n",
      "Epoch 260/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1291 - accuracy: 0.9543 - val_loss: 0.5304 - val_accuracy: 0.8293\n",
      "Epoch 261/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.1270 - accuracy: 0.9518 - val_loss: 0.4211 - val_accuracy: 0.8609\n",
      "Epoch 262/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1656 - accuracy: 0.9372 - val_loss: 1.6857 - val_accuracy: 0.7031\n",
      "Epoch 263/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1483 - accuracy: 0.9399 - val_loss: 0.7421 - val_accuracy: 0.8001\n",
      "Epoch 264/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1315 - accuracy: 0.9459 - val_loss: 0.5314 - val_accuracy: 0.8242\n",
      "Epoch 265/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.1235 - accuracy: 0.9509 - val_loss: 0.5331 - val_accuracy: 0.8314\n",
      "Epoch 266/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.2272 - accuracy: 0.9135 - val_loss: 0.5438 - val_accuracy: 0.8249\n",
      "Epoch 267/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1467 - accuracy: 0.9436 - val_loss: 0.4476 - val_accuracy: 0.8565\n",
      "Epoch 268/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1433 - accuracy: 0.9450 - val_loss: 0.8845 - val_accuracy: 0.7910\n",
      "Epoch 269/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1300 - accuracy: 0.9508 - val_loss: 0.7752 - val_accuracy: 0.7964\n",
      "Epoch 270/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1215 - accuracy: 0.9547 - val_loss: 0.7553 - val_accuracy: 0.7988\n",
      "Epoch 271/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1661 - accuracy: 0.9407 - val_loss: 0.6953 - val_accuracy: 0.8090\n",
      "Epoch 272/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1226 - accuracy: 0.9529 - val_loss: 0.9605 - val_accuracy: 0.8029\n",
      "Epoch 273/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1193 - accuracy: 0.9532 - val_loss: 0.7246 - val_accuracy: 0.8164\n",
      "Epoch 274/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1213 - accuracy: 0.9535 - val_loss: 0.6208 - val_accuracy: 0.8202\n",
      "Epoch 275/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1256 - accuracy: 0.9508 - val_loss: 0.4853 - val_accuracy: 0.8537\n",
      "Epoch 276/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1189 - accuracy: 0.9554 - val_loss: 1.2864 - val_accuracy: 0.7360\n",
      "Epoch 277/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1163 - accuracy: 0.9576 - val_loss: 1.2601 - val_accuracy: 0.7211\n",
      "Epoch 278/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1256 - accuracy: 0.9491 - val_loss: 1.7410 - val_accuracy: 0.7156\n",
      "Epoch 279/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1158 - accuracy: 0.9562 - val_loss: 0.6170 - val_accuracy: 0.8157\n",
      "Epoch 280/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1258 - accuracy: 0.9512 - val_loss: 0.6575 - val_accuracy: 0.8185\n",
      "Epoch 281/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1210 - accuracy: 0.9524 - val_loss: 0.4324 - val_accuracy: 0.8622\n",
      "Epoch 282/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1356 - accuracy: 0.9487 - val_loss: 1.2006 - val_accuracy: 0.7693\n",
      "Epoch 283/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1201 - accuracy: 0.9547 - val_loss: 0.7963 - val_accuracy: 0.8018\n",
      "Epoch 284/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.1196 - accuracy: 0.9521 - val_loss: 0.6368 - val_accuracy: 0.8225\n",
      "Epoch 285/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1146 - accuracy: 0.9572 - val_loss: 0.4332 - val_accuracy: 0.8711\n",
      "Epoch 286/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1149 - accuracy: 0.9553 - val_loss: 0.7073 - val_accuracy: 0.7971\n",
      "Epoch 287/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1269 - accuracy: 0.9532 - val_loss: 0.5202 - val_accuracy: 0.8449\n",
      "Epoch 288/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1181 - accuracy: 0.9555 - val_loss: 1.3745 - val_accuracy: 0.7441\n",
      "Epoch 289/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1048 - accuracy: 0.9606 - val_loss: 0.8502 - val_accuracy: 0.7737\n",
      "Epoch 290/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1221 - accuracy: 0.9529 - val_loss: 0.5510 - val_accuracy: 0.8263\n",
      "Epoch 291/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1298 - accuracy: 0.9509 - val_loss: 0.6292 - val_accuracy: 0.8137\n",
      "Epoch 292/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1224 - accuracy: 0.9527 - val_loss: 1.2679 - val_accuracy: 0.7822\n",
      "Epoch 293/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1220 - accuracy: 0.9502 - val_loss: 1.4187 - val_accuracy: 0.6871\n",
      "Epoch 294/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1170 - accuracy: 0.9547 - val_loss: 0.5286 - val_accuracy: 0.8426\n",
      "Epoch 295/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1207 - accuracy: 0.9542 - val_loss: 0.5480 - val_accuracy: 0.8463\n",
      "Epoch 296/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1221 - accuracy: 0.9565 - val_loss: 0.8538 - val_accuracy: 0.7642\n",
      "Epoch 297/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1280 - accuracy: 0.9502 - val_loss: 0.6538 - val_accuracy: 0.8062\n",
      "Epoch 298/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1974 - accuracy: 0.9266 - val_loss: 0.7825 - val_accuracy: 0.7679\n",
      "Epoch 299/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1354 - accuracy: 0.9482 - val_loss: 1.2675 - val_accuracy: 0.7224\n",
      "Epoch 300/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.1240 - accuracy: 0.9540 - val_loss: 0.7309 - val_accuracy: 0.7954\n",
      "Epoch 301/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1258 - accuracy: 0.9525 - val_loss: 0.4834 - val_accuracy: 0.8493\n",
      "Epoch 302/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1140 - accuracy: 0.9540 - val_loss: 0.9569 - val_accuracy: 0.7543\n",
      "Epoch 303/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1329 - accuracy: 0.9512 - val_loss: 0.6130 - val_accuracy: 0.8076\n",
      "Epoch 304/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1216 - accuracy: 0.9543 - val_loss: 0.8456 - val_accuracy: 0.7743\n",
      "Epoch 305/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1221 - accuracy: 0.9521 - val_loss: 0.5947 - val_accuracy: 0.8300\n",
      "Epoch 306/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1075 - accuracy: 0.9589 - val_loss: 1.4691 - val_accuracy: 0.7676\n",
      "Epoch 307/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1192 - accuracy: 0.9559 - val_loss: 0.5955 - val_accuracy: 0.8137\n",
      "Epoch 308/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1283 - accuracy: 0.9513 - val_loss: 0.4806 - val_accuracy: 0.8402\n",
      "Epoch 309/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1188 - accuracy: 0.9555 - val_loss: 3.1598 - val_accuracy: 0.6709\n",
      "Epoch 310/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1351 - accuracy: 0.9490 - val_loss: 1.6060 - val_accuracy: 0.6834\n",
      "Epoch 311/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1269 - accuracy: 0.9514 - val_loss: 1.2567 - val_accuracy: 0.7268\n",
      "Epoch 312/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1129 - accuracy: 0.9546 - val_loss: 0.9019 - val_accuracy: 0.7767\n",
      "Epoch 313/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1138 - accuracy: 0.9547 - val_loss: 0.5679 - val_accuracy: 0.8161\n",
      "Epoch 314/700\n",
      "7352/7352 [==============================] - 3s 370us/sample - loss: 0.1138 - accuracy: 0.9581 - val_loss: 0.5333 - val_accuracy: 0.8324\n",
      "Epoch 315/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1129 - accuracy: 0.9563 - val_loss: 0.6292 - val_accuracy: 0.8178\n",
      "Epoch 316/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1257 - accuracy: 0.9521 - val_loss: 0.7259 - val_accuracy: 0.7822\n",
      "Epoch 317/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1211 - accuracy: 0.9544 - val_loss: 0.7800 - val_accuracy: 0.8059\n",
      "Epoch 318/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1205 - accuracy: 0.9551 - val_loss: 0.4876 - val_accuracy: 0.8429\n",
      "Epoch 319/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1039 - accuracy: 0.9599 - val_loss: 0.6459 - val_accuracy: 0.7917\n",
      "Epoch 320/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1075 - accuracy: 0.9585 - val_loss: 0.4573 - val_accuracy: 0.8463\n",
      "Epoch 321/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1262 - accuracy: 0.9536 - val_loss: 0.5622 - val_accuracy: 0.8168\n",
      "Epoch 322/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1062 - accuracy: 0.9592 - val_loss: 0.5145 - val_accuracy: 0.8273\n",
      "Epoch 323/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1055 - accuracy: 0.9593 - val_loss: 2.2014 - val_accuracy: 0.6841\n",
      "Epoch 324/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1280 - accuracy: 0.9506 - val_loss: 0.8217 - val_accuracy: 0.7913\n",
      "Epoch 325/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1297 - accuracy: 0.9505 - val_loss: 0.7391 - val_accuracy: 0.8018\n",
      "Epoch 326/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1156 - accuracy: 0.9569 - val_loss: 0.4861 - val_accuracy: 0.8466\n",
      "Epoch 327/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1089 - accuracy: 0.9566 - val_loss: 0.9138 - val_accuracy: 0.7693\n",
      "Epoch 328/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1104 - accuracy: 0.9573 - val_loss: 0.4304 - val_accuracy: 0.8616\n",
      "Epoch 329/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1294 - accuracy: 0.9498 - val_loss: 0.7074 - val_accuracy: 0.7757\n",
      "Epoch 330/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.1146 - accuracy: 0.9577 - val_loss: 0.4898 - val_accuracy: 0.8514\n",
      "Epoch 331/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1387 - accuracy: 0.9456 - val_loss: 0.5474 - val_accuracy: 0.8300\n",
      "Epoch 332/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1131 - accuracy: 0.9578 - val_loss: 0.6421 - val_accuracy: 0.8134\n",
      "Epoch 333/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1040 - accuracy: 0.9599 - val_loss: 0.8903 - val_accuracy: 0.7737\n",
      "Epoch 334/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1182 - accuracy: 0.9536 - val_loss: 0.5344 - val_accuracy: 0.8331\n",
      "Epoch 335/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.1116 - accuracy: 0.9574 - val_loss: 1.0150 - val_accuracy: 0.7730\n",
      "Epoch 336/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1102 - accuracy: 0.9596 - val_loss: 0.4590 - val_accuracy: 0.8442\n",
      "Epoch 337/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1059 - accuracy: 0.9607 - val_loss: 0.7123 - val_accuracy: 0.7978\n",
      "Epoch 338/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1064 - accuracy: 0.9595 - val_loss: 0.5923 - val_accuracy: 0.8174\n",
      "Epoch 339/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1076 - accuracy: 0.9611 - val_loss: 0.4571 - val_accuracy: 0.8585\n",
      "Epoch 340/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0928 - accuracy: 0.9668 - val_loss: 0.5741 - val_accuracy: 0.8341\n",
      "Epoch 341/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1048 - accuracy: 0.9582 - val_loss: 0.5405 - val_accuracy: 0.8473\n",
      "Epoch 342/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1069 - accuracy: 0.9584 - val_loss: 0.4537 - val_accuracy: 0.8592\n",
      "Epoch 343/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1003 - accuracy: 0.9607 - val_loss: 0.4716 - val_accuracy: 0.8541\n",
      "Epoch 344/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1114 - accuracy: 0.9548 - val_loss: 0.6668 - val_accuracy: 0.8130\n",
      "Epoch 345/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1019 - accuracy: 0.9626 - val_loss: 0.7838 - val_accuracy: 0.7995\n",
      "Epoch 346/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1292 - accuracy: 0.9512 - val_loss: 1.5255 - val_accuracy: 0.7184\n",
      "Epoch 347/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1032 - accuracy: 0.9603 - val_loss: 0.8064 - val_accuracy: 0.7774\n",
      "Epoch 348/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1050 - accuracy: 0.9597 - val_loss: 0.5802 - val_accuracy: 0.8266\n",
      "Epoch 349/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1007 - accuracy: 0.9615 - val_loss: 0.5356 - val_accuracy: 0.8317\n",
      "Epoch 350/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1261 - accuracy: 0.9524 - val_loss: 0.5446 - val_accuracy: 0.8358\n",
      "Epoch 351/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1027 - accuracy: 0.9619 - val_loss: 0.4441 - val_accuracy: 0.8588\n",
      "Epoch 352/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1233 - accuracy: 0.9529 - val_loss: 0.8217 - val_accuracy: 0.7774\n",
      "Epoch 353/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1057 - accuracy: 0.9615 - val_loss: 0.4797 - val_accuracy: 0.8521\n",
      "Epoch 354/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1085 - accuracy: 0.9593 - val_loss: 0.7031 - val_accuracy: 0.7995\n",
      "Epoch 355/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1142 - accuracy: 0.9573 - val_loss: 0.7225 - val_accuracy: 0.7903\n",
      "Epoch 356/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1072 - accuracy: 0.9596 - val_loss: 0.7643 - val_accuracy: 0.8049\n",
      "Epoch 357/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0966 - accuracy: 0.9621 - val_loss: 0.5082 - val_accuracy: 0.8541\n",
      "Epoch 358/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0945 - accuracy: 0.9644 - val_loss: 0.5613 - val_accuracy: 0.8297\n",
      "Epoch 359/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0952 - accuracy: 0.9653 - val_loss: 0.4987 - val_accuracy: 0.8453\n",
      "Epoch 360/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1046 - accuracy: 0.9601 - val_loss: 0.8584 - val_accuracy: 0.7764\n",
      "Epoch 361/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1031 - accuracy: 0.9612 - val_loss: 1.0256 - val_accuracy: 0.7503\n",
      "Epoch 362/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1296 - accuracy: 0.9538 - val_loss: 0.8360 - val_accuracy: 0.7689\n",
      "Epoch 363/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1017 - accuracy: 0.9610 - val_loss: 1.2894 - val_accuracy: 0.7384\n",
      "Epoch 364/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0967 - accuracy: 0.9655 - val_loss: 1.0930 - val_accuracy: 0.7825\n",
      "Epoch 365/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0999 - accuracy: 0.9622 - val_loss: 1.1888 - val_accuracy: 0.7893\n",
      "Epoch 366/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1092 - accuracy: 0.9589 - val_loss: 0.4258 - val_accuracy: 0.8571\n",
      "Epoch 367/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1183 - accuracy: 0.9559 - val_loss: 0.9512 - val_accuracy: 0.7479\n",
      "Epoch 368/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1308 - accuracy: 0.9510 - val_loss: 0.6620 - val_accuracy: 0.8174\n",
      "Epoch 369/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1090 - accuracy: 0.9589 - val_loss: 0.6079 - val_accuracy: 0.8212\n",
      "Epoch 370/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1038 - accuracy: 0.9626 - val_loss: 0.6059 - val_accuracy: 0.8120\n",
      "Epoch 371/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0899 - accuracy: 0.9682 - val_loss: 1.6847 - val_accuracy: 0.7743\n",
      "Epoch 372/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0993 - accuracy: 0.9625 - val_loss: 0.7098 - val_accuracy: 0.8052\n",
      "Epoch 373/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0953 - accuracy: 0.9644 - val_loss: 0.5865 - val_accuracy: 0.8307\n",
      "Epoch 374/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0964 - accuracy: 0.9637 - val_loss: 0.5126 - val_accuracy: 0.8527\n",
      "Epoch 375/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0941 - accuracy: 0.9649 - val_loss: 0.5269 - val_accuracy: 0.8510\n",
      "Epoch 376/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1085 - accuracy: 0.9610 - val_loss: 1.0737 - val_accuracy: 0.7574\n",
      "Epoch 377/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1086 - accuracy: 0.9588 - val_loss: 0.5837 - val_accuracy: 0.8273\n",
      "Epoch 378/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0990 - accuracy: 0.9623 - val_loss: 0.5853 - val_accuracy: 0.8249\n",
      "Epoch 379/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1103 - accuracy: 0.9599 - val_loss: 0.5861 - val_accuracy: 0.8252\n",
      "Epoch 380/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0896 - accuracy: 0.9648 - val_loss: 2.6111 - val_accuracy: 0.6926\n",
      "Epoch 381/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0995 - accuracy: 0.9612 - val_loss: 1.1492 - val_accuracy: 0.7557\n",
      "Epoch 382/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1095 - accuracy: 0.9596 - val_loss: 0.5182 - val_accuracy: 0.8381\n",
      "Epoch 383/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0947 - accuracy: 0.9650 - val_loss: 0.7689 - val_accuracy: 0.8062\n",
      "Epoch 384/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0953 - accuracy: 0.9660 - val_loss: 0.8555 - val_accuracy: 0.8005\n",
      "Epoch 385/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0941 - accuracy: 0.9661 - val_loss: 0.7742 - val_accuracy: 0.8069\n",
      "Epoch 386/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.1049 - accuracy: 0.9619 - val_loss: 0.7004 - val_accuracy: 0.8076\n",
      "Epoch 387/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1027 - accuracy: 0.9614 - val_loss: 0.5106 - val_accuracy: 0.8510\n",
      "Epoch 388/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1021 - accuracy: 0.9622 - val_loss: 1.1499 - val_accuracy: 0.7557\n",
      "Epoch 389/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0911 - accuracy: 0.9674 - val_loss: 0.4736 - val_accuracy: 0.8537\n",
      "Epoch 390/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0939 - accuracy: 0.9640 - val_loss: 1.2562 - val_accuracy: 0.7503\n",
      "Epoch 391/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1000 - accuracy: 0.9621 - val_loss: 0.4383 - val_accuracy: 0.8619\n",
      "Epoch 392/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0949 - accuracy: 0.9642 - val_loss: 0.5449 - val_accuracy: 0.8449\n",
      "Epoch 393/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1007 - accuracy: 0.9612 - val_loss: 0.5497 - val_accuracy: 0.8239\n",
      "Epoch 394/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0929 - accuracy: 0.9663 - val_loss: 0.8817 - val_accuracy: 0.8025\n",
      "Epoch 395/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0931 - accuracy: 0.9635 - val_loss: 0.6294 - val_accuracy: 0.8276\n",
      "Epoch 396/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1124 - accuracy: 0.9570 - val_loss: 0.8171 - val_accuracy: 0.8039\n",
      "Epoch 397/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0962 - accuracy: 0.9622 - val_loss: 0.4534 - val_accuracy: 0.8507\n",
      "Epoch 398/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0906 - accuracy: 0.9665 - val_loss: 0.4537 - val_accuracy: 0.8636\n",
      "Epoch 399/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0865 - accuracy: 0.9691 - val_loss: 0.6732 - val_accuracy: 0.8303\n",
      "Epoch 400/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1057 - accuracy: 0.9601 - val_loss: 0.4189 - val_accuracy: 0.8599\n",
      "Epoch 401/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0900 - accuracy: 0.9697 - val_loss: 0.9205 - val_accuracy: 0.7811\n",
      "Epoch 402/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0796 - accuracy: 0.9716 - val_loss: 0.7883 - val_accuracy: 0.7913\n",
      "Epoch 403/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0931 - accuracy: 0.9646 - val_loss: 0.6139 - val_accuracy: 0.8164\n",
      "Epoch 404/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1073 - accuracy: 0.9607 - val_loss: 0.7704 - val_accuracy: 0.7862\n",
      "Epoch 405/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0870 - accuracy: 0.9669 - val_loss: 1.5419 - val_accuracy: 0.7251\n",
      "Epoch 406/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0893 - accuracy: 0.9656 - val_loss: 0.4976 - val_accuracy: 0.8480\n",
      "Epoch 407/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0902 - accuracy: 0.9663 - val_loss: 0.7273 - val_accuracy: 0.7913\n",
      "Epoch 408/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0924 - accuracy: 0.9657 - val_loss: 0.6512 - val_accuracy: 0.8178\n",
      "Epoch 409/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1098 - accuracy: 0.9599 - val_loss: 0.4886 - val_accuracy: 0.8487\n",
      "Epoch 410/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1069 - accuracy: 0.9612 - val_loss: 1.1227 - val_accuracy: 0.7489\n",
      "Epoch 411/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0924 - accuracy: 0.9661 - val_loss: 0.7190 - val_accuracy: 0.8022\n",
      "Epoch 412/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1003 - accuracy: 0.9642 - val_loss: 0.5242 - val_accuracy: 0.8449\n",
      "Epoch 413/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0939 - accuracy: 0.9631 - val_loss: 0.5426 - val_accuracy: 0.8354\n",
      "Epoch 414/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0897 - accuracy: 0.9657 - val_loss: 1.4305 - val_accuracy: 0.7106\n",
      "Epoch 415/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0984 - accuracy: 0.9616 - val_loss: 0.5108 - val_accuracy: 0.8514\n",
      "Epoch 416/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0951 - accuracy: 0.9648 - val_loss: 0.4843 - val_accuracy: 0.8517\n",
      "Epoch 417/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0860 - accuracy: 0.9667 - val_loss: 0.5811 - val_accuracy: 0.8280\n",
      "Epoch 418/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0765 - accuracy: 0.9708 - val_loss: 0.7916 - val_accuracy: 0.7978\n",
      "Epoch 419/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0901 - accuracy: 0.9675 - val_loss: 0.4952 - val_accuracy: 0.8585\n",
      "Epoch 420/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0898 - accuracy: 0.9653 - val_loss: 0.7078 - val_accuracy: 0.8205\n",
      "Epoch 421/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0895 - accuracy: 0.9665 - val_loss: 0.8409 - val_accuracy: 0.7815\n",
      "Epoch 422/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0922 - accuracy: 0.9660 - val_loss: 1.0306 - val_accuracy: 0.7859\n",
      "Epoch 423/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1008 - accuracy: 0.9599 - val_loss: 0.9437 - val_accuracy: 0.7499\n",
      "Epoch 424/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0858 - accuracy: 0.9672 - val_loss: 0.7620 - val_accuracy: 0.8015\n",
      "Epoch 425/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0959 - accuracy: 0.9656 - val_loss: 0.5829 - val_accuracy: 0.8239\n",
      "Epoch 426/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0866 - accuracy: 0.9680 - val_loss: 1.0453 - val_accuracy: 0.7971\n",
      "Epoch 427/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0809 - accuracy: 0.9682 - val_loss: 0.5888 - val_accuracy: 0.8293\n",
      "Epoch 428/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0832 - accuracy: 0.9708 - val_loss: 0.8501 - val_accuracy: 0.8066\n",
      "Epoch 429/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1001 - accuracy: 0.9637 - val_loss: 0.6860 - val_accuracy: 0.8079\n",
      "Epoch 430/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1040 - accuracy: 0.9608 - val_loss: 0.6101 - val_accuracy: 0.8334\n",
      "Epoch 431/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0903 - accuracy: 0.9650 - val_loss: 0.5475 - val_accuracy: 0.8436\n",
      "Epoch 432/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0908 - accuracy: 0.9660 - val_loss: 0.5870 - val_accuracy: 0.8246\n",
      "Epoch 433/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0829 - accuracy: 0.9714 - val_loss: 0.6680 - val_accuracy: 0.8168\n",
      "Epoch 434/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0846 - accuracy: 0.9683 - val_loss: 0.5663 - val_accuracy: 0.8463\n",
      "Epoch 435/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0866 - accuracy: 0.9659 - val_loss: 0.6866 - val_accuracy: 0.8185\n",
      "Epoch 436/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.1158 - accuracy: 0.9584 - val_loss: 0.6444 - val_accuracy: 0.8120\n",
      "Epoch 437/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1001 - accuracy: 0.9614 - val_loss: 0.4959 - val_accuracy: 0.8442\n",
      "Epoch 438/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0947 - accuracy: 0.9652 - val_loss: 0.4467 - val_accuracy: 0.8561\n",
      "Epoch 439/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0796 - accuracy: 0.9710 - val_loss: 0.6230 - val_accuracy: 0.8178\n",
      "Epoch 440/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0834 - accuracy: 0.9679 - val_loss: 0.6345 - val_accuracy: 0.8215\n",
      "Epoch 441/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0910 - accuracy: 0.9679 - val_loss: 0.5231 - val_accuracy: 0.8378\n",
      "Epoch 442/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0781 - accuracy: 0.9728 - val_loss: 0.4851 - val_accuracy: 0.8565\n",
      "Epoch 443/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0779 - accuracy: 0.9716 - val_loss: 0.4358 - val_accuracy: 0.8626\n",
      "Epoch 444/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0864 - accuracy: 0.9656 - val_loss: 1.1765 - val_accuracy: 0.7971\n",
      "Epoch 445/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0856 - accuracy: 0.9679 - val_loss: 0.5099 - val_accuracy: 0.8449\n",
      "Epoch 446/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0857 - accuracy: 0.9676 - val_loss: 0.5013 - val_accuracy: 0.8385\n",
      "Epoch 447/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0871 - accuracy: 0.9683 - val_loss: 1.2013 - val_accuracy: 0.7289\n",
      "Epoch 448/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0905 - accuracy: 0.9656 - val_loss: 0.5798 - val_accuracy: 0.8310\n",
      "Epoch 449/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0906 - accuracy: 0.9683 - val_loss: 0.4243 - val_accuracy: 0.8680\n",
      "Epoch 450/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0822 - accuracy: 0.9712 - val_loss: 0.4145 - val_accuracy: 0.8633\n",
      "Epoch 451/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0841 - accuracy: 0.9705 - val_loss: 0.6763 - val_accuracy: 0.8022\n",
      "Epoch 452/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1227 - accuracy: 0.9543 - val_loss: 0.5352 - val_accuracy: 0.8324\n",
      "Epoch 453/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0851 - accuracy: 0.9669 - val_loss: 0.4455 - val_accuracy: 0.8565\n",
      "Epoch 454/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0892 - accuracy: 0.9660 - val_loss: 0.4986 - val_accuracy: 0.8497\n",
      "Epoch 455/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0859 - accuracy: 0.9683 - val_loss: 0.4841 - val_accuracy: 0.8493\n",
      "Epoch 456/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0814 - accuracy: 0.9706 - val_loss: 0.6823 - val_accuracy: 0.8059\n",
      "Epoch 457/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0796 - accuracy: 0.9691 - val_loss: 0.5191 - val_accuracy: 0.8409\n",
      "Epoch 458/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0796 - accuracy: 0.9702 - val_loss: 0.5673 - val_accuracy: 0.8361\n",
      "Epoch 459/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0945 - accuracy: 0.9645 - val_loss: 0.4288 - val_accuracy: 0.8643\n",
      "Epoch 460/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0838 - accuracy: 0.9676 - val_loss: 0.9462 - val_accuracy: 0.7730\n",
      "Epoch 461/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0826 - accuracy: 0.9675 - val_loss: 0.6147 - val_accuracy: 0.8307\n",
      "Epoch 462/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0766 - accuracy: 0.9716 - val_loss: 0.5711 - val_accuracy: 0.8371\n",
      "Epoch 463/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0734 - accuracy: 0.9736 - val_loss: 0.7640 - val_accuracy: 0.8039\n",
      "Epoch 464/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0936 - accuracy: 0.9641 - val_loss: 1.2221 - val_accuracy: 0.7173\n",
      "Epoch 465/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0747 - accuracy: 0.9731 - val_loss: 0.8126 - val_accuracy: 0.7910\n",
      "Epoch 466/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.1165 - accuracy: 0.9580 - val_loss: 1.7676 - val_accuracy: 0.6861\n",
      "Epoch 467/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0967 - accuracy: 0.9618 - val_loss: 0.4562 - val_accuracy: 0.8592\n",
      "Epoch 468/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0812 - accuracy: 0.9693 - val_loss: 0.5571 - val_accuracy: 0.8347\n",
      "Epoch 469/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0809 - accuracy: 0.9708 - val_loss: 0.4351 - val_accuracy: 0.8660\n",
      "Epoch 470/700\n",
      "7352/7352 [==============================] - 2s 316us/sample - loss: 0.0854 - accuracy: 0.9699 - val_loss: 0.7818 - val_accuracy: 0.8045\n",
      "Epoch 471/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0903 - accuracy: 0.9648 - val_loss: 0.8603 - val_accuracy: 0.7913\n",
      "Epoch 472/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0977 - accuracy: 0.9616 - val_loss: 1.1121 - val_accuracy: 0.7333\n",
      "Epoch 473/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0866 - accuracy: 0.9682 - val_loss: 0.7473 - val_accuracy: 0.8076\n",
      "Epoch 474/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0821 - accuracy: 0.9689 - val_loss: 0.7947 - val_accuracy: 0.8076\n",
      "Epoch 475/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1016 - accuracy: 0.9616 - val_loss: 1.3045 - val_accuracy: 0.7143\n",
      "Epoch 476/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0752 - accuracy: 0.9706 - val_loss: 0.9381 - val_accuracy: 0.7950\n",
      "Epoch 477/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0904 - accuracy: 0.9665 - val_loss: 0.8659 - val_accuracy: 0.7964\n",
      "Epoch 478/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0777 - accuracy: 0.9703 - val_loss: 0.9854 - val_accuracy: 0.7869\n",
      "Epoch 479/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0810 - accuracy: 0.9705 - val_loss: 0.7646 - val_accuracy: 0.8073\n",
      "Epoch 480/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0845 - accuracy: 0.9695 - val_loss: 0.5700 - val_accuracy: 0.8371\n",
      "Epoch 481/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0774 - accuracy: 0.9725 - val_loss: 0.8401 - val_accuracy: 0.7937\n",
      "Epoch 482/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0834 - accuracy: 0.9678 - val_loss: 0.5022 - val_accuracy: 0.8524\n",
      "Epoch 483/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0744 - accuracy: 0.9710 - val_loss: 0.5346 - val_accuracy: 0.8500\n",
      "Epoch 484/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0700 - accuracy: 0.9748 - val_loss: 0.7525 - val_accuracy: 0.8086\n",
      "Epoch 485/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0821 - accuracy: 0.9698 - val_loss: 0.4838 - val_accuracy: 0.8585\n",
      "Epoch 486/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0790 - accuracy: 0.9705 - val_loss: 0.4946 - val_accuracy: 0.8646\n",
      "Epoch 487/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0759 - accuracy: 0.9716 - val_loss: 0.7801 - val_accuracy: 0.8093\n",
      "Epoch 488/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0710 - accuracy: 0.9735 - val_loss: 1.0757 - val_accuracy: 0.7828\n",
      "Epoch 489/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0799 - accuracy: 0.9684 - val_loss: 0.5831 - val_accuracy: 0.8402\n",
      "Epoch 490/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0733 - accuracy: 0.9736 - val_loss: 0.5139 - val_accuracy: 0.8541\n",
      "Epoch 491/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0796 - accuracy: 0.9695 - val_loss: 0.5458 - val_accuracy: 0.8392\n",
      "Epoch 492/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0741 - accuracy: 0.9731 - val_loss: 0.6208 - val_accuracy: 0.8198\n",
      "Epoch 493/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0725 - accuracy: 0.9709 - val_loss: 0.6787 - val_accuracy: 0.8151\n",
      "Epoch 494/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0758 - accuracy: 0.9727 - val_loss: 0.6868 - val_accuracy: 0.8164\n",
      "Epoch 495/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.5747 - val_accuracy: 0.8273\n",
      "Epoch 496/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0704 - accuracy: 0.9744 - val_loss: 0.5454 - val_accuracy: 0.8470\n",
      "Epoch 497/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0828 - accuracy: 0.9671 - val_loss: 0.9252 - val_accuracy: 0.7971\n",
      "Epoch 498/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0793 - accuracy: 0.9697 - val_loss: 0.7608 - val_accuracy: 0.7957\n",
      "Epoch 499/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0783 - accuracy: 0.9729 - val_loss: 0.4642 - val_accuracy: 0.8609\n",
      "Epoch 500/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0760 - accuracy: 0.9717 - val_loss: 1.2677 - val_accuracy: 0.7767\n",
      "Epoch 501/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0838 - accuracy: 0.9698 - val_loss: 0.4538 - val_accuracy: 0.8602\n",
      "Epoch 502/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0891 - accuracy: 0.9665 - val_loss: 0.4466 - val_accuracy: 0.8571\n",
      "Epoch 503/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0719 - accuracy: 0.9732 - val_loss: 0.6587 - val_accuracy: 0.8157\n",
      "Epoch 504/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0810 - accuracy: 0.9717 - val_loss: 0.5956 - val_accuracy: 0.8398\n",
      "Epoch 505/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0728 - accuracy: 0.9735 - val_loss: 2.4457 - val_accuracy: 0.7065\n",
      "Epoch 506/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0684 - accuracy: 0.9763 - val_loss: 0.6344 - val_accuracy: 0.8273\n",
      "Epoch 507/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0710 - accuracy: 0.9746 - val_loss: 0.5477 - val_accuracy: 0.8409\n",
      "Epoch 508/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0827 - accuracy: 0.9689 - val_loss: 0.5906 - val_accuracy: 0.8205\n",
      "Epoch 509/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0691 - accuracy: 0.9732 - val_loss: 0.5665 - val_accuracy: 0.8493\n",
      "Epoch 510/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0778 - accuracy: 0.9712 - val_loss: 0.7337 - val_accuracy: 0.8032\n",
      "Epoch 511/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0696 - accuracy: 0.9742 - val_loss: 0.5354 - val_accuracy: 0.8385\n",
      "Epoch 512/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0722 - accuracy: 0.9740 - val_loss: 0.7486 - val_accuracy: 0.7988\n",
      "Epoch 513/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0806 - accuracy: 0.9716 - val_loss: 1.7028 - val_accuracy: 0.7346\n",
      "Epoch 514/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0836 - accuracy: 0.9693 - val_loss: 0.8414 - val_accuracy: 0.7859\n",
      "Epoch 515/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0681 - accuracy: 0.9742 - val_loss: 0.8978 - val_accuracy: 0.7900\n",
      "Epoch 516/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0721 - accuracy: 0.9751 - val_loss: 0.4700 - val_accuracy: 0.8551\n",
      "Epoch 517/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0725 - accuracy: 0.9721 - val_loss: 1.3920 - val_accuracy: 0.7631\n",
      "Epoch 518/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0685 - accuracy: 0.9736 - val_loss: 0.6207 - val_accuracy: 0.8229\n",
      "Epoch 519/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0987 - accuracy: 0.9627 - val_loss: 0.6148 - val_accuracy: 0.8107\n",
      "Epoch 520/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0738 - accuracy: 0.9740 - val_loss: 0.4282 - val_accuracy: 0.8646\n",
      "Epoch 521/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0790 - accuracy: 0.9728 - val_loss: 0.4391 - val_accuracy: 0.8622\n",
      "Epoch 522/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0792 - accuracy: 0.9710 - val_loss: 0.4810 - val_accuracy: 0.8493\n",
      "Epoch 523/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0731 - accuracy: 0.9735 - val_loss: 0.8558 - val_accuracy: 0.8120\n",
      "Epoch 524/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0766 - accuracy: 0.9723 - val_loss: 0.5698 - val_accuracy: 0.8405\n",
      "Epoch 525/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0713 - accuracy: 0.9727 - val_loss: 0.4616 - val_accuracy: 0.8588\n",
      "Epoch 526/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0784 - accuracy: 0.9709 - val_loss: 0.4975 - val_accuracy: 0.8504\n",
      "Epoch 527/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0770 - accuracy: 0.9710 - val_loss: 0.4143 - val_accuracy: 0.8653\n",
      "Epoch 528/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0709 - accuracy: 0.9731 - val_loss: 0.5032 - val_accuracy: 0.8582\n",
      "Epoch 529/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0732 - accuracy: 0.9744 - val_loss: 0.7847 - val_accuracy: 0.8113\n",
      "Epoch 530/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0777 - accuracy: 0.9717 - val_loss: 0.4103 - val_accuracy: 0.8700\n",
      "Epoch 531/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0768 - accuracy: 0.9703 - val_loss: 0.3978 - val_accuracy: 0.8717\n",
      "Epoch 532/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0699 - accuracy: 0.9747 - val_loss: 0.7658 - val_accuracy: 0.8110\n",
      "Epoch 533/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0724 - accuracy: 0.9731 - val_loss: 0.5156 - val_accuracy: 0.8429\n",
      "Epoch 534/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0799 - accuracy: 0.9708 - val_loss: 0.7884 - val_accuracy: 0.8066\n",
      "Epoch 535/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0679 - accuracy: 0.9754 - val_loss: 0.5212 - val_accuracy: 0.8388\n",
      "Epoch 536/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0665 - accuracy: 0.9758 - val_loss: 0.5114 - val_accuracy: 0.8385\n",
      "Epoch 537/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0686 - accuracy: 0.9755 - val_loss: 0.4365 - val_accuracy: 0.8673\n",
      "Epoch 538/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0719 - accuracy: 0.9727 - val_loss: 0.6421 - val_accuracy: 0.8191\n",
      "Epoch 539/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0611 - accuracy: 0.9755 - val_loss: 0.5203 - val_accuracy: 0.8493\n",
      "Epoch 540/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0704 - accuracy: 0.9748 - val_loss: 1.2751 - val_accuracy: 0.7343\n",
      "Epoch 541/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0690 - accuracy: 0.9740 - val_loss: 0.4928 - val_accuracy: 0.8504\n",
      "Epoch 542/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0772 - accuracy: 0.9709 - val_loss: 0.8156 - val_accuracy: 0.7855\n",
      "Epoch 543/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0689 - accuracy: 0.9735 - val_loss: 0.7439 - val_accuracy: 0.8005\n",
      "Epoch 544/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0654 - accuracy: 0.9762 - val_loss: 0.4831 - val_accuracy: 0.8537\n",
      "Epoch 545/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0661 - accuracy: 0.9766 - val_loss: 1.5794 - val_accuracy: 0.7822\n",
      "Epoch 546/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0715 - accuracy: 0.9740 - val_loss: 0.4469 - val_accuracy: 0.8599\n",
      "Epoch 547/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0649 - accuracy: 0.9758 - val_loss: 0.7331 - val_accuracy: 0.8174\n",
      "Epoch 548/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0863 - accuracy: 0.9675 - val_loss: 0.4531 - val_accuracy: 0.8697\n",
      "Epoch 549/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0735 - accuracy: 0.9717 - val_loss: 0.6360 - val_accuracy: 0.8269\n",
      "Epoch 550/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0715 - accuracy: 0.9743 - val_loss: 0.4912 - val_accuracy: 0.8544\n",
      "Epoch 551/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0671 - accuracy: 0.9757 - val_loss: 0.5538 - val_accuracy: 0.8324\n",
      "Epoch 552/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0630 - accuracy: 0.9766 - val_loss: 0.5409 - val_accuracy: 0.8534\n",
      "Epoch 553/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0667 - accuracy: 0.9754 - val_loss: 0.4545 - val_accuracy: 0.8717\n",
      "Epoch 554/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0693 - accuracy: 0.9733 - val_loss: 0.5833 - val_accuracy: 0.8473\n",
      "Epoch 555/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0679 - accuracy: 0.9750 - val_loss: 1.2062 - val_accuracy: 0.7842\n",
      "Epoch 556/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0732 - accuracy: 0.9718 - val_loss: 1.0757 - val_accuracy: 0.8001\n",
      "Epoch 557/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0729 - accuracy: 0.9705 - val_loss: 0.6346 - val_accuracy: 0.8188\n",
      "Epoch 558/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0893 - accuracy: 0.9649 - val_loss: 0.7860 - val_accuracy: 0.7866\n",
      "Epoch 559/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0730 - accuracy: 0.9725 - val_loss: 0.4464 - val_accuracy: 0.8636\n",
      "Epoch 560/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0668 - accuracy: 0.9759 - val_loss: 0.5757 - val_accuracy: 0.8375\n",
      "Epoch 561/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0763 - accuracy: 0.9720 - val_loss: 0.5172 - val_accuracy: 0.8439\n",
      "Epoch 562/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0612 - accuracy: 0.9761 - val_loss: 0.5365 - val_accuracy: 0.8347\n",
      "Epoch 563/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0663 - accuracy: 0.9751 - val_loss: 0.5961 - val_accuracy: 0.8337\n",
      "Epoch 564/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0733 - accuracy: 0.9735 - val_loss: 0.9991 - val_accuracy: 0.7767\n",
      "Epoch 565/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0811 - accuracy: 0.9714 - val_loss: 0.4596 - val_accuracy: 0.8643\n",
      "Epoch 566/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0847 - accuracy: 0.9690 - val_loss: 0.9391 - val_accuracy: 0.7669\n",
      "Epoch 567/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0704 - accuracy: 0.9750 - val_loss: 0.5129 - val_accuracy: 0.8521\n",
      "Epoch 568/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0753 - accuracy: 0.9720 - val_loss: 0.4567 - val_accuracy: 0.8660\n",
      "Epoch 569/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0702 - accuracy: 0.9740 - val_loss: 1.2438 - val_accuracy: 0.7509\n",
      "Epoch 570/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0709 - accuracy: 0.9743 - val_loss: 0.5662 - val_accuracy: 0.8364\n",
      "Epoch 571/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0747 - accuracy: 0.9736 - val_loss: 0.5681 - val_accuracy: 0.8392\n",
      "Epoch 572/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0666 - accuracy: 0.9748 - val_loss: 0.6025 - val_accuracy: 0.8334\n",
      "Epoch 573/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0693 - accuracy: 0.9743 - val_loss: 0.5699 - val_accuracy: 0.8446\n",
      "Epoch 574/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0683 - accuracy: 0.9729 - val_loss: 0.4875 - val_accuracy: 0.8534\n",
      "Epoch 575/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0665 - accuracy: 0.9757 - val_loss: 0.6706 - val_accuracy: 0.8171\n",
      "Epoch 576/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0759 - accuracy: 0.9713 - val_loss: 0.4818 - val_accuracy: 0.8568\n",
      "Epoch 577/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0729 - accuracy: 0.9727 - val_loss: 0.4238 - val_accuracy: 0.8707\n",
      "Epoch 578/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0688 - accuracy: 0.9754 - val_loss: 0.8017 - val_accuracy: 0.8300\n",
      "Epoch 579/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0705 - accuracy: 0.9735 - val_loss: 0.5057 - val_accuracy: 0.8476\n",
      "Epoch 580/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0841 - accuracy: 0.9706 - val_loss: 0.5113 - val_accuracy: 0.8422\n",
      "Epoch 581/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.4457 - val_accuracy: 0.8680\n",
      "Epoch 582/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0656 - accuracy: 0.9759 - val_loss: 0.4303 - val_accuracy: 0.8704\n",
      "Epoch 583/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0652 - accuracy: 0.9757 - val_loss: 0.5694 - val_accuracy: 0.8381\n",
      "Epoch 584/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0930 - accuracy: 0.9659 - val_loss: 0.4479 - val_accuracy: 0.8582\n",
      "Epoch 585/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0661 - accuracy: 0.9757 - val_loss: 0.6763 - val_accuracy: 0.8205\n",
      "Epoch 586/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0670 - accuracy: 0.9761 - val_loss: 0.6843 - val_accuracy: 0.8127\n",
      "Epoch 587/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0720 - accuracy: 0.9721 - val_loss: 0.5116 - val_accuracy: 0.8456\n",
      "Epoch 588/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0820 - accuracy: 0.9694 - val_loss: 0.4888 - val_accuracy: 0.8476\n",
      "Epoch 589/700\n",
      "7352/7352 [==============================] - 2s 332us/sample - loss: 0.0715 - accuracy: 0.9742 - val_loss: 0.6991 - val_accuracy: 0.8059\n",
      "Epoch 590/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0656 - accuracy: 0.9776 - val_loss: 0.5384 - val_accuracy: 0.8429\n",
      "Epoch 591/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0607 - accuracy: 0.9774 - val_loss: 0.6044 - val_accuracy: 0.8283\n",
      "Epoch 592/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0748 - accuracy: 0.9702 - val_loss: 0.4930 - val_accuracy: 0.8551\n",
      "Epoch 593/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0660 - accuracy: 0.9746 - val_loss: 0.6428 - val_accuracy: 0.8174\n",
      "Epoch 594/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0623 - accuracy: 0.9784 - val_loss: 0.4472 - val_accuracy: 0.8636\n",
      "Epoch 595/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0583 - accuracy: 0.9788 - val_loss: 0.8356 - val_accuracy: 0.8059\n",
      "Epoch 596/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0790 - accuracy: 0.9718 - val_loss: 0.6196 - val_accuracy: 0.8320\n",
      "Epoch 597/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0659 - accuracy: 0.9765 - val_loss: 0.6147 - val_accuracy: 0.8320\n",
      "Epoch 598/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0656 - accuracy: 0.9777 - val_loss: 0.4552 - val_accuracy: 0.8629\n",
      "Epoch 599/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0564 - accuracy: 0.9799 - val_loss: 0.6671 - val_accuracy: 0.8242\n",
      "Epoch 600/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0627 - accuracy: 0.9766 - val_loss: 1.9145 - val_accuracy: 0.7204\n",
      "Epoch 601/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0568 - accuracy: 0.9789 - val_loss: 0.5422 - val_accuracy: 0.8436\n",
      "Epoch 602/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0674 - accuracy: 0.9742 - val_loss: 0.7023 - val_accuracy: 0.8035\n",
      "Epoch 603/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0797 - accuracy: 0.9713 - val_loss: 0.4751 - val_accuracy: 0.8639\n",
      "Epoch 604/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0761 - accuracy: 0.9697 - val_loss: 0.7095 - val_accuracy: 0.8174\n",
      "Epoch 605/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0702 - accuracy: 0.9757 - val_loss: 0.8520 - val_accuracy: 0.8015\n",
      "Epoch 606/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0584 - accuracy: 0.9785 - val_loss: 0.8557 - val_accuracy: 0.7869\n",
      "Epoch 607/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0587 - accuracy: 0.9807 - val_loss: 0.5999 - val_accuracy: 0.8398\n",
      "Epoch 608/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0628 - accuracy: 0.9773 - val_loss: 0.5839 - val_accuracy: 0.8463\n",
      "Epoch 609/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0604 - accuracy: 0.9785 - val_loss: 0.7198 - val_accuracy: 0.8178\n",
      "Epoch 610/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0820 - accuracy: 0.9703 - val_loss: 2.6214 - val_accuracy: 0.6973\n",
      "Epoch 611/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0657 - accuracy: 0.9733 - val_loss: 1.0097 - val_accuracy: 0.7794\n",
      "Epoch 612/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0616 - accuracy: 0.9770 - val_loss: 0.5392 - val_accuracy: 0.8521\n",
      "Epoch 613/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0687 - accuracy: 0.9763 - val_loss: 0.5934 - val_accuracy: 0.8378\n",
      "Epoch 614/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0731 - accuracy: 0.9748 - val_loss: 1.4547 - val_accuracy: 0.7581\n",
      "Epoch 615/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0641 - accuracy: 0.9742 - val_loss: 0.6366 - val_accuracy: 0.8286\n",
      "Epoch 616/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0647 - accuracy: 0.9785 - val_loss: 0.4785 - val_accuracy: 0.8639\n",
      "Epoch 617/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0648 - accuracy: 0.9761 - val_loss: 0.5871 - val_accuracy: 0.8432\n",
      "Epoch 618/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0705 - accuracy: 0.9732 - val_loss: 0.5382 - val_accuracy: 0.8415\n",
      "Epoch 619/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0732 - accuracy: 0.9743 - val_loss: 0.8208 - val_accuracy: 0.7940\n",
      "Epoch 620/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0635 - accuracy: 0.9778 - val_loss: 0.4960 - val_accuracy: 0.8544\n",
      "Epoch 621/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0617 - accuracy: 0.9767 - val_loss: 0.5393 - val_accuracy: 0.8422\n",
      "Epoch 622/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0654 - accuracy: 0.9754 - val_loss: 0.4512 - val_accuracy: 0.8609\n",
      "Epoch 623/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0666 - accuracy: 0.9757 - val_loss: 0.5197 - val_accuracy: 0.8466\n",
      "Epoch 624/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0612 - accuracy: 0.9789 - val_loss: 0.4390 - val_accuracy: 0.8643\n",
      "Epoch 625/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0700 - accuracy: 0.9751 - val_loss: 0.6250 - val_accuracy: 0.8222\n",
      "Epoch 626/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0710 - accuracy: 0.9732 - val_loss: 1.1040 - val_accuracy: 0.7652\n",
      "Epoch 627/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0620 - accuracy: 0.9763 - val_loss: 1.1373 - val_accuracy: 0.7893\n",
      "Epoch 628/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0592 - accuracy: 0.9792 - val_loss: 0.4382 - val_accuracy: 0.8677\n",
      "Epoch 629/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0627 - accuracy: 0.9769 - val_loss: 0.5751 - val_accuracy: 0.8392\n",
      "Epoch 630/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0784 - accuracy: 0.9695 - val_loss: 0.7259 - val_accuracy: 0.8103\n",
      "Epoch 631/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0583 - accuracy: 0.9788 - val_loss: 0.4553 - val_accuracy: 0.8683\n",
      "Epoch 632/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0786 - accuracy: 0.9708 - val_loss: 1.2730 - val_accuracy: 0.7428\n",
      "Epoch 633/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0666 - accuracy: 0.9765 - val_loss: 0.4280 - val_accuracy: 0.8751\n",
      "Epoch 634/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0706 - accuracy: 0.9752 - val_loss: 0.4504 - val_accuracy: 0.8663\n",
      "Epoch 635/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0613 - accuracy: 0.9773 - val_loss: 0.7298 - val_accuracy: 0.8215\n",
      "Epoch 636/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0621 - accuracy: 0.9797 - val_loss: 0.5145 - val_accuracy: 0.8551\n",
      "Epoch 637/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0580 - accuracy: 0.9788 - val_loss: 0.4973 - val_accuracy: 0.8480\n",
      "Epoch 638/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0652 - accuracy: 0.9763 - val_loss: 0.6559 - val_accuracy: 0.8256\n",
      "Epoch 639/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0571 - accuracy: 0.9788 - val_loss: 0.9111 - val_accuracy: 0.7693\n",
      "Epoch 640/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0575 - accuracy: 0.9808 - val_loss: 0.4705 - val_accuracy: 0.8612\n",
      "Epoch 641/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0670 - accuracy: 0.9739 - val_loss: 0.6240 - val_accuracy: 0.8229\n",
      "Epoch 642/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0573 - accuracy: 0.9795 - val_loss: 0.4610 - val_accuracy: 0.8619\n",
      "Epoch 643/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0592 - accuracy: 0.9785 - val_loss: 0.5744 - val_accuracy: 0.8422\n",
      "Epoch 644/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0630 - accuracy: 0.9773 - val_loss: 0.4581 - val_accuracy: 0.8663\n",
      "Epoch 645/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0535 - accuracy: 0.9816 - val_loss: 0.5000 - val_accuracy: 0.8609\n",
      "Epoch 646/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0607 - accuracy: 0.9771 - val_loss: 0.4891 - val_accuracy: 0.8517\n",
      "Epoch 647/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0595 - accuracy: 0.9784 - val_loss: 0.6320 - val_accuracy: 0.8198\n",
      "Epoch 648/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0506 - accuracy: 0.9825 - val_loss: 0.7236 - val_accuracy: 0.8215\n",
      "Epoch 649/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0631 - accuracy: 0.9754 - val_loss: 0.5809 - val_accuracy: 0.8378\n",
      "Epoch 650/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0693 - accuracy: 0.9740 - val_loss: 0.4543 - val_accuracy: 0.8649\n",
      "Epoch 651/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0619 - accuracy: 0.9771 - val_loss: 0.5219 - val_accuracy: 0.8453\n",
      "Epoch 652/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0621 - accuracy: 0.9766 - val_loss: 0.5199 - val_accuracy: 0.8453\n",
      "Epoch 653/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0582 - accuracy: 0.9774 - val_loss: 0.6474 - val_accuracy: 0.8222\n",
      "Epoch 654/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0716 - accuracy: 0.9717 - val_loss: 0.6721 - val_accuracy: 0.8280\n",
      "Epoch 655/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0597 - accuracy: 0.9774 - val_loss: 0.5173 - val_accuracy: 0.8442\n",
      "Epoch 656/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0559 - accuracy: 0.9792 - val_loss: 0.5746 - val_accuracy: 0.8347\n",
      "Epoch 657/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0735 - accuracy: 0.9731 - val_loss: 0.5727 - val_accuracy: 0.8300\n",
      "Epoch 658/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0591 - accuracy: 0.9786 - val_loss: 0.4691 - val_accuracy: 0.8561\n",
      "Epoch 659/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0706 - accuracy: 0.9720 - val_loss: 0.4368 - val_accuracy: 0.8670\n",
      "Epoch 660/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0651 - accuracy: 0.9762 - val_loss: 1.1261 - val_accuracy: 0.7822\n",
      "Epoch 661/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0622 - accuracy: 0.9789 - val_loss: 0.6778 - val_accuracy: 0.8191\n",
      "Epoch 662/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0620 - accuracy: 0.9767 - val_loss: 1.2612 - val_accuracy: 0.7696\n",
      "Epoch 663/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0675 - accuracy: 0.9747 - val_loss: 0.4767 - val_accuracy: 0.8582\n",
      "Epoch 664/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0563 - accuracy: 0.9811 - val_loss: 0.4826 - val_accuracy: 0.8558\n",
      "Epoch 665/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0555 - accuracy: 0.9808 - val_loss: 0.4707 - val_accuracy: 0.8605\n",
      "Epoch 666/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0608 - accuracy: 0.9792 - val_loss: 0.5920 - val_accuracy: 0.8358\n",
      "Epoch 667/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0611 - accuracy: 0.9781 - val_loss: 0.4381 - val_accuracy: 0.8680\n",
      "Epoch 668/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0658 - accuracy: 0.9776 - val_loss: 0.5665 - val_accuracy: 0.8442\n",
      "Epoch 669/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0582 - accuracy: 0.9789 - val_loss: 0.9675 - val_accuracy: 0.7947\n",
      "Epoch 670/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0780 - accuracy: 0.9729 - val_loss: 0.6236 - val_accuracy: 0.8246\n",
      "Epoch 671/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0674 - accuracy: 0.9755 - val_loss: 0.5721 - val_accuracy: 0.8375\n",
      "Epoch 672/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0551 - accuracy: 0.9793 - val_loss: 0.4808 - val_accuracy: 0.8521\n",
      "Epoch 673/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0651 - accuracy: 0.9757 - val_loss: 0.4385 - val_accuracy: 0.8619\n",
      "Epoch 674/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0663 - accuracy: 0.9761 - val_loss: 0.4785 - val_accuracy: 0.8500\n",
      "Epoch 675/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0590 - accuracy: 0.9791 - val_loss: 0.5009 - val_accuracy: 0.8456\n",
      "Epoch 676/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.4318 - val_accuracy: 0.8639\n",
      "Epoch 677/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.4695 - val_accuracy: 0.8561\n",
      "Epoch 678/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0512 - accuracy: 0.9820 - val_loss: 0.4624 - val_accuracy: 0.8629\n",
      "Epoch 679/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0538 - accuracy: 0.9792 - val_loss: 0.4891 - val_accuracy: 0.8585\n",
      "Epoch 680/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0569 - accuracy: 0.9801 - val_loss: 0.4339 - val_accuracy: 0.8639\n",
      "Epoch 681/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0482 - accuracy: 0.9827 - val_loss: 0.5140 - val_accuracy: 0.8442\n",
      "Epoch 682/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0561 - accuracy: 0.9786 - val_loss: 0.5482 - val_accuracy: 0.8327\n",
      "Epoch 683/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0691 - accuracy: 0.9758 - val_loss: 0.4835 - val_accuracy: 0.8463\n",
      "Epoch 684/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0590 - accuracy: 0.9788 - val_loss: 0.4137 - val_accuracy: 0.8626\n",
      "Epoch 685/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0641 - accuracy: 0.9765 - val_loss: 0.5399 - val_accuracy: 0.8385\n",
      "Epoch 686/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0547 - accuracy: 0.9803 - val_loss: 0.6909 - val_accuracy: 0.8086\n",
      "Epoch 687/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0671 - accuracy: 0.9757 - val_loss: 0.5597 - val_accuracy: 0.8263\n",
      "Epoch 688/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0634 - accuracy: 0.9777 - val_loss: 0.6948 - val_accuracy: 0.8059\n",
      "Epoch 689/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0615 - accuracy: 0.9757 - val_loss: 0.7759 - val_accuracy: 0.8157racy: 0.97\n",
      "Epoch 690/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0617 - accuracy: 0.9774 - val_loss: 0.4638 - val_accuracy: 0.8633\n",
      "Epoch 691/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0665 - accuracy: 0.9769 - val_loss: 1.2265 - val_accuracy: 0.7465\n",
      "Epoch 692/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0640 - accuracy: 0.9744 - val_loss: 0.7515 - val_accuracy: 0.7991\n",
      "Epoch 693/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0627 - accuracy: 0.9770 - val_loss: 0.5201 - val_accuracy: 0.8459\n",
      "Epoch 694/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0545 - accuracy: 0.9785 - val_loss: 0.6203 - val_accuracy: 0.8235\n",
      "Epoch 695/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0586 - accuracy: 0.9788 - val_loss: 0.5638 - val_accuracy: 0.8351\n",
      "Epoch 696/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0550 - accuracy: 0.9791 - val_loss: 0.5825 - val_accuracy: 0.8320\n",
      "Epoch 697/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0609 - accuracy: 0.9781 - val_loss: 0.5399 - val_accuracy: 0.8439\n",
      "Epoch 698/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0570 - accuracy: 0.9805 - val_loss: 0.5646 - val_accuracy: 0.8436\n",
      "Epoch 699/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0667 - accuracy: 0.9737 - val_loss: 0.6693 - val_accuracy: 0.8049\n",
      "Epoch 700/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0559 - accuracy: 0.9784 - val_loss: 0.5355 - val_accuracy: 0.8337\n",
      "------------------------ 测试中---------------------------\n",
      "2947/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 234us/sample - loss: 0.2678 - accuracy: 0.8337\n",
      "Baseline Error: 16.63%\n",
      "Size of the unpruned model before compression: 2.70 Mb\n",
      "Size of the unpruned model after compression: 2.44 Mb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import csv\n",
    "import tempfile\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.keras import backend as K\n",
    "from utils.utilities import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(813306)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allocator_type = 'BFC'  # A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "#config.gpu_options.allow_growth = True\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "#构建数据集 channel_last\n",
    "#构建数据集 channel_last\n",
    "def load_data():    \n",
    "    X_train, labels_train, list_ch_train = read_data(data_path=\"../data/HAR_Dataset\", split=\"train\") # train\n",
    "    X_test, labels_test, list_ch_test = read_data(data_path=\"../data/HAR_Dataset\", split=\"test\") # test\n",
    "    assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "    x_train = X_train[:,:,np.newaxis,:]\n",
    "    x_val = X_test[:,:,np.newaxis,:]\n",
    "    x_train = x_train[:,:,:,3:6]\n",
    "    x_val = x_val[:,:,:,3:6]\n",
    "    y_train = to_categorical(labels_train)\n",
    "    y_val = to_categorical(labels_test)\n",
    "    return (x_train,y_train),(x_val,y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_resnet(input_shape, n_feature_maps, nb_classes, dropout):\n",
    "    print('build conv_x')\n",
    "    x = Input(shape=(input_shape))\n",
    "\n",
    "    x_total = keras.layers.Conv2D(10, (17, 1),strides = (1,1), padding='same')(x)\n",
    "    conv_x = keras.layers.BatchNormalization()(x_total)  # 853\n",
    "\n",
    " \n",
    "    conv_x = keras.layers.Conv2D(n_feature_maps, (17, 1), padding='same')(conv_x)  # input size == ouput size\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "\n",
    "    print('build conv_y')\n",
    "    conv_y = keras.layers.Conv2D(n_feature_maps * 2, (17, 1), padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "\n",
    "    conv_y = Dropout(dropout)(conv_y)\n",
    "    print('build conv_z')\n",
    "    conv_z = keras.layers.Conv2D(n_feature_maps, (9, 1), padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps)  # 若当前输出和跨层连接的x，通道数不同，则采用1*1卷积使得通道数相同\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = keras.layers.Conv2D(n_feature_maps, (1, 1), padding='same')(x_total)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = keras.layers.BatchNormalization()(x_total)\n",
    "\n",
    "    print('Merging skip connection')\n",
    "    # y = merge([shortcut_y, conv_z], mode='sum')\n",
    "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "\n",
    "    full = keras.layers.GlobalAveragePooling2D()(y)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    print('        -- model was built.')\n",
    "    return x, out\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = 7\n",
    "    channels = 3\n",
    "    dropout = 0.2\n",
    "    nb_epochs = 700\n",
    "    batch_size = 50\n",
    "    data_row = 128\n",
    "    data_column = 1\n",
    "    trainpath = r'./data'\n",
    "\n",
    "    (x_train,y_train),(x_val,y_val) = load_data()\n",
    "\n",
    "\n",
    "    tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "    input_shape = (data_row, data_column,channels)\n",
    "\n",
    "    print('train dataset size:',x_train.shape[0])\n",
    "    print('validation dataset size:',x_val.shape[0])\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    x, y = build_resnet(input_shape, 64, num, dropout)  # 建立resnet只考虑了单个example\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.9,\n",
    "                                  patience=20, min_lr=0.00005)\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n",
    "                     verbose=1, validation_data=(x_val, y_val), callbacks=[reduce_lr])  # 回调函数会在训练的时候适当被调用\n",
    "\n",
    "\n",
    "    # 测试\n",
    "    print(\"------------------------ 测试中---------------------------\")\n",
    "    #evaluation of the model\n",
    "    scores = model.evaluate(x_val,y_val)\n",
    "    print('Baseline Error: %.2f%%'%(100 * (1 - scores[1])))\n",
    "    keras.models.save_model(model, '../model/test_resnet_v4.h5')\n",
    "    keras_file = '../model/test_resnet_v4.h5'\n",
    "    _, zip1 = tempfile.mkstemp('.zip') \n",
    "    with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(keras_file)\n",
    "    print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "          (os.path.getsize(keras_file) / float(2**20)))\n",
    "    print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "          (os.path.getsize(zip1) / float(2**20)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6-9 channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 7352\n",
      "validation dataset size: 2947\n",
      "build conv_x\n",
      "build conv_y\n",
      "build conv_z\n",
      "Merging skip connection\n",
      "        -- model was built.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 1, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 1, 10)   520         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 1, 10)   40          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 1, 64)   10944       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 1, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 1, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 1, 128)  139392      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 1, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 1, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 1, 128)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 128, 1, 64)   704         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 1, 64)   73792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 128, 1, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128, 1, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 1, 64)   0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 1, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            455         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 227,127\n",
      "Trainable params: 226,467\n",
      "Non-trainable params: 660\n",
      "__________________________________________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/700\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015F41E5EBF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x0000015F41E5EBF8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: No module named 'tensorflow_core.estimator'\n",
      "7352/7352 [==============================] - 4s 491us/sample - loss: 0.3006 - accuracy: 0.9044 - val_loss: 2.1213 - val_accuracy: 0.3865\n",
      "Epoch 2/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1720 - accuracy: 0.9377 - val_loss: 0.8271 - val_accuracy: 0.6563\n",
      "Epoch 3/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1432 - accuracy: 0.9436 - val_loss: 0.2696 - val_accuracy: 0.9131\n",
      "Epoch 4/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1450 - accuracy: 0.9452 - val_loss: 0.4747 - val_accuracy: 0.8361\n",
      "Epoch 5/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1354 - accuracy: 0.9426 - val_loss: 0.3262 - val_accuracy: 0.9101\n",
      "Epoch 6/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1306 - accuracy: 0.9457 - val_loss: 0.3893 - val_accuracy: 0.9016\n",
      "Epoch 7/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1284 - accuracy: 0.9505 - val_loss: 0.2631 - val_accuracy: 0.9158\n",
      "Epoch 8/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1259 - accuracy: 0.9476 - val_loss: 0.3613 - val_accuracy: 0.9033\n",
      "Epoch 9/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1399 - accuracy: 0.9441 - val_loss: 0.4634 - val_accuracy: 0.8392\n",
      "Epoch 10/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1257 - accuracy: 0.9475 - val_loss: 0.2803 - val_accuracy: 0.9036\n",
      "Epoch 11/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1358 - accuracy: 0.9450 - val_loss: 0.2786 - val_accuracy: 0.9138\n",
      "Epoch 12/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1222 - accuracy: 0.9461 - val_loss: 0.3287 - val_accuracy: 0.9036\n",
      "Epoch 13/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.1290 - accuracy: 0.9475 - val_loss: 0.2991 - val_accuracy: 0.9067\n",
      "Epoch 14/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1217 - accuracy: 0.9498 - val_loss: 0.3415 - val_accuracy: 0.9077\n",
      "Epoch 15/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1154 - accuracy: 0.9509 - val_loss: 0.3287 - val_accuracy: 0.9053\n",
      "Epoch 16/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1156 - accuracy: 0.9529 - val_loss: 0.3375 - val_accuracy: 0.9114\n",
      "Epoch 17/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1306 - accuracy: 0.9476 - val_loss: 0.4611 - val_accuracy: 0.8714\n",
      "Epoch 18/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1192 - accuracy: 0.9501 - val_loss: 0.2967 - val_accuracy: 0.9158\n",
      "Epoch 19/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1146 - accuracy: 0.9535 - val_loss: 0.2682 - val_accuracy: 0.9247\n",
      "Epoch 20/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1272 - accuracy: 0.9464 - val_loss: 0.2854 - val_accuracy: 0.9162\n",
      "Epoch 21/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1193 - accuracy: 0.9498 - val_loss: 0.2496 - val_accuracy: 0.9169\n",
      "Epoch 22/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1185 - accuracy: 0.9483 - val_loss: 0.2890 - val_accuracy: 0.9186\n",
      "Epoch 23/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1104 - accuracy: 0.9539 - val_loss: 0.3029 - val_accuracy: 0.9355\n",
      "Epoch 24/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1088 - accuracy: 0.9529 - val_loss: 0.3109 - val_accuracy: 0.9189\n",
      "Epoch 25/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1093 - accuracy: 0.9514 - val_loss: 0.2905 - val_accuracy: 0.9321\n",
      "Epoch 26/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1144 - accuracy: 0.9497 - val_loss: 0.5194 - val_accuracy: 0.8897\n",
      "Epoch 27/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1146 - accuracy: 0.9498 - val_loss: 0.3482 - val_accuracy: 0.9223\n",
      "Epoch 28/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1045 - accuracy: 0.9555 - val_loss: 0.3457 - val_accuracy: 0.9182\n",
      "Epoch 29/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.1028 - accuracy: 0.9543 - val_loss: 0.3849 - val_accuracy: 0.9169\n",
      "Epoch 30/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.1119 - accuracy: 0.9504 - val_loss: 0.4088 - val_accuracy: 0.9199\n",
      "Epoch 31/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1377 - accuracy: 0.9440 - val_loss: 0.3789 - val_accuracy: 0.8843\n",
      "Epoch 32/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1138 - accuracy: 0.9517 - val_loss: 0.3382 - val_accuracy: 0.9186\n",
      "Epoch 33/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1261 - accuracy: 0.9463 - val_loss: 0.5341 - val_accuracy: 0.8588\n",
      "Epoch 34/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.1112 - accuracy: 0.9527 - val_loss: 0.5519 - val_accuracy: 0.8531\n",
      "Epoch 35/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1129 - accuracy: 0.9516 - val_loss: 0.4086 - val_accuracy: 0.9016\n",
      "Epoch 36/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1016 - accuracy: 0.9529 - val_loss: 0.4140 - val_accuracy: 0.8992\n",
      "Epoch 37/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0986 - accuracy: 0.9562 - val_loss: 0.4557 - val_accuracy: 0.8809\n",
      "Epoch 38/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1040 - accuracy: 0.9539 - val_loss: 0.3757 - val_accuracy: 0.8962\n",
      "Epoch 39/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.1118 - accuracy: 0.9523 - val_loss: 0.3160 - val_accuracy: 0.9108\n",
      "Epoch 40/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1257 - accuracy: 0.9452 - val_loss: 0.3823 - val_accuracy: 0.8941\n",
      "Epoch 41/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0966 - accuracy: 0.9572 - val_loss: 0.3550 - val_accuracy: 0.8979\n",
      "Epoch 42/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0981 - accuracy: 0.9547 - val_loss: 0.3882 - val_accuracy: 0.9013\n",
      "Epoch 43/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1052 - accuracy: 0.9535 - val_loss: 0.3918 - val_accuracy: 0.9101\n",
      "Epoch 44/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1163 - accuracy: 0.9493 - val_loss: 0.4174 - val_accuracy: 0.8846\n",
      "Epoch 45/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0997 - accuracy: 0.9561 - val_loss: 0.4498 - val_accuracy: 0.8670\n",
      "Epoch 46/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.1233 - accuracy: 0.9487 - val_loss: 1.4982 - val_accuracy: 0.6468\n",
      "Epoch 47/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.1164 - accuracy: 0.9494 - val_loss: 0.3474 - val_accuracy: 0.9067\n",
      "Epoch 48/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1036 - accuracy: 0.9540 - val_loss: 0.2990 - val_accuracy: 0.9172\n",
      "Epoch 49/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0977 - accuracy: 0.9563 - val_loss: 0.3200 - val_accuracy: 0.9226\n",
      "Epoch 50/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0937 - accuracy: 0.9576 - val_loss: 0.3835 - val_accuracy: 0.9043\n",
      "Epoch 51/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0994 - accuracy: 0.9539 - val_loss: 0.4086 - val_accuracy: 0.9050\n",
      "Epoch 52/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0933 - accuracy: 0.9584 - val_loss: 0.3504 - val_accuracy: 0.9084\n",
      "Epoch 53/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0959 - accuracy: 0.9553 - val_loss: 0.4719 - val_accuracy: 0.8921\n",
      "Epoch 54/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0977 - accuracy: 0.9562 - val_loss: 0.3230 - val_accuracy: 0.9169\n",
      "Epoch 55/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0935 - accuracy: 0.9563 - val_loss: 0.3589 - val_accuracy: 0.9135\n",
      "Epoch 56/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0937 - accuracy: 0.9572 - val_loss: 0.3926 - val_accuracy: 0.9084\n",
      "Epoch 57/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0930 - accuracy: 0.9576 - val_loss: 0.3413 - val_accuracy: 0.9067\n",
      "Epoch 58/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0937 - accuracy: 0.9576 - val_loss: 0.3771 - val_accuracy: 0.9050\n",
      "Epoch 59/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0982 - accuracy: 0.9550 - val_loss: 0.3919 - val_accuracy: 0.9169\n",
      "Epoch 60/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0956 - accuracy: 0.9563 - val_loss: 0.4538 - val_accuracy: 0.8884\n",
      "Epoch 61/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0986 - accuracy: 0.9555 - val_loss: 0.4839 - val_accuracy: 0.8833\n",
      "Epoch 62/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1131 - accuracy: 0.9527 - val_loss: 0.3366 - val_accuracy: 0.9063\n",
      "Epoch 63/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0953 - accuracy: 0.9587 - val_loss: 0.3714 - val_accuracy: 0.9016\n",
      "Epoch 64/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0937 - accuracy: 0.9593 - val_loss: 0.3473 - val_accuracy: 0.8999\n",
      "Epoch 65/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0959 - accuracy: 0.9562 - val_loss: 0.3976 - val_accuracy: 0.9101\n",
      "Epoch 66/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0964 - accuracy: 0.9592 - val_loss: 0.3847 - val_accuracy: 0.9013\n",
      "Epoch 67/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0948 - accuracy: 0.9580 - val_loss: 0.3773 - val_accuracy: 0.9036\n",
      "Epoch 68/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0895 - accuracy: 0.9582 - val_loss: 0.4109 - val_accuracy: 0.9087\n",
      "Epoch 69/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0919 - accuracy: 0.9607 - val_loss: 0.3777 - val_accuracy: 0.9013\n",
      "Epoch 70/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0915 - accuracy: 0.9581 - val_loss: 0.3907 - val_accuracy: 0.9013\n",
      "Epoch 71/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0965 - accuracy: 0.9574 - val_loss: 0.3649 - val_accuracy: 0.9131\n",
      "Epoch 72/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0895 - accuracy: 0.9612 - val_loss: 0.3725 - val_accuracy: 0.9111\n",
      "Epoch 73/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0945 - accuracy: 0.9559 - val_loss: 0.3871 - val_accuracy: 0.9023\n",
      "Epoch 74/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0992 - accuracy: 0.9553 - val_loss: 0.3685 - val_accuracy: 0.9135\n",
      "Epoch 75/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0893 - accuracy: 0.9596 - val_loss: 0.3827 - val_accuracy: 0.9026\n",
      "Epoch 76/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0886 - accuracy: 0.9585 - val_loss: 0.3685 - val_accuracy: 0.9148\n",
      "Epoch 77/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0909 - accuracy: 0.9567 - val_loss: 0.3702 - val_accuracy: 0.9186\n",
      "Epoch 78/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.1033 - accuracy: 0.9546 - val_loss: 0.4037 - val_accuracy: 0.9026\n",
      "Epoch 79/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0947 - accuracy: 0.9567 - val_loss: 0.3131 - val_accuracy: 0.9087\n",
      "Epoch 80/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1040 - accuracy: 0.9542 - val_loss: 0.3733 - val_accuracy: 0.9101\n",
      "Epoch 81/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0930 - accuracy: 0.9577 - val_loss: 0.3469 - val_accuracy: 0.9125\n",
      "Epoch 82/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0949 - accuracy: 0.9580 - val_loss: 0.3386 - val_accuracy: 0.8982\n",
      "Epoch 83/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0903 - accuracy: 0.9610 - val_loss: 0.3740 - val_accuracy: 0.9108\n",
      "Epoch 84/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0916 - accuracy: 0.9588 - val_loss: 0.3695 - val_accuracy: 0.9172\n",
      "Epoch 85/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0901 - accuracy: 0.9601 - val_loss: 0.3505 - val_accuracy: 0.9169\n",
      "Epoch 86/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0920 - accuracy: 0.9580 - val_loss: 0.3302 - val_accuracy: 0.9101\n",
      "Epoch 87/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0976 - accuracy: 0.9570 - val_loss: 0.4252 - val_accuracy: 0.9111\n",
      "Epoch 88/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0924 - accuracy: 0.9599 - val_loss: 0.5546 - val_accuracy: 0.8497\n",
      "Epoch 89/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0916 - accuracy: 0.9578 - val_loss: 0.4350 - val_accuracy: 0.9128\n",
      "Epoch 90/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0889 - accuracy: 0.9577 - val_loss: 0.4140 - val_accuracy: 0.9152\n",
      "Epoch 91/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0852 - accuracy: 0.9604 - val_loss: 0.3894 - val_accuracy: 0.9111\n",
      "Epoch 92/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0873 - accuracy: 0.9588 - val_loss: 0.3724 - val_accuracy: 0.9060\n",
      "Epoch 93/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0868 - accuracy: 0.9618 - val_loss: 0.3946 - val_accuracy: 0.9186\n",
      "Epoch 94/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0896 - accuracy: 0.9611 - val_loss: 0.4306 - val_accuracy: 0.9046\n",
      "Epoch 95/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0848 - accuracy: 0.9614 - val_loss: 0.4444 - val_accuracy: 0.9182\n",
      "Epoch 96/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0897 - accuracy: 0.9601 - val_loss: 0.4247 - val_accuracy: 0.8945\n",
      "Epoch 97/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0966 - accuracy: 0.9555 - val_loss: 0.4079 - val_accuracy: 0.8975\n",
      "Epoch 98/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0892 - accuracy: 0.9584 - val_loss: 0.4600 - val_accuracy: 0.8843\n",
      "Epoch 99/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0888 - accuracy: 0.9587 - val_loss: 0.3851 - val_accuracy: 0.9226\n",
      "Epoch 100/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0887 - accuracy: 0.9621 - val_loss: 0.3972 - val_accuracy: 0.9270\n",
      "Epoch 101/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0821 - accuracy: 0.9630 - val_loss: 0.4318 - val_accuracy: 0.9023\n",
      "Epoch 102/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0867 - accuracy: 0.9606 - val_loss: 0.3949 - val_accuracy: 0.9165\n",
      "Epoch 103/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0866 - accuracy: 0.9599 - val_loss: 0.3967 - val_accuracy: 0.9182\n",
      "Epoch 104/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0922 - accuracy: 0.9596 - val_loss: 0.4507 - val_accuracy: 0.9121\n",
      "Epoch 105/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0847 - accuracy: 0.9615 - val_loss: 0.3663 - val_accuracy: 0.9213\n",
      "Epoch 106/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0881 - accuracy: 0.9574 - val_loss: 0.4023 - val_accuracy: 0.9182\n",
      "Epoch 107/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0920 - accuracy: 0.9600 - val_loss: 0.4153 - val_accuracy: 0.9196\n",
      "Epoch 108/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0940 - accuracy: 0.9587 - val_loss: 0.3653 - val_accuracy: 0.9118\n",
      "Epoch 109/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0889 - accuracy: 0.9600 - val_loss: 0.3648 - val_accuracy: 0.9216\n",
      "Epoch 110/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0976 - accuracy: 0.9573 - val_loss: 0.3865 - val_accuracy: 0.9281\n",
      "Epoch 111/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0863 - accuracy: 0.9625 - val_loss: 0.4120 - val_accuracy: 0.9125\n",
      "Epoch 112/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0839 - accuracy: 0.9629 - val_loss: 0.3932 - val_accuracy: 0.9006\n",
      "Epoch 113/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0995 - accuracy: 0.9577 - val_loss: 0.5793 - val_accuracy: 0.8955\n",
      "Epoch 114/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0960 - accuracy: 0.9578 - val_loss: 0.4110 - val_accuracy: 0.9223\n",
      "Epoch 115/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0874 - accuracy: 0.9612 - val_loss: 0.3665 - val_accuracy: 0.9162\n",
      "Epoch 116/700\n",
      "7352/7352 [==============================] - 2s 316us/sample - loss: 0.0869 - accuracy: 0.9592 - val_loss: 0.4001 - val_accuracy: 0.9080\n",
      "Epoch 117/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0899 - accuracy: 0.9580 - val_loss: 0.3819 - val_accuracy: 0.9091\n",
      "Epoch 118/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0861 - accuracy: 0.9600 - val_loss: 0.4309 - val_accuracy: 0.9274\n",
      "Epoch 119/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0864 - accuracy: 0.9582 - val_loss: 0.3922 - val_accuracy: 0.9257\n",
      "Epoch 120/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0873 - accuracy: 0.9578 - val_loss: 0.4545 - val_accuracy: 0.9053\n",
      "Epoch 121/700\n",
      "7352/7352 [==============================] - 2s 316us/sample - loss: 0.0906 - accuracy: 0.9601 - val_loss: 0.4171 - val_accuracy: 0.9114\n",
      "Epoch 122/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0878 - accuracy: 0.9612 - val_loss: 0.4121 - val_accuracy: 0.9209\n",
      "Epoch 123/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0854 - accuracy: 0.9607 - val_loss: 0.3901 - val_accuracy: 0.9172\n",
      "Epoch 124/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0873 - accuracy: 0.9604 - val_loss: 0.4079 - val_accuracy: 0.9247\n",
      "Epoch 125/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0832 - accuracy: 0.9619 - val_loss: 0.4814 - val_accuracy: 0.8999\n",
      "Epoch 126/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0889 - accuracy: 0.9601 - val_loss: 0.4277 - val_accuracy: 0.9084\n",
      "Epoch 127/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0839 - accuracy: 0.9608 - val_loss: 0.4254 - val_accuracy: 0.9002\n",
      "Epoch 128/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0837 - accuracy: 0.9631 - val_loss: 0.4232 - val_accuracy: 0.9192\n",
      "Epoch 129/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0812 - accuracy: 0.9610 - val_loss: 0.4521 - val_accuracy: 0.9141\n",
      "Epoch 130/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0831 - accuracy: 0.9606 - val_loss: 0.4042 - val_accuracy: 0.9148\n",
      "Epoch 131/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0813 - accuracy: 0.9618 - val_loss: 0.4347 - val_accuracy: 0.9114\n",
      "Epoch 132/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0858 - accuracy: 0.9596 - val_loss: 0.3983 - val_accuracy: 0.9135\n",
      "Epoch 133/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0843 - accuracy: 0.9614 - val_loss: 0.3992 - val_accuracy: 0.9104\n",
      "Epoch 134/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0799 - accuracy: 0.9616 - val_loss: 0.4036 - val_accuracy: 0.9070\n",
      "Epoch 135/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0858 - accuracy: 0.9587 - val_loss: 0.4004 - val_accuracy: 0.9165\n",
      "Epoch 136/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0875 - accuracy: 0.9606 - val_loss: 0.5049 - val_accuracy: 0.9009\n",
      "Epoch 137/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0847 - accuracy: 0.9618 - val_loss: 0.4624 - val_accuracy: 0.9063curacy: 0. - ETA: 0s - loss: 0.0847 - accuracy: 0.\n",
      "Epoch 138/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0816 - accuracy: 0.9625 - val_loss: 0.4815 - val_accuracy: 0.9118\n",
      "Epoch 139/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0896 - accuracy: 0.9608 - val_loss: 0.4714 - val_accuracy: 0.9141\n",
      "Epoch 140/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0811 - accuracy: 0.9641 - val_loss: 0.5192 - val_accuracy: 0.8999\n",
      "Epoch 141/700\n",
      "7352/7352 [==============================] - 2s 333us/sample - loss: 0.0850 - accuracy: 0.9608 - val_loss: 0.4753 - val_accuracy: 0.9118\n",
      "Epoch 142/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0931 - accuracy: 0.9576 - val_loss: 0.3833 - val_accuracy: 0.9250\n",
      "Epoch 143/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0837 - accuracy: 0.9623 - val_loss: 0.4068 - val_accuracy: 0.9158\n",
      "Epoch 144/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0827 - accuracy: 0.9630 - val_loss: 0.4325 - val_accuracy: 0.9118\n",
      "Epoch 145/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0846 - accuracy: 0.9616 - val_loss: 0.4622 - val_accuracy: 0.9141\n",
      "Epoch 146/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0793 - accuracy: 0.9619 - val_loss: 0.4240 - val_accuracy: 0.9135\n",
      "Epoch 147/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0823 - accuracy: 0.9612 - val_loss: 0.4362 - val_accuracy: 0.9111\n",
      "Epoch 148/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0837 - accuracy: 0.9614 - val_loss: 0.4203 - val_accuracy: 0.9179\n",
      "Epoch 149/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0802 - accuracy: 0.9618 - val_loss: 0.5242 - val_accuracy: 0.9084\n",
      "Epoch 150/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0863 - accuracy: 0.9607 - val_loss: 0.4192 - val_accuracy: 0.9182\n",
      "Epoch 151/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0844 - accuracy: 0.9614 - val_loss: 0.4330 - val_accuracy: 0.9196\n",
      "Epoch 152/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0834 - accuracy: 0.9599 - val_loss: 0.4779 - val_accuracy: 0.9067\n",
      "Epoch 153/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0844 - accuracy: 0.9608 - val_loss: 0.4933 - val_accuracy: 0.9070\n",
      "Epoch 154/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0830 - accuracy: 0.9600 - val_loss: 0.4047 - val_accuracy: 0.9196\n",
      "Epoch 155/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0787 - accuracy: 0.9614 - val_loss: 0.4586 - val_accuracy: 0.8965\n",
      "Epoch 156/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0829 - accuracy: 0.9606 - val_loss: 0.4340 - val_accuracy: 0.9125\n",
      "Epoch 157/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0822 - accuracy: 0.9608 - val_loss: 0.4950 - val_accuracy: 0.9094\n",
      "Epoch 158/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0813 - accuracy: 0.9623 - val_loss: 0.4319 - val_accuracy: 0.9165\n",
      "Epoch 159/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0892 - accuracy: 0.9585 - val_loss: 0.4182 - val_accuracy: 0.9192\n",
      "Epoch 160/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0786 - accuracy: 0.9649 - val_loss: 0.4381 - val_accuracy: 0.8992\n",
      "Epoch 161/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0813 - accuracy: 0.9614 - val_loss: 0.4307 - val_accuracy: 0.9148\n",
      "Epoch 162/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0832 - accuracy: 0.9612 - val_loss: 0.4820 - val_accuracy: 0.8999\n",
      "Epoch 163/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0786 - accuracy: 0.9637 - val_loss: 0.3890 - val_accuracy: 0.9209\n",
      "Epoch 164/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0779 - accuracy: 0.9656 - val_loss: 0.4416 - val_accuracy: 0.9131\n",
      "Epoch 165/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0798 - accuracy: 0.9642 - val_loss: 0.4503 - val_accuracy: 0.9057\n",
      "Epoch 166/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0931 - accuracy: 0.9574 - val_loss: 0.4333 - val_accuracy: 0.9118\n",
      "Epoch 167/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0883 - accuracy: 0.9606 - val_loss: 0.7664 - val_accuracy: 0.8571\n",
      "Epoch 168/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.1009 - accuracy: 0.9580 - val_loss: 0.4894 - val_accuracy: 0.9111\n",
      "Epoch 169/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0816 - accuracy: 0.9630 - val_loss: 0.4656 - val_accuracy: 0.9013\n",
      "Epoch 170/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0812 - accuracy: 0.9637 - val_loss: 0.4491 - val_accuracy: 0.9063\n",
      "Epoch 171/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0821 - accuracy: 0.9591 - val_loss: 0.5029 - val_accuracy: 0.9141\n",
      "Epoch 172/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0814 - accuracy: 0.9626 - val_loss: 0.4980 - val_accuracy: 0.9135\n",
      "Epoch 173/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0847 - accuracy: 0.9625 - val_loss: 0.4681 - val_accuracy: 0.9179\n",
      "Epoch 174/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0826 - accuracy: 0.9626 - val_loss: 0.4594 - val_accuracy: 0.9209\n",
      "Epoch 175/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0862 - accuracy: 0.9604 - val_loss: 0.4488 - val_accuracy: 0.9108\n",
      "Epoch 176/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0834 - accuracy: 0.9633 - val_loss: 0.4548 - val_accuracy: 0.9094\n",
      "Epoch 177/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0798 - accuracy: 0.9631 - val_loss: 0.4515 - val_accuracy: 0.9104\n",
      "Epoch 178/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0792 - accuracy: 0.9648 - val_loss: 0.4888 - val_accuracy: 0.8999\n",
      "Epoch 179/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0788 - accuracy: 0.9644 - val_loss: 0.4895 - val_accuracy: 0.8965\n",
      "Epoch 180/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0803 - accuracy: 0.9637 - val_loss: 0.4684 - val_accuracy: 0.9121\n",
      "Epoch 181/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0801 - accuracy: 0.9637 - val_loss: 0.5798 - val_accuracy: 0.8975\n",
      "Epoch 182/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0845 - accuracy: 0.9625 - val_loss: 0.5390 - val_accuracy: 0.8982\n",
      "Epoch 183/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0794 - accuracy: 0.9641 - val_loss: 0.4910 - val_accuracy: 0.9074\n",
      "Epoch 184/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0856 - accuracy: 0.9629 - val_loss: 0.4563 - val_accuracy: 0.9033 - l\n",
      "Epoch 185/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0849 - accuracy: 0.9625 - val_loss: 0.4166 - val_accuracy: 0.9182\n",
      "Epoch 186/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0785 - accuracy: 0.9656 - val_loss: 0.4497 - val_accuracy: 0.9158\n",
      "Epoch 187/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0787 - accuracy: 0.9627 - val_loss: 0.4485 - val_accuracy: 0.9111\n",
      "Epoch 188/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0806 - accuracy: 0.9646 - val_loss: 0.4387 - val_accuracy: 0.9097\n",
      "Epoch 189/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0808 - accuracy: 0.9619 - val_loss: 0.4565 - val_accuracy: 0.9077\n",
      "Epoch 190/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0760 - accuracy: 0.9668 - val_loss: 0.4601 - val_accuracy: 0.8989\n",
      "Epoch 191/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0805 - accuracy: 0.9637 - val_loss: 0.4814 - val_accuracy: 0.9060\n",
      "Epoch 192/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0764 - accuracy: 0.9645 - val_loss: 0.4454 - val_accuracy: 0.9155\n",
      "Epoch 193/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0821 - accuracy: 0.9615 - val_loss: 0.5425 - val_accuracy: 0.9019\n",
      "Epoch 194/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0785 - accuracy: 0.9631 - val_loss: 0.5010 - val_accuracy: 0.9084\n",
      "Epoch 195/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0870 - accuracy: 0.9623 - val_loss: 0.4811 - val_accuracy: 0.8999\n",
      "Epoch 196/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0778 - accuracy: 0.9618 - val_loss: 0.4868 - val_accuracy: 0.9026\n",
      "Epoch 197/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0793 - accuracy: 0.9625 - val_loss: 0.4498 - val_accuracy: 0.9152\n",
      "Epoch 198/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0772 - accuracy: 0.9641 - val_loss: 0.4544 - val_accuracy: 0.8901\n",
      "Epoch 199/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0791 - accuracy: 0.9634 - val_loss: 0.4753 - val_accuracy: 0.9033\n",
      "Epoch 200/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0770 - accuracy: 0.9638 - val_loss: 0.4534 - val_accuracy: 0.9131\n",
      "Epoch 201/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0796 - accuracy: 0.9629 - val_loss: 0.4986 - val_accuracy: 0.9091\n",
      "Epoch 202/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0809 - accuracy: 0.9633 - val_loss: 0.6137 - val_accuracy: 0.9053\n",
      "Epoch 203/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0818 - accuracy: 0.9618 - val_loss: 0.4631 - val_accuracy: 0.9053\n",
      "Epoch 204/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0867 - accuracy: 0.9630 - val_loss: 0.4278 - val_accuracy: 0.9074\n",
      "Epoch 205/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0801 - accuracy: 0.9631 - val_loss: 0.4497 - val_accuracy: 0.9104\n",
      "Epoch 206/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0816 - accuracy: 0.9612 - val_loss: 0.4149 - val_accuracy: 0.9091\n",
      "Epoch 207/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0767 - accuracy: 0.9653 - val_loss: 0.4374 - val_accuracy: 0.8989\n",
      "Epoch 208/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0788 - accuracy: 0.9630 - val_loss: 0.4223 - val_accuracy: 0.9084\n",
      "Epoch 209/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0769 - accuracy: 0.9652 - val_loss: 0.4032 - val_accuracy: 0.9033\n",
      "Epoch 210/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0781 - accuracy: 0.9625 - val_loss: 0.4465 - val_accuracy: 0.8846\n",
      "Epoch 211/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0789 - accuracy: 0.9629 - val_loss: 0.3979 - val_accuracy: 0.9108\n",
      "Epoch 212/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0765 - accuracy: 0.9645 - val_loss: 0.3743 - val_accuracy: 0.9152\n",
      "Epoch 213/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0777 - accuracy: 0.9637 - val_loss: 0.3997 - val_accuracy: 0.9138\n",
      "Epoch 214/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0796 - accuracy: 0.9631 - val_loss: 0.4200 - val_accuracy: 0.9050\n",
      "Epoch 215/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0829 - accuracy: 0.9611 - val_loss: 0.3681 - val_accuracy: 0.9128\n",
      "Epoch 216/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0786 - accuracy: 0.9635 - val_loss: 0.3781 - val_accuracy: 0.9165\n",
      "Epoch 217/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0807 - accuracy: 0.9614 - val_loss: 0.3463 - val_accuracy: 0.9203\n",
      "Epoch 218/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0767 - accuracy: 0.9657 - val_loss: 0.3682 - val_accuracy: 0.9084\n",
      "Epoch 219/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0772 - accuracy: 0.9637 - val_loss: 0.3799 - val_accuracy: 0.9074\n",
      "Epoch 220/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0763 - accuracy: 0.9655 - val_loss: 0.3647 - val_accuracy: 0.9158\n",
      "Epoch 221/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0736 - accuracy: 0.9655 - val_loss: 0.4105 - val_accuracy: 0.9077\n",
      "Epoch 222/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0767 - accuracy: 0.9640 - val_loss: 0.4039 - val_accuracy: 0.9209\n",
      "Epoch 223/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0760 - accuracy: 0.9649 - val_loss: 0.3894 - val_accuracy: 0.9135\n",
      "Epoch 224/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0756 - accuracy: 0.9665 - val_loss: 0.3668 - val_accuracy: 0.9179\n",
      "Epoch 225/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0784 - accuracy: 0.9633 - val_loss: 0.4285 - val_accuracy: 0.9040\n",
      "Epoch 226/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0751 - accuracy: 0.9655 - val_loss: 0.4124 - val_accuracy: 0.8972\n",
      "Epoch 227/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0723 - accuracy: 0.9657 - val_loss: 0.3790 - val_accuracy: 0.9138\n",
      "Epoch 228/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0747 - accuracy: 0.9663 - val_loss: 0.4172 - val_accuracy: 0.9131\n",
      "Epoch 229/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0761 - accuracy: 0.9665 - val_loss: 0.4010 - val_accuracy: 0.9036\n",
      "Epoch 230/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0775 - accuracy: 0.9630 - val_loss: 0.3974 - val_accuracy: 0.9158\n",
      "Epoch 231/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0743 - accuracy: 0.9656 - val_loss: 0.3905 - val_accuracy: 0.9138\n",
      "Epoch 232/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0769 - accuracy: 0.9644 - val_loss: 0.3850 - val_accuracy: 0.9145\n",
      "Epoch 233/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0747 - accuracy: 0.9676 - val_loss: 0.3883 - val_accuracy: 0.9091\n",
      "Epoch 234/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0833 - accuracy: 0.9625 - val_loss: 0.3812 - val_accuracy: 0.9114\n",
      "Epoch 235/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0763 - accuracy: 0.9650 - val_loss: 0.3794 - val_accuracy: 0.9182\n",
      "Epoch 236/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0762 - accuracy: 0.9655 - val_loss: 0.3982 - val_accuracy: 0.9019\n",
      "Epoch 237/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0869 - accuracy: 0.9588 - val_loss: 0.3340 - val_accuracy: 0.9084\n",
      "Epoch 238/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0747 - accuracy: 0.9671 - val_loss: 0.3816 - val_accuracy: 0.9111\n",
      "Epoch 239/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0728 - accuracy: 0.9659 - val_loss: 0.4026 - val_accuracy: 0.8968\n",
      "Epoch 240/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0760 - accuracy: 0.9664 - val_loss: 0.3822 - val_accuracy: 0.9030\n",
      "Epoch 241/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0820 - accuracy: 0.9616 - val_loss: 0.4313 - val_accuracy: 0.9097\n",
      "Epoch 242/700\n",
      "7352/7352 [==============================] - 2s 327us/sample - loss: 0.0836 - accuracy: 0.9615 - val_loss: 0.4482 - val_accuracy: 0.9026\n",
      "Epoch 243/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0739 - accuracy: 0.9649 - val_loss: 0.4087 - val_accuracy: 0.9165\n",
      "Epoch 244/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0747 - accuracy: 0.9646 - val_loss: 0.4224 - val_accuracy: 0.9094\n",
      "Epoch 245/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0735 - accuracy: 0.9649 - val_loss: 0.4158 - val_accuracy: 0.9108\n",
      "Epoch 246/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0730 - accuracy: 0.9656 - val_loss: 0.4368 - val_accuracy: 0.9084\n",
      "Epoch 247/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0750 - accuracy: 0.9650 - val_loss: 0.4494 - val_accuracy: 0.9121\n",
      "Epoch 248/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0708 - accuracy: 0.9650 - val_loss: 0.4301 - val_accuracy: 0.9158\n",
      "Epoch 249/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0786 - accuracy: 0.9640 - val_loss: 0.4093 - val_accuracy: 0.9097\n",
      "Epoch 250/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0724 - accuracy: 0.9680 - val_loss: 0.4161 - val_accuracy: 0.9019\n",
      "Epoch 251/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0784 - accuracy: 0.9652 - val_loss: 0.4236 - val_accuracy: 0.8985\n",
      "Epoch 252/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0734 - accuracy: 0.9675 - val_loss: 0.4023 - val_accuracy: 0.9111\n",
      "Epoch 253/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0740 - accuracy: 0.9676 - val_loss: 0.3759 - val_accuracy: 0.9108\n",
      "Epoch 254/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0721 - accuracy: 0.9660 - val_loss: 0.3875 - val_accuracy: 0.9162\n",
      "Epoch 255/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0767 - accuracy: 0.9648 - val_loss: 0.3954 - val_accuracy: 0.9087\n",
      "Epoch 256/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0735 - accuracy: 0.9653 - val_loss: 0.4060 - val_accuracy: 0.8979\n",
      "Epoch 257/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0739 - accuracy: 0.9638 - val_loss: 0.4144 - val_accuracy: 0.9125\n",
      "Epoch 258/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0750 - accuracy: 0.9671 - val_loss: 0.4097 - val_accuracy: 0.9097\n",
      "Epoch 259/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0761 - accuracy: 0.9634 - val_loss: 0.4167 - val_accuracy: 0.8918\n",
      "Epoch 260/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0725 - accuracy: 0.9638 - val_loss: 0.4186 - val_accuracy: 0.9050\n",
      "Epoch 261/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0733 - accuracy: 0.9631 - val_loss: 0.4059 - val_accuracy: 0.9097\n",
      "Epoch 262/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0770 - accuracy: 0.9648 - val_loss: 0.4146 - val_accuracy: 0.9179\n",
      "Epoch 263/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0697 - accuracy: 0.9690 - val_loss: 0.4490 - val_accuracy: 0.9006\n",
      "Epoch 264/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0766 - accuracy: 0.9646 - val_loss: 0.4243 - val_accuracy: 0.9118\n",
      "Epoch 265/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0752 - accuracy: 0.9650 - val_loss: 0.4189 - val_accuracy: 0.9091\n",
      "Epoch 266/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0712 - accuracy: 0.9660 - val_loss: 0.4297 - val_accuracy: 0.9046\n",
      "Epoch 267/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0734 - accuracy: 0.9648 - val_loss: 0.4295 - val_accuracy: 0.9125\n",
      "Epoch 268/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0732 - accuracy: 0.9644 - val_loss: 0.4666 - val_accuracy: 0.8918\n",
      "Epoch 269/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0724 - accuracy: 0.9678 - val_loss: 0.4431 - val_accuracy: 0.9043\n",
      "Epoch 270/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0750 - accuracy: 0.9668 - val_loss: 0.4277 - val_accuracy: 0.9148\n",
      "Epoch 271/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0711 - accuracy: 0.9664 - val_loss: 0.4207 - val_accuracy: 0.9179\n",
      "Epoch 272/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0732 - accuracy: 0.9672 - val_loss: 0.4151 - val_accuracy: 0.9104\n",
      "Epoch 273/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0714 - accuracy: 0.9669 - val_loss: 0.4356 - val_accuracy: 0.9111\n",
      "Epoch 274/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0728 - accuracy: 0.9668 - val_loss: 0.4274 - val_accuracy: 0.9203\n",
      "Epoch 275/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0718 - accuracy: 0.9669 - val_loss: 0.3781 - val_accuracy: 0.9162\n",
      "Epoch 276/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0716 - accuracy: 0.9683 - val_loss: 0.3995 - val_accuracy: 0.9050\n",
      "Epoch 277/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0748 - accuracy: 0.9657 - val_loss: 0.3509 - val_accuracy: 0.9019\n",
      "Epoch 278/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0757 - accuracy: 0.9659 - val_loss: 0.3871 - val_accuracy: 0.9050\n",
      "Epoch 279/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0719 - accuracy: 0.9650 - val_loss: 0.4081 - val_accuracy: 0.9019\n",
      "Epoch 280/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0743 - accuracy: 0.9656 - val_loss: 0.4609 - val_accuracy: 0.9084\n",
      "Epoch 281/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0707 - accuracy: 0.9678 - val_loss: 0.4758 - val_accuracy: 0.8985\n",
      "Epoch 282/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0702 - accuracy: 0.9671 - val_loss: 0.4210 - val_accuracy: 0.9087\n",
      "Epoch 283/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0713 - accuracy: 0.9657 - val_loss: 0.4686 - val_accuracy: 0.9070\n",
      "Epoch 284/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0701 - accuracy: 0.9664 - val_loss: 0.4330 - val_accuracy: 0.9074\n",
      "Epoch 285/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0714 - accuracy: 0.9655 - val_loss: 0.4155 - val_accuracy: 0.9114\n",
      "Epoch 286/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0731 - accuracy: 0.9659 - val_loss: 0.4052 - val_accuracy: 0.9121\n",
      "Epoch 287/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0740 - accuracy: 0.9657 - val_loss: 0.3999 - val_accuracy: 0.9080\n",
      "Epoch 288/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0729 - accuracy: 0.9675 - val_loss: 0.5155 - val_accuracy: 0.9030\n",
      "Epoch 289/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0716 - accuracy: 0.9649 - val_loss: 0.5202 - val_accuracy: 0.9036\n",
      "Epoch 290/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0767 - accuracy: 0.9652 - val_loss: 0.5120 - val_accuracy: 0.8972\n",
      "Epoch 291/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0716 - accuracy: 0.9668 - val_loss: 0.4750 - val_accuracy: 0.9057\n",
      "Epoch 292/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0691 - accuracy: 0.9693 - val_loss: 0.4747 - val_accuracy: 0.9080\n",
      "Epoch 293/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0707 - accuracy: 0.9661 - val_loss: 0.4415 - val_accuracy: 0.9077\n",
      "Epoch 294/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0680 - accuracy: 0.9693 - val_loss: 0.4557 - val_accuracy: 0.9019\n",
      "Epoch 295/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0694 - accuracy: 0.9661 - val_loss: 0.4395 - val_accuracy: 0.9074\n",
      "Epoch 296/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0676 - accuracy: 0.9684 - val_loss: 0.4376 - val_accuracy: 0.9125\n",
      "Epoch 297/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0671 - accuracy: 0.9686 - val_loss: 0.4556 - val_accuracy: 0.9111\n",
      "Epoch 298/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0696 - accuracy: 0.9686 - val_loss: 0.4325 - val_accuracy: 0.9162\n",
      "Epoch 299/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0697 - accuracy: 0.9655 - val_loss: 0.4169 - val_accuracy: 0.9145\n",
      "Epoch 300/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0696 - accuracy: 0.9667 - val_loss: 0.4450 - val_accuracy: 0.9097\n",
      "Epoch 301/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0706 - accuracy: 0.9679 - val_loss: 0.5390 - val_accuracy: 0.9036\n",
      "Epoch 302/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0680 - accuracy: 0.9701 - val_loss: 0.5518 - val_accuracy: 0.8979\n",
      "Epoch 303/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0718 - accuracy: 0.9669 - val_loss: 0.4664 - val_accuracy: 0.9101\n",
      "Epoch 304/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0729 - accuracy: 0.9646 - val_loss: 0.4901 - val_accuracy: 0.9145\n",
      "Epoch 305/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0728 - accuracy: 0.9659 - val_loss: 0.4103 - val_accuracy: 0.9141\n",
      "Epoch 306/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0680 - accuracy: 0.9694 - val_loss: 0.4145 - val_accuracy: 0.9040\n",
      "Epoch 307/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0736 - accuracy: 0.9650 - val_loss: 0.4282 - val_accuracy: 0.9077\n",
      "Epoch 308/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0735 - accuracy: 0.9669 - val_loss: 0.4036 - val_accuracy: 0.9097\n",
      "Epoch 309/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0704 - accuracy: 0.9687 - val_loss: 0.4052 - val_accuracy: 0.9179\n",
      "Epoch 310/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0703 - accuracy: 0.9667 - val_loss: 0.4125 - val_accuracy: 0.9036\n",
      "Epoch 311/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0699 - accuracy: 0.9672 - val_loss: 0.4213 - val_accuracy: 0.9067\n",
      "Epoch 312/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0732 - accuracy: 0.9646 - val_loss: 0.4155 - val_accuracy: 0.9101\n",
      "Epoch 313/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0689 - accuracy: 0.9657 - val_loss: 0.3828 - val_accuracy: 0.9152\n",
      "Epoch 314/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0721 - accuracy: 0.9667 - val_loss: 0.3787 - val_accuracy: 0.9162\n",
      "Epoch 315/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0687 - accuracy: 0.9682 - val_loss: 0.4124 - val_accuracy: 0.9101\n",
      "Epoch 316/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0698 - accuracy: 0.9680 - val_loss: 0.4153 - val_accuracy: 0.9057\n",
      "Epoch 317/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0724 - accuracy: 0.9672 - val_loss: 0.4280 - val_accuracy: 0.9026\n",
      "Epoch 318/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0677 - accuracy: 0.9687 - val_loss: 0.4076 - val_accuracy: 0.9087\n",
      "Epoch 319/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0659 - accuracy: 0.9693 - val_loss: 0.4208 - val_accuracy: 0.8945\n",
      "Epoch 320/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0664 - accuracy: 0.9689 - val_loss: 0.4257 - val_accuracy: 0.9067\n",
      "Epoch 321/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0709 - accuracy: 0.9680 - val_loss: 0.4314 - val_accuracy: 0.9074\n",
      "Epoch 322/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0695 - accuracy: 0.9679 - val_loss: 0.4311 - val_accuracy: 0.9063\n",
      "Epoch 323/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0692 - accuracy: 0.9679 - val_loss: 0.4582 - val_accuracy: 0.9104\n",
      "Epoch 324/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0682 - accuracy: 0.9680 - val_loss: 0.3992 - val_accuracy: 0.9145\n",
      "Epoch 325/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0669 - accuracy: 0.9674 - val_loss: 0.4569 - val_accuracy: 0.9050\n",
      "Epoch 326/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0666 - accuracy: 0.9691 - val_loss: 0.4232 - val_accuracy: 0.9104\n",
      "Epoch 327/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0687 - accuracy: 0.9684 - val_loss: 0.4222 - val_accuracy: 0.9097\n",
      "Epoch 328/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0665 - accuracy: 0.9699 - val_loss: 0.4550 - val_accuracy: 0.9087\n",
      "Epoch 329/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0689 - accuracy: 0.9674 - val_loss: 0.4447 - val_accuracy: 0.9016\n",
      "Epoch 330/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0705 - accuracy: 0.9672 - val_loss: 0.4073 - val_accuracy: 0.9084\n",
      "Epoch 331/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0675 - accuracy: 0.9683 - val_loss: 0.4288 - val_accuracy: 0.9067\n",
      "Epoch 332/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0660 - accuracy: 0.9689 - val_loss: 0.4135 - val_accuracy: 0.9077\n",
      "Epoch 333/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0671 - accuracy: 0.9686 - val_loss: 0.4140 - val_accuracy: 0.9087\n",
      "Epoch 334/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0652 - accuracy: 0.9699 - val_loss: 0.4188 - val_accuracy: 0.9101\n",
      "Epoch 335/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0727 - accuracy: 0.9671 - val_loss: 0.4333 - val_accuracy: 0.9148\n",
      "Epoch 336/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0663 - accuracy: 0.9690 - val_loss: 0.4425 - val_accuracy: 0.9101\n",
      "Epoch 337/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0666 - accuracy: 0.9697 - val_loss: 0.4652 - val_accuracy: 0.9067\n",
      "Epoch 338/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0673 - accuracy: 0.9680 - val_loss: 0.4569 - val_accuracy: 0.9131\n",
      "Epoch 339/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0634 - accuracy: 0.9712 - val_loss: 0.4625 - val_accuracy: 0.9074\n",
      "Epoch 340/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0663 - accuracy: 0.9683 - val_loss: 0.4333 - val_accuracy: 0.9131\n",
      "Epoch 341/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0652 - accuracy: 0.9693 - val_loss: 0.4493 - val_accuracy: 0.9057\n",
      "Epoch 342/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0693 - accuracy: 0.9679 - val_loss: 0.4565 - val_accuracy: 0.9087\n",
      "Epoch 343/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0659 - accuracy: 0.9690 - val_loss: 0.4617 - val_accuracy: 0.9125\n",
      "Epoch 344/700\n",
      "7352/7352 [==============================] - 2s 331us/sample - loss: 0.0671 - accuracy: 0.9701 - val_loss: 0.4548 - val_accuracy: 0.9084\n",
      "Epoch 345/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0680 - accuracy: 0.9678 - val_loss: 0.4305 - val_accuracy: 0.9084\n",
      "Epoch 346/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0641 - accuracy: 0.9693 - val_loss: 0.4292 - val_accuracy: 0.9077\n",
      "Epoch 347/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0651 - accuracy: 0.9718 - val_loss: 0.4418 - val_accuracy: 0.9101\n",
      "Epoch 348/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0670 - accuracy: 0.9693 - val_loss: 0.4457 - val_accuracy: 0.9094\n",
      "Epoch 349/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0622 - accuracy: 0.9718 - val_loss: 0.4134 - val_accuracy: 0.9108\n",
      "Epoch 350/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0656 - accuracy: 0.9694 - val_loss: 0.4330 - val_accuracy: 0.9111\n",
      "Epoch 351/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0650 - accuracy: 0.9698 - val_loss: 0.4455 - val_accuracy: 0.9080\n",
      "Epoch 352/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0704 - accuracy: 0.9682 - val_loss: 0.4194 - val_accuracy: 0.9128\n",
      "Epoch 353/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0648 - accuracy: 0.9689 - val_loss: 0.4194 - val_accuracy: 0.9141\n",
      "Epoch 354/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0656 - accuracy: 0.9684 - val_loss: 0.4087 - val_accuracy: 0.9128\n",
      "Epoch 355/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0707 - accuracy: 0.9689 - val_loss: 0.3826 - val_accuracy: 0.9087\n",
      "Epoch 356/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0630 - accuracy: 0.9709 - val_loss: 0.4249 - val_accuracy: 0.9104\n",
      "Epoch 357/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0671 - accuracy: 0.9689 - val_loss: 0.4457 - val_accuracy: 0.9046\n",
      "Epoch 358/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0661 - accuracy: 0.9710 - val_loss: 0.4417 - val_accuracy: 0.9046\n",
      "Epoch 359/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0651 - accuracy: 0.9691 - val_loss: 0.4467 - val_accuracy: 0.9087\n",
      "Epoch 360/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0647 - accuracy: 0.9693 - val_loss: 0.4252 - val_accuracy: 0.9125\n",
      "Epoch 361/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0648 - accuracy: 0.9708 - val_loss: 0.4716 - val_accuracy: 0.9111\n",
      "Epoch 362/700\n",
      "7352/7352 [==============================] - 2s 314us/sample - loss: 0.0652 - accuracy: 0.9694 - val_loss: 0.4284 - val_accuracy: 0.9094\n",
      "Epoch 363/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0670 - accuracy: 0.9687 - val_loss: 0.4060 - val_accuracy: 0.9026\n",
      "Epoch 364/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0667 - accuracy: 0.9728 - val_loss: 0.4347 - val_accuracy: 0.9009\n",
      "Epoch 365/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0644 - accuracy: 0.9712 - val_loss: 0.4565 - val_accuracy: 0.9060\n",
      "Epoch 366/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0651 - accuracy: 0.9680 - val_loss: 0.4426 - val_accuracy: 0.9104\n",
      "Epoch 367/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0656 - accuracy: 0.9702 - val_loss: 0.4420 - val_accuracy: 0.9101\n",
      "Epoch 368/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0631 - accuracy: 0.9703 - val_loss: 0.4102 - val_accuracy: 0.9138\n",
      "Epoch 369/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0644 - accuracy: 0.9689 - val_loss: 0.4333 - val_accuracy: 0.9070\n",
      "Epoch 370/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0661 - accuracy: 0.9698 - val_loss: 0.4359 - val_accuracy: 0.9118\n",
      "Epoch 371/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0621 - accuracy: 0.9716 - val_loss: 0.4276 - val_accuracy: 0.9172\n",
      "Epoch 372/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0698 - accuracy: 0.9678 - val_loss: 0.4475 - val_accuracy: 0.9121\n",
      "Epoch 373/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0648 - accuracy: 0.9698 - val_loss: 0.4268 - val_accuracy: 0.9101\n",
      "Epoch 374/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0638 - accuracy: 0.9693 - val_loss: 0.4189 - val_accuracy: 0.9128s: 0.0621 \n",
      "Epoch 375/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0702 - accuracy: 0.9676 - val_loss: 0.3938 - val_accuracy: 0.9158\n",
      "Epoch 376/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0654 - accuracy: 0.9701 - val_loss: 0.4171 - val_accuracy: 0.9104\n",
      "Epoch 377/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0629 - accuracy: 0.9712 - val_loss: 0.3994 - val_accuracy: 0.9111\n",
      "Epoch 378/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0647 - accuracy: 0.9672 - val_loss: 0.4042 - val_accuracy: 0.9145\n",
      "Epoch 379/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0616 - accuracy: 0.9731 - val_loss: 0.4133 - val_accuracy: 0.9070\n",
      "Epoch 380/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0625 - accuracy: 0.9708 - val_loss: 0.4078 - val_accuracy: 0.9070\n",
      "Epoch 381/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0626 - accuracy: 0.9702 - val_loss: 0.3870 - val_accuracy: 0.9138\n",
      "Epoch 382/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0628 - accuracy: 0.9708 - val_loss: 0.3977 - val_accuracy: 0.9148\n",
      "Epoch 383/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0622 - accuracy: 0.9703 - val_loss: 0.4242 - val_accuracy: 0.9145\n",
      "Epoch 384/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0629 - accuracy: 0.9713 - val_loss: 0.4020 - val_accuracy: 0.9138\n",
      "Epoch 385/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0656 - accuracy: 0.9689 - val_loss: 0.4424 - val_accuracy: 0.9080\n",
      "Epoch 386/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0588 - accuracy: 0.9731 - val_loss: 0.4061 - val_accuracy: 0.9138\n",
      "Epoch 387/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0622 - accuracy: 0.9709 - val_loss: 0.4580 - val_accuracy: 0.9101\n",
      "Epoch 388/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0651 - accuracy: 0.9716 - val_loss: 0.4662 - val_accuracy: 0.9114\n",
      "Epoch 389/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0638 - accuracy: 0.9713 - val_loss: 0.4162 - val_accuracy: 0.9135\n",
      "Epoch 390/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0621 - accuracy: 0.9727 - val_loss: 0.4295 - val_accuracy: 0.9046\n",
      "Epoch 391/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0600 - accuracy: 0.9712 - val_loss: 0.4222 - val_accuracy: 0.9060\n",
      "Epoch 392/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0599 - accuracy: 0.9731 - val_loss: 0.4040 - val_accuracy: 0.9128\n",
      "Epoch 393/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0616 - accuracy: 0.9712 - val_loss: 0.4506 - val_accuracy: 0.9121\n",
      "Epoch 394/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0640 - accuracy: 0.9705 - val_loss: 0.4366 - val_accuracy: 0.9053\n",
      "Epoch 395/700\n",
      "7352/7352 [==============================] - 2s 329us/sample - loss: 0.0609 - accuracy: 0.9717 - val_loss: 0.4137 - val_accuracy: 0.9101\n",
      "Epoch 396/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0624 - accuracy: 0.9675 - val_loss: 0.3639 - val_accuracy: 0.9145\n",
      "Epoch 397/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0576 - accuracy: 0.9735 - val_loss: 0.3846 - val_accuracy: 0.9108\n",
      "Epoch 398/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0620 - accuracy: 0.9702 - val_loss: 0.3914 - val_accuracy: 0.9165\n",
      "Epoch 399/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0567 - accuracy: 0.9743 - val_loss: 0.4476 - val_accuracy: 0.9169\n",
      "Epoch 400/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0625 - accuracy: 0.9698 - val_loss: 0.4028 - val_accuracy: 0.9131\n",
      "Epoch 401/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0613 - accuracy: 0.9702 - val_loss: 0.4526 - val_accuracy: 0.9135\n",
      "Epoch 402/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0601 - accuracy: 0.9720 - val_loss: 0.4109 - val_accuracy: 0.9172\n",
      "Epoch 403/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0603 - accuracy: 0.9716 - val_loss: 0.4096 - val_accuracy: 0.9121\n",
      "Epoch 404/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0591 - accuracy: 0.9727 - val_loss: 0.4137 - val_accuracy: 0.9141\n",
      "Epoch 405/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0633 - accuracy: 0.9693 - val_loss: 0.4749 - val_accuracy: 0.9158\n",
      "Epoch 406/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0611 - accuracy: 0.9710 - val_loss: 0.4177 - val_accuracy: 0.9101\n",
      "Epoch 407/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0612 - accuracy: 0.9720 - val_loss: 0.4854 - val_accuracy: 0.9036\n",
      "Epoch 408/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0595 - accuracy: 0.9721 - val_loss: 0.4162 - val_accuracy: 0.9145\n",
      "Epoch 409/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0589 - accuracy: 0.9721 - val_loss: 0.4472 - val_accuracy: 0.9104\n",
      "Epoch 410/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0600 - accuracy: 0.9717 - val_loss: 0.4037 - val_accuracy: 0.9152\n",
      "Epoch 411/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0573 - accuracy: 0.9735 - val_loss: 0.4140 - val_accuracy: 0.9125\n",
      "Epoch 412/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0576 - accuracy: 0.9725 - val_loss: 0.4109 - val_accuracy: 0.9046\n",
      "Epoch 413/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0623 - accuracy: 0.9724 - val_loss: 0.4568 - val_accuracy: 0.9114\n",
      "Epoch 414/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0579 - accuracy: 0.9725 - val_loss: 0.4600 - val_accuracy: 0.9118\n",
      "Epoch 415/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0615 - accuracy: 0.9695 - val_loss: 0.4990 - val_accuracy: 0.9060\n",
      "Epoch 416/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0573 - accuracy: 0.9728 - val_loss: 0.4198 - val_accuracy: 0.9162\n",
      "Epoch 417/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0562 - accuracy: 0.9746 - val_loss: 0.4383 - val_accuracy: 0.9148\n",
      "Epoch 418/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0627 - accuracy: 0.9706 - val_loss: 0.4398 - val_accuracy: 0.9148\n",
      "Epoch 419/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0590 - accuracy: 0.9716 - val_loss: 0.4160 - val_accuracy: 0.9141\n",
      "Epoch 420/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0674 - accuracy: 0.9684 - val_loss: 0.4556 - val_accuracy: 0.9155\n",
      "Epoch 421/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0613 - accuracy: 0.9727 - val_loss: 0.5313 - val_accuracy: 0.8897\n",
      "Epoch 422/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0679 - accuracy: 0.9678 - val_loss: 0.4303 - val_accuracy: 0.9111\n",
      "Epoch 423/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0620 - accuracy: 0.9720 - val_loss: 0.3982 - val_accuracy: 0.9148\n",
      "Epoch 424/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0576 - accuracy: 0.9732 - val_loss: 0.4023 - val_accuracy: 0.9135\n",
      "Epoch 425/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0583 - accuracy: 0.9699 - val_loss: 0.4439 - val_accuracy: 0.9053\n",
      "Epoch 426/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0574 - accuracy: 0.9728 - val_loss: 0.4300 - val_accuracy: 0.9108\n",
      "Epoch 427/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0582 - accuracy: 0.9742 - val_loss: 0.4959 - val_accuracy: 0.9094\n",
      "Epoch 428/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0572 - accuracy: 0.9733 - val_loss: 0.4274 - val_accuracy: 0.9141\n",
      "Epoch 429/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0557 - accuracy: 0.9727 - val_loss: 0.4306 - val_accuracy: 0.9138\n",
      "Epoch 430/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0579 - accuracy: 0.9740 - val_loss: 0.4457 - val_accuracy: 0.9067\n",
      "Epoch 431/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0583 - accuracy: 0.9732 - val_loss: 0.4214 - val_accuracy: 0.9135\n",
      "Epoch 432/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0586 - accuracy: 0.9737 - val_loss: 0.4480 - val_accuracy: 0.9128\n",
      "Epoch 433/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0556 - accuracy: 0.9742 - val_loss: 0.4558 - val_accuracy: 0.9043\n",
      "Epoch 434/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0582 - accuracy: 0.9751 - val_loss: 0.4616 - val_accuracy: 0.8982\n",
      "Epoch 435/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0570 - accuracy: 0.9739 - val_loss: 0.4104 - val_accuracy: 0.9148\n",
      "Epoch 436/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0562 - accuracy: 0.9740 - val_loss: 0.5006 - val_accuracy: 0.9121\n",
      "Epoch 437/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0592 - accuracy: 0.9718 - val_loss: 0.4648 - val_accuracy: 0.9179\n",
      "Epoch 438/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0677 - accuracy: 0.9703 - val_loss: 0.4964 - val_accuracy: 0.9145\n",
      "Epoch 439/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0573 - accuracy: 0.9732 - val_loss: 0.4599 - val_accuracy: 0.9128\n",
      "Epoch 440/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0550 - accuracy: 0.9743 - val_loss: 0.4600 - val_accuracy: 0.9138\n",
      "Epoch 441/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0560 - accuracy: 0.9739 - val_loss: 0.4633 - val_accuracy: 0.9097\n",
      "Epoch 442/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0555 - accuracy: 0.9748 - val_loss: 0.4573 - val_accuracy: 0.9057\n",
      "Epoch 443/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0552 - accuracy: 0.9766 - val_loss: 0.4744 - val_accuracy: 0.9057\n",
      "Epoch 444/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0628 - accuracy: 0.9713 - val_loss: 0.4888 - val_accuracy: 0.9131\n",
      "Epoch 445/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0572 - accuracy: 0.9732 - val_loss: 0.4786 - val_accuracy: 0.9125\n",
      "Epoch 446/700\n",
      "7352/7352 [==============================] - 2s 326us/sample - loss: 0.0548 - accuracy: 0.9742 - val_loss: 0.4668 - val_accuracy: 0.9152\n",
      "Epoch 447/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0555 - accuracy: 0.9743 - val_loss: 0.4921 - val_accuracy: 0.8979\n",
      "Epoch 448/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0590 - accuracy: 0.9732 - val_loss: 0.4648 - val_accuracy: 0.9121\n",
      "Epoch 449/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0550 - accuracy: 0.9751 - val_loss: 0.5364 - val_accuracy: 0.9148\n",
      "Epoch 450/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0551 - accuracy: 0.9740 - val_loss: 0.5065 - val_accuracy: 0.9111\n",
      "Epoch 451/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0580 - accuracy: 0.9729 - val_loss: 0.5045 - val_accuracy: 0.9145\n",
      "Epoch 452/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0544 - accuracy: 0.9744 - val_loss: 0.5084 - val_accuracy: 0.9094\n",
      "Epoch 453/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0549 - accuracy: 0.9737 - val_loss: 0.4593 - val_accuracy: 0.9135\n",
      "Epoch 454/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0542 - accuracy: 0.9762 - val_loss: 0.4805 - val_accuracy: 0.9108\n",
      "Epoch 455/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0550 - accuracy: 0.9746 - val_loss: 0.5429 - val_accuracy: 0.9057\n",
      "Epoch 456/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0543 - accuracy: 0.9754 - val_loss: 0.4939 - val_accuracy: 0.9125\n",
      "Epoch 457/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0614 - accuracy: 0.9716 - val_loss: 0.4902 - val_accuracy: 0.9114\n",
      "Epoch 458/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0529 - accuracy: 0.9744 - val_loss: 0.4606 - val_accuracy: 0.9097\n",
      "Epoch 459/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0531 - accuracy: 0.9742 - val_loss: 0.4656 - val_accuracy: 0.9155\n",
      "Epoch 460/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0528 - accuracy: 0.9751 - val_loss: 0.4965 - val_accuracy: 0.9125\n",
      "Epoch 461/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0531 - accuracy: 0.9762 - val_loss: 0.5114 - val_accuracy: 0.9050\n",
      "Epoch 462/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0528 - accuracy: 0.9762 - val_loss: 0.5114 - val_accuracy: 0.9060\n",
      "Epoch 463/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0553 - accuracy: 0.9737 - val_loss: 0.5188 - val_accuracy: 0.9094\n",
      "Epoch 464/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0547 - accuracy: 0.9744 - val_loss: 0.4752 - val_accuracy: 0.9131\n",
      "Epoch 465/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0571 - accuracy: 0.9727 - val_loss: 0.4730 - val_accuracy: 0.9148\n",
      "Epoch 466/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0549 - accuracy: 0.9746 - val_loss: 0.4698 - val_accuracy: 0.9125\n",
      "Epoch 467/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0565 - accuracy: 0.9742 - val_loss: 0.4505 - val_accuracy: 0.9125\n",
      "Epoch 468/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0565 - accuracy: 0.9728 - val_loss: 0.4404 - val_accuracy: 0.9091\n",
      "Epoch 469/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0559 - accuracy: 0.9746 - val_loss: 0.4978 - val_accuracy: 0.9094\n",
      "Epoch 470/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0536 - accuracy: 0.9755 - val_loss: 0.5397 - val_accuracy: 0.9060\n",
      "Epoch 471/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0522 - accuracy: 0.9754 - val_loss: 0.5846 - val_accuracy: 0.9053\n",
      "Epoch 472/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0529 - accuracy: 0.9752 - val_loss: 0.5196 - val_accuracy: 0.9104\n",
      "Epoch 473/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0543 - accuracy: 0.9736 - val_loss: 0.5168 - val_accuracy: 0.9101\n",
      "Epoch 474/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0539 - accuracy: 0.9748 - val_loss: 0.4759 - val_accuracy: 0.9101\n",
      "Epoch 475/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0517 - accuracy: 0.9750 - val_loss: 0.5076 - val_accuracy: 0.9084\n",
      "Epoch 476/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0531 - accuracy: 0.9769 - val_loss: 0.4987 - val_accuracy: 0.9084\n",
      "Epoch 477/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0524 - accuracy: 0.9767 - val_loss: 0.5352 - val_accuracy: 0.9087\n",
      "Epoch 478/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0523 - accuracy: 0.9761 - val_loss: 0.4980 - val_accuracy: 0.9050\n",
      "Epoch 479/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0558 - accuracy: 0.9751 - val_loss: 0.6061 - val_accuracy: 0.9097\n",
      "Epoch 480/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0495 - accuracy: 0.9766 - val_loss: 0.6098 - val_accuracy: 0.9070\n",
      "Epoch 481/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0543 - accuracy: 0.9747 - val_loss: 0.5030 - val_accuracy: 0.9152\n",
      "Epoch 482/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0528 - accuracy: 0.9751 - val_loss: 0.5388 - val_accuracy: 0.9155\n",
      "Epoch 483/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0500 - accuracy: 0.9777 - val_loss: 0.6376 - val_accuracy: 0.9019\n",
      "Epoch 484/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0526 - accuracy: 0.9752 - val_loss: 0.5247 - val_accuracy: 0.9169\n",
      "Epoch 485/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0567 - accuracy: 0.9735 - val_loss: 0.5283 - val_accuracy: 0.9179\n",
      "Epoch 486/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0611 - accuracy: 0.9716 - val_loss: 0.6090 - val_accuracy: 0.9121\n",
      "Epoch 487/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0530 - accuracy: 0.9769 - val_loss: 0.6223 - val_accuracy: 0.9009\n",
      "Epoch 488/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0501 - accuracy: 0.9780 - val_loss: 0.5435 - val_accuracy: 0.9145\n",
      "Epoch 489/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0516 - accuracy: 0.9767 - val_loss: 0.5697 - val_accuracy: 0.9074\n",
      "Epoch 490/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0525 - accuracy: 0.9767 - val_loss: 0.5079 - val_accuracy: 0.9070\n",
      "Epoch 491/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0573 - accuracy: 0.9754 - val_loss: 0.4921 - val_accuracy: 0.9046\n",
      "Epoch 492/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0592 - accuracy: 0.9728 - val_loss: 0.4697 - val_accuracy: 0.9036\n",
      "Epoch 493/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0537 - accuracy: 0.9769 - val_loss: 0.4547 - val_accuracy: 0.9135\n",
      "Epoch 494/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0539 - accuracy: 0.9740 - val_loss: 0.4822 - val_accuracy: 0.9101\n",
      "Epoch 495/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0531 - accuracy: 0.9767 - val_loss: 0.5425 - val_accuracy: 0.9094\n",
      "Epoch 496/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0535 - accuracy: 0.9746 - val_loss: 0.5151 - val_accuracy: 0.8989\n",
      "Epoch 497/700\n",
      "7352/7352 [==============================] - 2s 330us/sample - loss: 0.0492 - accuracy: 0.9803 - val_loss: 0.5109 - val_accuracy: 0.9050\n",
      "Epoch 498/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0526 - accuracy: 0.9757 - val_loss: 0.5005 - val_accuracy: 0.9084\n",
      "Epoch 499/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0531 - accuracy: 0.9757 - val_loss: 0.5377 - val_accuracy: 0.9108\n",
      "Epoch 500/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0508 - accuracy: 0.9773 - val_loss: 0.5650 - val_accuracy: 0.9094\n",
      "Epoch 501/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0503 - accuracy: 0.9774 - val_loss: 0.5023 - val_accuracy: 0.9084\n",
      "Epoch 502/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0478 - accuracy: 0.9799 - val_loss: 0.5098 - val_accuracy: 0.9121\n",
      "Epoch 503/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0526 - accuracy: 0.9758 - val_loss: 0.5193 - val_accuracy: 0.9141\n",
      "Epoch 504/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0491 - accuracy: 0.9766 - val_loss: 0.5344 - val_accuracy: 0.9162\n",
      "Epoch 505/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0504 - accuracy: 0.9766 - val_loss: 0.4899 - val_accuracy: 0.9141\n",
      "Epoch 506/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0475 - accuracy: 0.9776 - val_loss: 0.5906 - val_accuracy: 0.9152\n",
      "Epoch 507/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0478 - accuracy: 0.9777 - val_loss: 0.5326 - val_accuracy: 0.9209\n",
      "Epoch 508/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0483 - accuracy: 0.9795 - val_loss: 0.5093 - val_accuracy: 0.9141\n",
      "Epoch 509/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0503 - accuracy: 0.9778 - val_loss: 0.4743 - val_accuracy: 0.9128\n",
      "Epoch 510/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0494 - accuracy: 0.9781 - val_loss: 0.5181 - val_accuracy: 0.9121\n",
      "Epoch 511/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0485 - accuracy: 0.9773 - val_loss: 0.5054 - val_accuracy: 0.9138\n",
      "Epoch 512/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0547 - accuracy: 0.9750 - val_loss: 0.4953 - val_accuracy: 0.9209\n",
      "Epoch 513/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0490 - accuracy: 0.9771 - val_loss: 0.5130 - val_accuracy: 0.9114\n",
      "Epoch 514/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0489 - accuracy: 0.9796 - val_loss: 0.5325 - val_accuracy: 0.9131\n",
      "Epoch 515/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0490 - accuracy: 0.9785 - val_loss: 0.5068 - val_accuracy: 0.9097\n",
      "Epoch 516/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0553 - accuracy: 0.9754 - val_loss: 0.4728 - val_accuracy: 0.9141\n",
      "Epoch 517/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0498 - accuracy: 0.9769 - val_loss: 0.4697 - val_accuracy: 0.9118\n",
      "Epoch 518/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0530 - accuracy: 0.9767 - val_loss: 0.4791 - val_accuracy: 0.9169\n",
      "Epoch 519/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0515 - accuracy: 0.9755 - val_loss: 0.5136 - val_accuracy: 0.9158\n",
      "Epoch 520/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0471 - accuracy: 0.9797 - val_loss: 0.5983 - val_accuracy: 0.9118\n",
      "Epoch 521/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0504 - accuracy: 0.9765 - val_loss: 0.4966 - val_accuracy: 0.9084\n",
      "Epoch 522/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0514 - accuracy: 0.9750 - val_loss: 0.4910 - val_accuracy: 0.9138\n",
      "Epoch 523/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0483 - accuracy: 0.9777 - val_loss: 0.4980 - val_accuracy: 0.9046\n",
      "Epoch 524/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0479 - accuracy: 0.9801 - val_loss: 0.5159 - val_accuracy: 0.9087\n",
      "Epoch 525/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0472 - accuracy: 0.9784 - val_loss: 0.6262 - val_accuracy: 0.9135\n",
      "Epoch 526/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0511 - accuracy: 0.9761 - val_loss: 0.5269 - val_accuracy: 0.9111\n",
      "Epoch 527/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0503 - accuracy: 0.9780 - val_loss: 0.5074 - val_accuracy: 0.9121\n",
      "Epoch 528/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0472 - accuracy: 0.9796 - val_loss: 0.6101 - val_accuracy: 0.9128\n",
      "Epoch 529/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0477 - accuracy: 0.9774 - val_loss: 0.5854 - val_accuracy: 0.9060\n",
      "Epoch 530/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0494 - accuracy: 0.9795 - val_loss: 0.5266 - val_accuracy: 0.9118\n",
      "Epoch 531/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0443 - accuracy: 0.9792 - val_loss: 0.5129 - val_accuracy: 0.9114\n",
      "Epoch 532/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0542 - accuracy: 0.9763 - val_loss: 0.5448 - val_accuracy: 0.9063\n",
      "Epoch 533/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0478 - accuracy: 0.9803 - val_loss: 0.5955 - val_accuracy: 0.9050\n",
      "Epoch 534/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0477 - accuracy: 0.9791 - val_loss: 0.6458 - val_accuracy: 0.9145\n",
      "Epoch 535/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0466 - accuracy: 0.9781 - val_loss: 0.5815 - val_accuracy: 0.9019\n",
      "Epoch 536/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0481 - accuracy: 0.9784 - val_loss: 0.5204 - val_accuracy: 0.9114\n",
      "Epoch 537/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0492 - accuracy: 0.9774 - val_loss: 0.5316 - val_accuracy: 0.9087\n",
      "Epoch 538/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0614 - accuracy: 0.9728 - val_loss: 0.5543 - val_accuracy: 0.9077\n",
      "Epoch 539/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0475 - accuracy: 0.9788 - val_loss: 0.5890 - val_accuracy: 0.9087\n",
      "Epoch 540/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0517 - accuracy: 0.9765 - val_loss: 0.5908 - val_accuracy: 0.9033\n",
      "Epoch 541/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0522 - accuracy: 0.9774 - val_loss: 0.5379 - val_accuracy: 0.9070\n",
      "Epoch 542/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0475 - accuracy: 0.9791 - val_loss: 0.5372 - val_accuracy: 0.9080\n",
      "Epoch 543/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0499 - accuracy: 0.9767 - val_loss: 0.5956 - val_accuracy: 0.9118\n",
      "Epoch 544/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0481 - accuracy: 0.9770 - val_loss: 0.5798 - val_accuracy: 0.9043\n",
      "Epoch 545/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0474 - accuracy: 0.9785 - val_loss: 0.5849 - val_accuracy: 0.9043\n",
      "Epoch 546/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0581 - accuracy: 0.9740 - val_loss: 0.5974 - val_accuracy: 0.9084\n",
      "Epoch 547/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0477 - accuracy: 0.9784 - val_loss: 0.5985 - val_accuracy: 0.9077\n",
      "Epoch 548/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0466 - accuracy: 0.9788 - val_loss: 0.6369 - val_accuracy: 0.9060\n",
      "Epoch 549/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0491 - accuracy: 0.9792 - val_loss: 0.5607 - val_accuracy: 0.9070\n",
      "Epoch 550/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0488 - accuracy: 0.9776 - val_loss: 0.5478 - val_accuracy: 0.9019\n",
      "Epoch 551/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0517 - accuracy: 0.9780 - val_loss: 0.5557 - val_accuracy: 0.9125\n",
      "Epoch 552/700\n",
      "7352/7352 [==============================] - 2s 324us/sample - loss: 0.0473 - accuracy: 0.9776 - val_loss: 0.5531 - val_accuracy: 0.9131\n",
      "Epoch 553/700\n",
      "7352/7352 [==============================] - 2s 316us/sample - loss: 0.0463 - accuracy: 0.9808 - val_loss: 0.5217 - val_accuracy: 0.9094\n",
      "Epoch 554/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0485 - accuracy: 0.9771 - val_loss: 0.4843 - val_accuracy: 0.9128\n",
      "Epoch 555/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0474 - accuracy: 0.9793 - val_loss: 0.5120 - val_accuracy: 0.9128\n",
      "Epoch 556/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0451 - accuracy: 0.9801 - val_loss: 0.4767 - val_accuracy: 0.9084\n",
      "Epoch 557/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0462 - accuracy: 0.9795 - val_loss: 0.5473 - val_accuracy: 0.9131\n",
      "Epoch 558/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0425 - accuracy: 0.9812 - val_loss: 0.4757 - val_accuracy: 0.9125\n",
      "Epoch 559/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0415 - accuracy: 0.9829 - val_loss: 0.5376 - val_accuracy: 0.9070\n",
      "Epoch 560/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0444 - accuracy: 0.9791 - val_loss: 0.4684 - val_accuracy: 0.9104\n",
      "Epoch 561/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0475 - accuracy: 0.9786 - val_loss: 0.4837 - val_accuracy: 0.9138\n",
      "Epoch 562/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0451 - accuracy: 0.9800 - val_loss: 0.5074 - val_accuracy: 0.9084\n",
      "Epoch 563/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0408 - accuracy: 0.9820 - val_loss: 0.4876 - val_accuracy: 0.9067\n",
      "Epoch 564/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0448 - accuracy: 0.9812 - val_loss: 0.4755 - val_accuracy: 0.9118\n",
      "Epoch 565/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0450 - accuracy: 0.9792 - val_loss: 0.5333 - val_accuracy: 0.9080\n",
      "Epoch 566/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0464 - accuracy: 0.9778 - val_loss: 0.5533 - val_accuracy: 0.9091\n",
      "Epoch 567/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0437 - accuracy: 0.9808 - val_loss: 0.5198 - val_accuracy: 0.9097\n",
      "Epoch 568/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0501 - accuracy: 0.9770 - val_loss: 0.4616 - val_accuracy: 0.9097\n",
      "Epoch 569/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0466 - accuracy: 0.9793 - val_loss: 0.5503 - val_accuracy: 0.9074\n",
      "Epoch 570/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0470 - accuracy: 0.9791 - val_loss: 0.4975 - val_accuracy: 0.9091\n",
      "Epoch 571/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0470 - accuracy: 0.9784 - val_loss: 0.7107 - val_accuracy: 0.9182\n",
      "Epoch 572/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0462 - accuracy: 0.9800 - val_loss: 0.5365 - val_accuracy: 0.9070\n",
      "Epoch 573/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0445 - accuracy: 0.9800 - val_loss: 0.5147 - val_accuracy: 0.9138\n",
      "Epoch 574/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0481 - accuracy: 0.9774 - val_loss: 0.5172 - val_accuracy: 0.9118\n",
      "Epoch 575/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0501 - accuracy: 0.9785 - val_loss: 0.5389 - val_accuracy: 0.9060\n",
      "Epoch 576/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0478 - accuracy: 0.9780 - val_loss: 0.5006 - val_accuracy: 0.9050\n",
      "Epoch 577/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0430 - accuracy: 0.9801 - val_loss: 0.5287 - val_accuracy: 0.9087\n",
      "Epoch 578/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0446 - accuracy: 0.9801 - val_loss: 0.5745 - val_accuracy: 0.9077\n",
      "Epoch 579/700\n",
      "7352/7352 [==============================] - 2s 316us/sample - loss: 0.0432 - accuracy: 0.9808 - val_loss: 0.5392 - val_accuracy: 0.9125\n",
      "Epoch 580/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0500 - accuracy: 0.9770 - val_loss: 0.5980 - val_accuracy: 0.9087\n",
      "Epoch 581/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0450 - accuracy: 0.9784 - val_loss: 0.5434 - val_accuracy: 0.9094\n",
      "Epoch 582/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0434 - accuracy: 0.9793 - val_loss: 0.5315 - val_accuracy: 0.9138\n",
      "Epoch 583/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0458 - accuracy: 0.9780 - val_loss: 0.4916 - val_accuracy: 0.9152\n",
      "Epoch 584/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0509 - accuracy: 0.9765 - val_loss: 0.5235 - val_accuracy: 0.9016\n",
      "Epoch 585/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0446 - accuracy: 0.9803 - val_loss: 0.5215 - val_accuracy: 0.9036\n",
      "Epoch 586/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0422 - accuracy: 0.9803 - val_loss: 0.5583 - val_accuracy: 0.9046\n",
      "Epoch 587/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0404 - accuracy: 0.9823 - val_loss: 0.5334 - val_accuracy: 0.9009\n",
      "Epoch 588/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0437 - accuracy: 0.9814 - val_loss: 0.5418 - val_accuracy: 0.9046\n",
      "Epoch 589/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0445 - accuracy: 0.9804 - val_loss: 0.5280 - val_accuracy: 0.9094\n",
      "Epoch 590/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0404 - accuracy: 0.9805 - val_loss: 0.5081 - val_accuracy: 0.9091\n",
      "Epoch 591/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0390 - accuracy: 0.9818 - val_loss: 0.5287 - val_accuracy: 0.9104\n",
      "Epoch 592/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0418 - accuracy: 0.9825 - val_loss: 0.5386 - val_accuracy: 0.9077\n",
      "Epoch 593/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0441 - accuracy: 0.9803 - val_loss: 0.5127 - val_accuracy: 0.9087\n",
      "Epoch 594/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0468 - accuracy: 0.9778 - val_loss: 0.4986 - val_accuracy: 0.9060\n",
      "Epoch 595/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0405 - accuracy: 0.9830 - val_loss: 0.4969 - val_accuracy: 0.9087\n",
      "Epoch 596/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0441 - accuracy: 0.9801 - val_loss: 0.5065 - val_accuracy: 0.9101\n",
      "Epoch 597/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0416 - accuracy: 0.9804 - val_loss: 0.4962 - val_accuracy: 0.9152\n",
      "Epoch 598/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0420 - accuracy: 0.9795 - val_loss: 0.5286 - val_accuracy: 0.9046\n",
      "Epoch 599/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0440 - accuracy: 0.9793 - val_loss: 0.5163 - val_accuracy: 0.9002\n",
      "Epoch 600/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0424 - accuracy: 0.9815 - val_loss: 0.5388 - val_accuracy: 0.9070\n",
      "Epoch 601/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0404 - accuracy: 0.9808 - val_loss: 0.5057 - val_accuracy: 0.9131\n",
      "Epoch 602/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0406 - accuracy: 0.9820 - val_loss: 0.5655 - val_accuracy: 0.9006\n",
      "Epoch 603/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0412 - accuracy: 0.9818 - val_loss: 0.5728 - val_accuracy: 0.9101\n",
      "Epoch 604/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0401 - accuracy: 0.9820 - val_loss: 0.4851 - val_accuracy: 0.9121\n",
      "Epoch 605/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0459 - accuracy: 0.9789 - val_loss: 0.4651 - val_accuracy: 0.9063\n",
      "Epoch 606/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0478 - accuracy: 0.9788 - val_loss: 0.5491 - val_accuracy: 0.9070\n",
      "Epoch 607/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0454 - accuracy: 0.9796 - val_loss: 0.5999 - val_accuracy: 0.9060\n",
      "Epoch 608/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0451 - accuracy: 0.9808 - val_loss: 0.5698 - val_accuracy: 0.9046\n",
      "Epoch 609/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0420 - accuracy: 0.9834 - val_loss: 0.5184 - val_accuracy: 0.9033\n",
      "Epoch 610/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0511 - accuracy: 0.9766 - val_loss: 0.4782 - val_accuracy: 0.9057\n",
      "Epoch 611/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0469 - accuracy: 0.9792 - val_loss: 0.4865 - val_accuracy: 0.9019\n",
      "Epoch 612/700\n",
      "7352/7352 [==============================] - 2s 316us/sample - loss: 0.0402 - accuracy: 0.9823 - val_loss: 0.4709 - val_accuracy: 0.9026\n",
      "Epoch 613/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0404 - accuracy: 0.9827 - val_loss: 0.4706 - val_accuracy: 0.9138\n",
      "Epoch 614/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0415 - accuracy: 0.9827 - val_loss: 0.5004 - val_accuracy: 0.9036\n",
      "Epoch 615/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0391 - accuracy: 0.9844 - val_loss: 0.4924 - val_accuracy: 0.9097\n",
      "Epoch 616/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0381 - accuracy: 0.9831 - val_loss: 0.5116 - val_accuracy: 0.9013\n",
      "Epoch 617/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0417 - accuracy: 0.9804 - val_loss: 0.5244 - val_accuracy: 0.9046\n",
      "Epoch 618/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0408 - accuracy: 0.9816 - val_loss: 0.5456 - val_accuracy: 0.9036\n",
      "Epoch 619/700\n",
      "7352/7352 [==============================] - 2s 325us/sample - loss: 0.0409 - accuracy: 0.9814 - val_loss: 0.5079 - val_accuracy: 0.9087\n",
      "Epoch 620/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0394 - accuracy: 0.9826 - val_loss: 0.5473 - val_accuracy: 0.9135\n",
      "Epoch 621/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0397 - accuracy: 0.9833 - val_loss: 0.5177 - val_accuracy: 0.9152\n",
      "Epoch 622/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0392 - accuracy: 0.9830 - val_loss: 0.5282 - val_accuracy: 0.9026\n",
      "Epoch 623/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0385 - accuracy: 0.9815 - val_loss: 0.4624 - val_accuracy: 0.9114\n",
      "Epoch 624/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0405 - accuracy: 0.9812 - val_loss: 0.4730 - val_accuracy: 0.9036\n",
      "Epoch 625/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0397 - accuracy: 0.9823 - val_loss: 0.5233 - val_accuracy: 0.9097\n",
      "Epoch 626/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0372 - accuracy: 0.9823 - val_loss: 0.5296 - val_accuracy: 0.9097\n",
      "Epoch 627/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0408 - accuracy: 0.9808 - val_loss: 0.5006 - val_accuracy: 0.9074\n",
      "Epoch 628/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0398 - accuracy: 0.9823 - val_loss: 0.5527 - val_accuracy: 0.9077\n",
      "Epoch 629/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0445 - accuracy: 0.9801 - val_loss: 0.5149 - val_accuracy: 0.9111\n",
      "Epoch 630/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0380 - accuracy: 0.9826 - val_loss: 0.5064 - val_accuracy: 0.9101\n",
      "Epoch 631/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0386 - accuracy: 0.9842 - val_loss: 0.5479 - val_accuracy: 0.9070\n",
      "Epoch 632/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0397 - accuracy: 0.9829 - val_loss: 0.4785 - val_accuracy: 0.9101\n",
      "Epoch 633/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0397 - accuracy: 0.9827 - val_loss: 0.4714 - val_accuracy: 0.9067\n",
      "Epoch 634/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0428 - accuracy: 0.9819 - val_loss: 0.4860 - val_accuracy: 0.9114\n",
      "Epoch 635/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0402 - accuracy: 0.9829 - val_loss: 0.5508 - val_accuracy: 0.9091\n",
      "Epoch 636/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0388 - accuracy: 0.9831 - val_loss: 0.5356 - val_accuracy: 0.9043\n",
      "Epoch 637/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0373 - accuracy: 0.9849 - val_loss: 0.5020 - val_accuracy: 0.9060\n",
      "Epoch 638/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0397 - accuracy: 0.9831 - val_loss: 0.6182 - val_accuracy: 0.9046\n",
      "Epoch 639/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0391 - accuracy: 0.9834 - val_loss: 0.5203 - val_accuracy: 0.9026\n",
      "Epoch 640/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0354 - accuracy: 0.9852 - val_loss: 0.4779 - val_accuracy: 0.9209\n",
      "Epoch 641/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0409 - accuracy: 0.9811 - val_loss: 0.5610 - val_accuracy: 0.9019\n",
      "Epoch 642/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0389 - accuracy: 0.9808 - val_loss: 0.4407 - val_accuracy: 0.9169\n",
      "Epoch 643/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0381 - accuracy: 0.9833 - val_loss: 0.5329 - val_accuracy: 0.9118\n",
      "Epoch 644/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0387 - accuracy: 0.9833 - val_loss: 0.5575 - val_accuracy: 0.9050\n",
      "Epoch 645/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0411 - accuracy: 0.9820 - val_loss: 0.6021 - val_accuracy: 0.9060\n",
      "Epoch 646/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0400 - accuracy: 0.9825 - val_loss: 0.5055 - val_accuracy: 0.9097\n",
      "Epoch 647/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0371 - accuracy: 0.9842 - val_loss: 0.5668 - val_accuracy: 0.9101\n",
      "Epoch 648/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0380 - accuracy: 0.9852 - val_loss: 0.5422 - val_accuracy: 0.9087\n",
      "Epoch 649/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0368 - accuracy: 0.9837 - val_loss: 0.5450 - val_accuracy: 0.9084\n",
      "Epoch 650/700\n",
      "7352/7352 [==============================] - 2s 328us/sample - loss: 0.0399 - accuracy: 0.9826 - val_loss: 0.6256 - val_accuracy: 0.9067\n",
      "Epoch 651/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0363 - accuracy: 0.9845 - val_loss: 0.5407 - val_accuracy: 0.9023\n",
      "Epoch 652/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0367 - accuracy: 0.9842 - val_loss: 0.5596 - val_accuracy: 0.9091\n",
      "Epoch 653/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0376 - accuracy: 0.9848 - val_loss: 0.4979 - val_accuracy: 0.9118\n",
      "Epoch 654/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0379 - accuracy: 0.9841 - val_loss: 0.5666 - val_accuracy: 0.9060\n",
      "Epoch 655/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0410 - accuracy: 0.9803 - val_loss: 0.5118 - val_accuracy: 0.9080\n",
      "Epoch 656/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0389 - accuracy: 0.9818 - val_loss: 0.5442 - val_accuracy: 0.9114\n",
      "Epoch 657/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0428 - accuracy: 0.9788 - val_loss: 0.6246 - val_accuracy: 0.8999\n",
      "Epoch 658/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0399 - accuracy: 0.9814 - val_loss: 0.5301 - val_accuracy: 0.9013\n",
      "Epoch 659/700\n",
      "7352/7352 [==============================] - 2s 317us/sample - loss: 0.0394 - accuracy: 0.9837 - val_loss: 0.5072 - val_accuracy: 0.9074\n",
      "Epoch 660/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0390 - accuracy: 0.9815 - val_loss: 0.5237 - val_accuracy: 0.9169\n",
      "Epoch 661/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0389 - accuracy: 0.9830 - val_loss: 0.5197 - val_accuracy: 0.9091\n",
      "Epoch 662/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0376 - accuracy: 0.9833 - val_loss: 0.5461 - val_accuracy: 0.9125\n",
      "Epoch 663/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0347 - accuracy: 0.9852 - val_loss: 0.5431 - val_accuracy: 0.9131\n",
      "Epoch 664/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0355 - accuracy: 0.9829 - val_loss: 0.5961 - val_accuracy: 0.9108\n",
      "Epoch 665/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0357 - accuracy: 0.9845 - val_loss: 0.5360 - val_accuracy: 0.9097\n",
      "Epoch 666/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0350 - accuracy: 0.9857 - val_loss: 0.5182 - val_accuracy: 0.9104\n",
      "Epoch 667/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0371 - accuracy: 0.9818 - val_loss: 0.5549 - val_accuracy: 0.9128\n",
      "Epoch 668/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0340 - accuracy: 0.9864 - val_loss: 0.5976 - val_accuracy: 0.9138\n",
      "Epoch 669/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0359 - accuracy: 0.9842 - val_loss: 0.5974 - val_accuracy: 0.9084\n",
      "Epoch 670/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0376 - accuracy: 0.9831 - val_loss: 0.5616 - val_accuracy: 0.9070\n",
      "Epoch 671/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0360 - accuracy: 0.9844 - val_loss: 0.5910 - val_accuracy: 0.9091\n",
      "Epoch 672/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0358 - accuracy: 0.9846 - val_loss: 0.5666 - val_accuracy: 0.9101\n",
      "Epoch 673/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0355 - accuracy: 0.9835 - val_loss: 0.5888 - val_accuracy: 0.9080\n",
      "Epoch 674/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0340 - accuracy: 0.9860 - val_loss: 0.5211 - val_accuracy: 0.9050\n",
      "Epoch 675/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0369 - accuracy: 0.9845 - val_loss: 0.5336 - val_accuracy: 0.9155\n",
      "Epoch 676/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0360 - accuracy: 0.9844 - val_loss: 0.6211 - val_accuracy: 0.9104\n",
      "Epoch 677/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0370 - accuracy: 0.9844 - val_loss: 0.5799 - val_accuracy: 0.9057\n",
      "Epoch 678/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0350 - accuracy: 0.9842 - val_loss: 0.5025 - val_accuracy: 0.9101\n",
      "Epoch 679/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0390 - accuracy: 0.9831 - val_loss: 0.5148 - val_accuracy: 0.9080\n",
      "Epoch 680/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0452 - accuracy: 0.9823 - val_loss: 0.5284 - val_accuracy: 0.9070\n",
      "Epoch 681/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0406 - accuracy: 0.9822 - val_loss: 0.5672 - val_accuracy: 0.9067\n",
      "Epoch 682/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0360 - accuracy: 0.9834 - val_loss: 0.5848 - val_accuracy: 0.9026\n",
      "Epoch 683/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0355 - accuracy: 0.9845 - val_loss: 0.5281 - val_accuracy: 0.9040\n",
      "Epoch 684/700\n",
      "7352/7352 [==============================] - 2s 323us/sample - loss: 0.0433 - accuracy: 0.9819 - val_loss: 0.5706 - val_accuracy: 0.8992\n",
      "Epoch 685/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0378 - accuracy: 0.9825 - val_loss: 0.6080 - val_accuracy: 0.9033\n",
      "Epoch 686/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0399 - accuracy: 0.9826 - val_loss: 0.5587 - val_accuracy: 0.9121\n",
      "Epoch 687/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0388 - accuracy: 0.9837 - val_loss: 0.6393 - val_accuracy: 0.9104\n",
      "Epoch 688/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0348 - accuracy: 0.9849 - val_loss: 0.5726 - val_accuracy: 0.9141\n",
      "Epoch 689/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0357 - accuracy: 0.9848 - val_loss: 0.5693 - val_accuracy: 0.9135\n",
      "Epoch 690/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0343 - accuracy: 0.9844 - val_loss: 0.5754 - val_accuracy: 0.9104\n",
      "Epoch 691/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0344 - accuracy: 0.9860 - val_loss: 0.5579 - val_accuracy: 0.9125\n",
      "Epoch 692/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0364 - accuracy: 0.9835 - val_loss: 0.5741 - val_accuracy: 0.9091\n",
      "Epoch 693/700\n",
      "7352/7352 [==============================] - 2s 318us/sample - loss: 0.0344 - accuracy: 0.9861 - val_loss: 0.5792 - val_accuracy: 0.9128\n",
      "Epoch 694/700\n",
      "7352/7352 [==============================] - 2s 322us/sample - loss: 0.0375 - accuracy: 0.9842 - val_loss: 0.5857 - val_accuracy: 0.9033\n",
      "Epoch 695/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0355 - accuracy: 0.9845 - val_loss: 0.5917 - val_accuracy: 0.9043\n",
      "Epoch 696/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0321 - accuracy: 0.9859 - val_loss: 0.5427 - val_accuracy: 0.9111\n",
      "Epoch 697/700\n",
      "7352/7352 [==============================] - 2s 319us/sample - loss: 0.0354 - accuracy: 0.9846 - val_loss: 0.5747 - val_accuracy: 0.9067\n",
      "Epoch 698/700\n",
      "7352/7352 [==============================] - 2s 321us/sample - loss: 0.0355 - accuracy: 0.9852 - val_loss: 0.6090 - val_accuracy: 0.9019\n",
      "Epoch 699/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0336 - accuracy: 0.9872 - val_loss: 0.5704 - val_accuracy: 0.9053\n",
      "Epoch 700/700\n",
      "7352/7352 [==============================] - 2s 320us/sample - loss: 0.0353 - accuracy: 0.9848 - val_loss: 0.5824 - val_accuracy: 0.9104\n",
      "------------------------ 测试中---------------------------\n",
      "2947/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 130us/sample - loss: 0.2927 - accuracy: 0.9104\n",
      "Baseline Error: 8.96%\n",
      "Size of the unpruned model before compression: 2.70 Mb\n",
      "Size of the unpruned model after compression: 2.43 Mb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import csv\n",
    "import tempfile\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.keras import backend as K\n",
    "from utils.utilities import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(813306)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allocator_type = 'BFC'  # A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "#config.gpu_options.allow_growth = True\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "#构建数据集 channel_last\n",
    "#构建数据集 channel_last\n",
    "def load_data():    \n",
    "    X_train, labels_train, list_ch_train = read_data(data_path=\"../data/HAR_Dataset\", split=\"train\") # train\n",
    "    X_test, labels_test, list_ch_test = read_data(data_path=\"../data/HAR_Dataset\", split=\"test\") # test\n",
    "    assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "    x_train = X_train[:,:,np.newaxis,:]\n",
    "    x_val = X_test[:,:,np.newaxis,:]\n",
    "    x_train = x_train[:,:,:,6:]\n",
    "    x_val = x_val[:,:,:,6:]\n",
    "    y_train = to_categorical(labels_train)\n",
    "    y_val = to_categorical(labels_test)\n",
    "    return (x_train,y_train),(x_val,y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_resnet(input_shape, n_feature_maps, nb_classes, dropout):\n",
    "    print('build conv_x')\n",
    "    x = Input(shape=(input_shape))\n",
    "\n",
    "    x_total = keras.layers.Conv2D(10, (17, 1),strides = (1,1), padding='same')(x)\n",
    "    conv_x = keras.layers.BatchNormalization()(x_total)  # 853\n",
    "\n",
    " \n",
    "    conv_x = keras.layers.Conv2D(n_feature_maps, (17, 1), padding='same')(conv_x)  # input size == ouput size\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "\n",
    "    print('build conv_y')\n",
    "    conv_y = keras.layers.Conv2D(n_feature_maps * 2, (17, 1), padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "\n",
    "    conv_y = Dropout(dropout)(conv_y)\n",
    "    print('build conv_z')\n",
    "    conv_z = keras.layers.Conv2D(n_feature_maps, (9, 1), padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps)  # 若当前输出和跨层连接的x，通道数不同，则采用1*1卷积使得通道数相同\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = keras.layers.Conv2D(n_feature_maps, (1, 1), padding='same')(x_total)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = keras.layers.BatchNormalization()(x_total)\n",
    "\n",
    "    print('Merging skip connection')\n",
    "    # y = merge([shortcut_y, conv_z], mode='sum')\n",
    "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "\n",
    "    full = keras.layers.GlobalAveragePooling2D()(y)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    print('        -- model was built.')\n",
    "    return x, out\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = 7\n",
    "    channels = 3\n",
    "    dropout = 0.2\n",
    "    nb_epochs = 700\n",
    "    batch_size = 50\n",
    "    data_row = 128\n",
    "    data_column = 1\n",
    "    trainpath = r'./data'\n",
    "\n",
    "    (x_train,y_train),(x_val,y_val) = load_data()\n",
    "\n",
    "\n",
    "    tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "    input_shape = (data_row, data_column,channels)\n",
    "\n",
    "    print('train dataset size:',x_train.shape[0])\n",
    "    print('validation dataset size:',x_val.shape[0])\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    x, y = build_resnet(input_shape, 64, num, dropout)  # 建立resnet只考虑了单个example\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.9,\n",
    "                                  patience=20, min_lr=0.00005)\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n",
    "                     verbose=1, validation_data=(x_val, y_val), callbacks=[reduce_lr])  # 回调函数会在训练的时候适当被调用\n",
    "\n",
    "\n",
    "    # 测试\n",
    "    print(\"------------------------ 测试中---------------------------\")\n",
    "    #evaluation of the model\n",
    "    scores = model.evaluate(x_val,y_val)\n",
    "    print('Baseline Error: %.2f%%'%(100 * (1 - scores[1])))\n",
    "    keras.models.save_model(model, '../model/test_resnet_v4.h5')\n",
    "    keras_file = '../model/test_resnet_v4.h5'\n",
    "    _, zip1 = tempfile.mkstemp('.zip') \n",
    "    with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(keras_file)\n",
    "    print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "          (os.path.getsize(keras_file) / float(2**20)))\n",
    "    print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "          (os.path.getsize(zip1) / float(2**20)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 7352\n",
      "validation dataset size: 2947\n",
      "build conv_x\n",
      "build conv_z\n",
      "        -- model was built.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 128, 1, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 128, 1)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli (None, 128, 1)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli (None, 128, 1)       0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 128, 1, 1)    0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 128, 1, 1)    0           tf.__operators__.getitem_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 128, 1, 1)    0           tf.__operators__.getitem_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 1, 16)   272         reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 128, 1, 16)   272         reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 1, 16)   272         reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 64, 1, 16)    0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 64, 1, 16)    0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 64, 1, 16)    0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 1, 16)    64          average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 1, 16)    64          average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 64, 1, 16)    64          average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 64, 1, 16)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 64, 1, 16)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 64, 1, 16)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 1, 32)    8224        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 1, 32)    8224        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 1, 32)    8224        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 32, 1, 32)    0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 32, 1, 32)    0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 32, 1, 32)    0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 1, 32)    128         average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 1, 32)    128         average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 1, 32)    128         average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 1, 32)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 1, 32)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 1, 32)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 1, 16)    8208        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 1, 16)    8208        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 1, 16)    8208        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 1, 16)    0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 16, 1, 16)    0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 16, 1, 16)    0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 1, 16)    64          average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 1, 16)    64          average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 1, 16)    64          average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 1, 16)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 1, 16)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 1, 16)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 1, 16)    4112        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 1, 16)    4112        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 1, 16)    4112        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 8, 1, 16)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 8, 1, 16)     0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 8, 1, 16)     0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 8, 1, 16)     64          average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 1, 16)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 8, 1, 16)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 8, 1, 16)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 1, 16)     4112        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 8, 1, 16)     4112        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 1, 16)     4112        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 4, 1, 16)     0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 4, 1, 16)     0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 4, 1, 16)     0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 4, 1, 16)     64          average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 4, 1, 16)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 1, 16)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 1, 16)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 1, 1)      129         activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 1, 1)      129         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 4, 1, 1)      129         activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 4, 1, 3)      0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 4, 1, 3)      12          tf.concat_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 4, 1, 64)     3136        batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 4, 1, 64)     256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 1, 64)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 4, 1, 64)     256         tf.concat_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 4, 1, 64)     32832       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 4, 1, 64)     0           conv2d_44[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 4, 1, 64)     256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 4, 1, 64)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 64)           0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7)            455         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 113,526\n",
      "Trainable params: 112,688\n",
      "Non-trainable params: 838\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/700\n",
      "148/148 [==============================] - 9s 44ms/step - loss: 1.0611 - accuracy: 0.5460 - val_loss: 10.8937 - val_accuracy: 0.4381\n",
      "Epoch 2/700\n",
      "148/148 [==============================] - 6s 39ms/step - loss: 0.7400 - accuracy: 0.6866 - val_loss: 0.8102 - val_accuracy: 0.6071\n",
      "Epoch 3/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.6253 - accuracy: 0.7306 - val_loss: 6.1187 - val_accuracy: 0.2324\n",
      "Epoch 4/700\n",
      "148/148 [==============================] - 6s 41ms/step - loss: 0.4500 - accuracy: 0.8151 - val_loss: 14.6983 - val_accuracy: 0.1775\n",
      "Epoch 5/700\n",
      "148/148 [==============================] - 6s 41ms/step - loss: 0.4942 - accuracy: 0.8114 - val_loss: 2.3249 - val_accuracy: 0.6423\n",
      "Epoch 6/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.3675 - accuracy: 0.8702 - val_loss: 2.9977 - val_accuracy: 0.6305\n",
      "Epoch 7/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.2520 - accuracy: 0.9080 - val_loss: 2.9174 - val_accuracy: 0.4832\n",
      "Epoch 8/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.4483 - accuracy: 0.8393 - val_loss: 4.0155 - val_accuracy: 0.4143\n",
      "Epoch 9/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.3433 - accuracy: 0.8816 - val_loss: 1.0329 - val_accuracy: 0.7401\n",
      "Epoch 10/700\n",
      "148/148 [==============================] - 6s 39ms/step - loss: 0.3080 - accuracy: 0.8899 - val_loss: 1.9548 - val_accuracy: 0.6966\n",
      "Epoch 11/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.2390 - accuracy: 0.9091 - val_loss: 0.6239 - val_accuracy: 0.7638\n",
      "Epoch 12/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.3923 - accuracy: 0.8526 - val_loss: 0.9589 - val_accuracy: 0.7900\n",
      "Epoch 13/700\n",
      "148/148 [==============================] - 6s 41ms/step - loss: 0.2315 - accuracy: 0.9188 - val_loss: 0.9149 - val_accuracy: 0.7984\n",
      "Epoch 14/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.2741 - accuracy: 0.8979 - val_loss: 2.1997 - val_accuracy: 0.6715\n",
      "Epoch 15/700\n",
      "148/148 [==============================] - 7s 44ms/step - loss: 0.1968 - accuracy: 0.9235 - val_loss: 0.7184 - val_accuracy: 0.8039\n",
      "Epoch 16/700\n",
      "148/148 [==============================] - 6s 44ms/step - loss: 0.2096 - accuracy: 0.9202 - val_loss: 1.1846 - val_accuracy: 0.6664\n",
      "Epoch 17/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.5287 - accuracy: 0.8444 - val_loss: 7.8202 - val_accuracy: 0.3943\n",
      "Epoch 18/700\n",
      "148/148 [==============================] - 8s 51ms/step - loss: 0.2728 - accuracy: 0.8928 - val_loss: 0.5693 - val_accuracy: 0.8500\n",
      "Epoch 19/700\n",
      "148/148 [==============================] - 6s 44ms/step - loss: 0.2171 - accuracy: 0.9293 - val_loss: 0.6060 - val_accuracy: 0.8079\n",
      "Epoch 20/700\n",
      "148/148 [==============================] - 6s 39ms/step - loss: 0.2994 - accuracy: 0.8905 - val_loss: 0.2957 - val_accuracy: 0.8700\n",
      "Epoch 21/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.2179 - accuracy: 0.9181 - val_loss: 0.3158 - val_accuracy: 0.8897\n",
      "Epoch 22/700\n",
      "148/148 [==============================] - 7s 44ms/step - loss: 0.1675 - accuracy: 0.9334 - val_loss: 0.6658 - val_accuracy: 0.8076\n",
      "Epoch 23/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.2005 - accuracy: 0.9267 - val_loss: 0.4533 - val_accuracy: 0.8626\n",
      "Epoch 24/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.2517 - accuracy: 0.9111 - val_loss: 0.4552 - val_accuracy: 0.8592\n",
      "Epoch 25/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.2571 - accuracy: 0.9189 - val_loss: 0.8876 - val_accuracy: 0.7475\n",
      "Epoch 26/700\n",
      "148/148 [==============================] - 7s 44ms/step - loss: 0.3029 - accuracy: 0.8961 - val_loss: 0.3531 - val_accuracy: 0.8680\n",
      "Epoch 27/700\n",
      "148/148 [==============================] - 6s 41ms/step - loss: 0.1945 - accuracy: 0.9235 - val_loss: 0.2817 - val_accuracy: 0.8843\n",
      "Epoch 28/700\n",
      "148/148 [==============================] - 7s 45ms/step - loss: 0.2009 - accuracy: 0.9245 - val_loss: 0.3649 - val_accuracy: 0.8812\n",
      "Epoch 29/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.3443 - accuracy: 0.8967 - val_loss: 0.4064 - val_accuracy: 0.8765\n",
      "Epoch 30/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.2049 - accuracy: 0.9192 - val_loss: 0.4383 - val_accuracy: 0.8660\n",
      "Epoch 31/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.2909 - accuracy: 0.8929 - val_loss: 1.1005 - val_accuracy: 0.7876\n",
      "Epoch 32/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.2358 - accuracy: 0.9173 - val_loss: 0.5613 - val_accuracy: 0.8592\n",
      "Epoch 33/700\n",
      "148/148 [==============================] - 6s 44ms/step - loss: 0.1773 - accuracy: 0.9310 - val_loss: 0.3579 - val_accuracy: 0.8812\n",
      "Epoch 34/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.2197 - accuracy: 0.9186 - val_loss: 0.7987 - val_accuracy: 0.7995\n",
      "Epoch 35/700\n",
      "148/148 [==============================] - 7s 46ms/step - loss: 0.1952 - accuracy: 0.9289 - val_loss: 0.6803 - val_accuracy: 0.8436\n",
      "Epoch 36/700\n",
      "148/148 [==============================] - 7s 45ms/step - loss: 0.1521 - accuracy: 0.9432 - val_loss: 0.4569 - val_accuracy: 0.8666\n",
      "Epoch 37/700\n",
      "148/148 [==============================] - 7s 47ms/step - loss: 0.2551 - accuracy: 0.9070 - val_loss: 1.0952 - val_accuracy: 0.7611\n",
      "Epoch 38/700\n",
      "148/148 [==============================] - 7s 45ms/step - loss: 0.1571 - accuracy: 0.9379 - val_loss: 0.7490 - val_accuracy: 0.8259\n",
      "Epoch 39/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.3534 - accuracy: 0.8947 - val_loss: 2.1539 - val_accuracy: 0.5755\n",
      "Epoch 40/700\n",
      "148/148 [==============================] - 6s 41ms/step - loss: 0.2144 - accuracy: 0.9224 - val_loss: 0.5722 - val_accuracy: 0.8531\n",
      "Epoch 41/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.1791 - accuracy: 0.9217 - val_loss: 0.4505 - val_accuracy: 0.8616\n",
      "Epoch 42/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.2091 - accuracy: 0.9254 - val_loss: 0.9525 - val_accuracy: 0.8113\n",
      "Epoch 43/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.2861 - accuracy: 0.8974 - val_loss: 0.5998 - val_accuracy: 0.8402\n",
      "Epoch 44/700\n",
      "148/148 [==============================] - 6s 37ms/step - loss: 0.3168 - accuracy: 0.8971 - val_loss: 0.4473 - val_accuracy: 0.8609\n",
      "Epoch 45/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.2101 - accuracy: 0.9172 - val_loss: 0.3544 - val_accuracy: 0.8785\n",
      "Epoch 46/700\n",
      "148/148 [==============================] - 7s 46ms/step - loss: 0.1754 - accuracy: 0.9221 - val_loss: 0.3607 - val_accuracy: 0.8850\n",
      "Epoch 47/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.1846 - accuracy: 0.9276 - val_loss: 0.3442 - val_accuracy: 0.8782\n",
      "Epoch 48/700\n",
      "148/148 [==============================] - 6s 39ms/step - loss: 0.1903 - accuracy: 0.9254 - val_loss: 0.3667 - val_accuracy: 0.8826\n",
      "Epoch 49/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.1581 - accuracy: 0.9383 - val_loss: 0.4541 - val_accuracy: 0.8792\n",
      "Epoch 50/700\n",
      "148/148 [==============================] - 6s 39ms/step - loss: 0.2181 - accuracy: 0.9169 - val_loss: 0.9078 - val_accuracy: 0.8273\n",
      "Epoch 51/700\n",
      "148/148 [==============================] - 7s 47ms/step - loss: 0.1670 - accuracy: 0.9361 - val_loss: 0.4713 - val_accuracy: 0.8748\n",
      "Epoch 52/700\n",
      "148/148 [==============================] - 7s 47ms/step - loss: 0.1810 - accuracy: 0.9313 - val_loss: 0.7133 - val_accuracy: 0.8476\n",
      "Epoch 53/700\n",
      "148/148 [==============================] - 7s 46ms/step - loss: 0.1532 - accuracy: 0.9387 - val_loss: 0.5005 - val_accuracy: 0.8595\n",
      "Epoch 54/700\n",
      "148/148 [==============================] - 6s 39ms/step - loss: 0.2212 - accuracy: 0.9152 - val_loss: 0.2533 - val_accuracy: 0.9152\n",
      "Epoch 55/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.1292 - accuracy: 0.9481 - val_loss: 0.3808 - val_accuracy: 0.8856\n",
      "Epoch 56/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.2357 - accuracy: 0.9176 - val_loss: 0.3094 - val_accuracy: 0.9023\n",
      "Epoch 57/700\n",
      "148/148 [==============================] - 5s 37ms/step - loss: 0.1311 - accuracy: 0.9499 - val_loss: 0.4148 - val_accuracy: 0.8772\n",
      "Epoch 58/700\n",
      "148/148 [==============================] - 6s 41ms/step - loss: 0.1742 - accuracy: 0.9290 - val_loss: 0.4682 - val_accuracy: 0.8412\n",
      "Epoch 59/700\n",
      "148/148 [==============================] - 7s 45ms/step - loss: 0.2245 - accuracy: 0.9130 - val_loss: 0.3384 - val_accuracy: 0.8931\n",
      "Epoch 60/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.1246 - accuracy: 0.9501 - val_loss: 0.2423 - val_accuracy: 0.9213\n",
      "Epoch 61/700\n",
      "148/148 [==============================] - 6s 44ms/step - loss: 0.1274 - accuracy: 0.9481 - val_loss: 0.4767 - val_accuracy: 0.8806\n",
      "Epoch 62/700\n",
      "148/148 [==============================] - 7s 44ms/step - loss: 0.1311 - accuracy: 0.9431 - val_loss: 0.4255 - val_accuracy: 0.8436\n",
      "Epoch 63/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.1907 - accuracy: 0.9215 - val_loss: 0.3513 - val_accuracy: 0.9114\n",
      "Epoch 64/700\n",
      "148/148 [==============================] - 5s 37ms/step - loss: 0.3968 - accuracy: 0.8557 - val_loss: 0.3061 - val_accuracy: 0.8938\n",
      "Epoch 65/700\n",
      "148/148 [==============================] - 6s 44ms/step - loss: 0.1781 - accuracy: 0.9326 - val_loss: 0.3546 - val_accuracy: 0.8914\n",
      "Epoch 66/700\n",
      "148/148 [==============================] - 7s 47ms/step - loss: 0.1691 - accuracy: 0.9386 - val_loss: 0.4389 - val_accuracy: 0.8358\n",
      "Epoch 67/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.3262 - accuracy: 0.8903 - val_loss: 0.3911 - val_accuracy: 0.8880\n",
      "Epoch 68/700\n",
      "148/148 [==============================] - 5s 37ms/step - loss: 0.2429 - accuracy: 0.9175 - val_loss: 0.4057 - val_accuracy: 0.8843\n",
      "Epoch 69/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.1298 - accuracy: 0.9512 - val_loss: 0.3489 - val_accuracy: 0.8884\n",
      "Epoch 70/700\n",
      "148/148 [==============================] - 5s 37ms/step - loss: 0.1345 - accuracy: 0.9443 - val_loss: 0.9117 - val_accuracy: 0.8039\n",
      "Epoch 71/700\n",
      "148/148 [==============================] - 5s 37ms/step - loss: 0.2977 - accuracy: 0.9061 - val_loss: 0.6071 - val_accuracy: 0.8449\n",
      "Epoch 72/700\n",
      "148/148 [==============================] - 5s 37ms/step - loss: 0.1791 - accuracy: 0.9330 - val_loss: 0.3701 - val_accuracy: 0.9013\n",
      "Epoch 73/700\n",
      "148/148 [==============================] - 5s 37ms/step - loss: 0.1237 - accuracy: 0.9512 - val_loss: 0.4049 - val_accuracy: 0.8935\n",
      "Epoch 74/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.1202 - accuracy: 0.9475 - val_loss: 0.3670 - val_accuracy: 0.9033\n",
      "Epoch 75/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.1171 - accuracy: 0.9517 - val_loss: 0.4486 - val_accuracy: 0.9023\n",
      "Epoch 76/700\n",
      "148/148 [==============================] - 6s 41ms/step - loss: 0.1215 - accuracy: 0.9497 - val_loss: 0.5291 - val_accuracy: 0.8890\n",
      "Epoch 77/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.2025 - accuracy: 0.9258 - val_loss: 0.6410 - val_accuracy: 0.8758\n",
      "Epoch 78/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.2201 - accuracy: 0.9245 - val_loss: 0.7902 - val_accuracy: 0.8453\n",
      "Epoch 79/700\n",
      "148/148 [==============================] - 6s 44ms/step - loss: 0.3770 - accuracy: 0.8917 - val_loss: 0.4070 - val_accuracy: 0.8877\n",
      "Epoch 80/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.1929 - accuracy: 0.9109 - val_loss: 0.3958 - val_accuracy: 0.8850\n",
      "Epoch 81/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.1233 - accuracy: 0.9484 - val_loss: 0.3272 - val_accuracy: 0.9060\n",
      "Epoch 82/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.1221 - accuracy: 0.9497 - val_loss: 0.3851 - val_accuracy: 0.9030\n",
      "Epoch 83/700\n",
      "148/148 [==============================] - 5s 37ms/step - loss: 0.1103 - accuracy: 0.9533 - val_loss: 0.2916 - val_accuracy: 0.9131\n",
      "Epoch 84/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.2474 - accuracy: 0.9229 - val_loss: 0.4742 - val_accuracy: 0.8761\n",
      "Epoch 85/700\n",
      "148/148 [==============================] - 7s 45ms/step - loss: 0.1973 - accuracy: 0.9246 - val_loss: 0.4542 - val_accuracy: 0.8717\n",
      "Epoch 86/700\n",
      "148/148 [==============================] - 7s 49ms/step - loss: 0.2254 - accuracy: 0.9203 - val_loss: 0.3067 - val_accuracy: 0.8894\n",
      "Epoch 87/700\n",
      "148/148 [==============================] - 7s 50ms/step - loss: 0.1792 - accuracy: 0.9291 - val_loss: 0.2747 - val_accuracy: 0.8996\n",
      "Epoch 88/700\n",
      "148/148 [==============================] - 7s 50ms/step - loss: 0.1816 - accuracy: 0.9097 - val_loss: 0.2538 - val_accuracy: 0.9091\n",
      "Epoch 89/700\n",
      "148/148 [==============================] - 7s 48ms/step - loss: 0.1945 - accuracy: 0.9342 - val_loss: 0.3454 - val_accuracy: 0.9077\n",
      "Epoch 90/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.1660 - accuracy: 0.9340 - val_loss: 0.5810 - val_accuracy: 0.8602\n",
      "Epoch 91/700\n",
      "148/148 [==============================] - 6s 44ms/step - loss: 0.2359 - accuracy: 0.9228 - val_loss: 0.4021 - val_accuracy: 0.8880\n",
      "Epoch 92/700\n",
      "148/148 [==============================] - 6s 42ms/step - loss: 0.1226 - accuracy: 0.9481 - val_loss: 0.3617 - val_accuracy: 0.8938\n",
      "Epoch 93/700\n",
      "148/148 [==============================] - 7s 46ms/step - loss: 0.1185 - accuracy: 0.9516 - val_loss: 0.3951 - val_accuracy: 0.9026\n",
      "Epoch 94/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.1182 - accuracy: 0.9501 - val_loss: 9.7311 - val_accuracy: 0.3746\n",
      "Epoch 95/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.3974 - accuracy: 0.8948 - val_loss: 0.4813 - val_accuracy: 0.8405\n",
      "Epoch 96/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.1872 - accuracy: 0.9327 - val_loss: 0.3648 - val_accuracy: 0.9162\n",
      "Epoch 97/700\n",
      "148/148 [==============================] - 6s 40ms/step - loss: 0.2631 - accuracy: 0.9080 - val_loss: 0.3602 - val_accuracy: 0.9080\n",
      "Epoch 98/700\n",
      "148/148 [==============================] - 7s 47ms/step - loss: 0.2142 - accuracy: 0.9176 - val_loss: 0.3088 - val_accuracy: 0.8975\n",
      "Epoch 99/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.1883 - accuracy: 0.9368 - val_loss: 0.3485 - val_accuracy: 0.9101\n",
      "Epoch 100/700\n",
      "148/148 [==============================] - 6s 38ms/step - loss: 0.1272 - accuracy: 0.9439 - val_loss: 0.3395 - val_accuracy: 0.9006\n",
      "Epoch 101/700\n",
      "148/148 [==============================] - 6s 43ms/step - loss: 0.2482 - accuracy: 0.9143 - val_loss: 0.3354 - val_accuracy: 0.9080\n",
      "Epoch 102/700\n",
      "148/148 [==============================] - 7s 45ms/step - loss: 0.1299 - accuracy: 0.9462 - val_loss: 0.4116 - val_accuracy: 0.9002\n",
      "Epoch 103/700\n",
      " 84/148 [================>.............] - ETA: 2s - loss: 0.1142 - accuracy: 0.9525"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-6d40f0a38921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    170\u001b[0m                                   patience=20, min_lr=0.00005)\n\u001b[0;32m    171\u001b[0m     hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n\u001b[1;32m--> 172\u001b[1;33m                      verbose=1, validation_data=(x_val, y_val), callbacks=[reduce_lr])  # 回调函数会在训练的时候适当被调用\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import csv\n",
    "import tempfile\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.keras import backend as K\n",
    "from utils.utilities import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(813306)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allocator_type = 'BFC'  # A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "#config.gpu_options.allow_growth = True\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "#构建数据集 channel_last\n",
    "#构建数据集 channel_last\n",
    "def load_data():    \n",
    "    X_train, labels_train, list_ch_train = read_data(data_path=\"../data/HAR_Dataset\", split=\"train\") # train\n",
    "    X_test, labels_test, list_ch_test = read_data(data_path=\"../data/HAR_Dataset\", split=\"test\") # test\n",
    "    assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "    x_train = X_train[:,:,np.newaxis,:]\n",
    "    x_val = X_test[:,:,np.newaxis,:]\n",
    "    x_train = x_train[:,:,:,6:]\n",
    "    x_val = x_val[:,:,:,6:]\n",
    "    y_train = to_categorical(labels_train)\n",
    "    y_val = to_categorical(labels_test)\n",
    "    return (x_train,y_train),(x_val,y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_resnet(input_shape, n_feature_maps, nb_classes, dropout):\n",
    "    print('build conv_x')\n",
    "    x = Input(shape=(input_shape))\n",
    "    x_total = []\n",
    "    for i in range(input_shape[-1]):\n",
    "        x_temp = Reshape((input_shape[0],1,1))(x[:,:,:,i])\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(32, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(16, (16, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        x_temp = keras.layers.AveragePooling2D(pool_size=(2, 1), strides=None, padding='same', data_format=None)(x_temp)\n",
    "        x_temp = keras.layers.BatchNormalization()(x_temp)\n",
    "        x_temp = Activation('relu')(x_temp)\n",
    "        \n",
    "        \n",
    "        x_temp = keras.layers.Conv2D(1, (8, 1),strides = (1,1), padding='same')(x_temp)\n",
    "        \n",
    "        \n",
    "        x_total.append(x_temp)\n",
    "\n",
    "    \n",
    "    x_total = K.concatenate(x_total , axis=-1)\n",
    "    conv_x = keras.layers.BatchNormalization()(x_total)  # 853\n",
    "    \n",
    "    # channel attention here\n",
    "    '''\n",
    "    x = keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = keras.layers.Dense(int(x.shape[-1]) // self.reduction, use_bias=False,activation=keras.activations.relu)(x)\n",
    "    x = keras.layers.Dense(int(inputs.shape[-1]), use_bias=False,activation=keras.activations.hard_sigmoid)(x)\n",
    "    x = keras.layers.Multiply()([inputs,x])\n",
    "    '''\n",
    " \n",
    "    conv_x = keras.layers.Conv2D(n_feature_maps, (16, 1), padding='same')(conv_x)  # input size == ouput size\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    print('build conv_y')\n",
    "    conv_y = keras.layers.Conv2D(n_feature_maps * 2, (16, 1), padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "\n",
    "    conv_y = Dropout(dropout)(conv_y)\n",
    "    '''\n",
    "    print('build conv_z')\n",
    "    conv_z = keras.layers.Conv2D(n_feature_maps, (8, 1), padding='same')(conv_x)\n",
    "    #conv_z = keras.layers.BatchNormalization()(conv_x)\n",
    "\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps)  # 若当前输出和跨层连接的x，通道数不同，则采用1*1卷积使得通道数相同\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = keras.layers.Conv2D(n_feature_maps, (1, 1), padding='same')(x_total)\n",
    "        #shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = x_total#keras.layers.BatchNormalization()(x_total)\n",
    "\n",
    "    #print('Merging skip connection')\n",
    "    # y = merge([shortcut_y, conv_z], mode='sum')\n",
    "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
    "    y = keras.layers.BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "\n",
    "    full = keras.layers.GlobalAveragePooling2D()(y)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    print('        -- model was built.')\n",
    "    return x, out\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = 7\n",
    "    channels = 3\n",
    "    dropout = 0.2\n",
    "    nb_epochs = 700\n",
    "    batch_size = 50\n",
    "    data_row = 128\n",
    "    data_column = 1\n",
    "    trainpath = r'./data'\n",
    "\n",
    "    (x_train,y_train),(x_val,y_val) = load_data()\n",
    "\n",
    "\n",
    "    tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "    input_shape = (data_row, data_column,channels)\n",
    "\n",
    "    print('train dataset size:',x_train.shape[0])\n",
    "    print('validation dataset size:',x_val.shape[0])\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    x, y = build_resnet(input_shape, 64, num, dropout)  # 建立resnet只考虑了单个example\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam(lr=0.1)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.9,\n",
    "                                  patience=20, min_lr=0.00005)\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n",
    "                     verbose=1, validation_data=(x_val, y_val), callbacks=[reduce_lr])  # 回调函数会在训练的时候适当被调用\n",
    "\n",
    "\n",
    "    # 测试\n",
    "    print(\"------------------------ 测试中---------------------------\")\n",
    "    #evaluation of the model\n",
    "    scores = model.evaluate(x_val,y_val)\n",
    "    print('Baseline Error: %.2f%%'%(100 * (1 - scores[1])))\n",
    "    keras.models.save_model(model, '../model/test_resnet_v4.h5')\n",
    "    keras_file = '../model/test_resnet_v4.h5'\n",
    "    _, zip1 = tempfile.mkstemp('.zip') \n",
    "    with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(keras_file)\n",
    "    print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "          (os.path.getsize(keras_file) / float(2**20)))\n",
    "    print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "          (os.path.getsize(zip1) / float(2**20)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 7352\n",
      "validation dataset size: 2947\n",
      "build conv_x\n",
      "build conv_y\n",
      "build conv_z\n",
      "Merging skip connection\n",
      "        -- model was built.\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 128, 1, 9)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 1, 10)   1540        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 128, 1, 10)   40          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 1, 64)   10944       batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 128, 1, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 1, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 128, 1, 128)  139392      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 128, 1, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 1, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128, 1, 128)  0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 128, 1, 64)   704         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 128, 1, 64)   73792       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 128, 1, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 128, 1, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 1, 64)   0           batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 1, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 64)           0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 7)            455         global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 228,147\n",
      "Trainable params: 227,487\n",
      "Non-trainable params: 660\n",
      "__________________________________________________________________________________________________\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/700\n",
      "7352/7352 [==============================] - 7s 994us/sample - loss: 0.2951 - accuracy: 0.9140 - val_loss: 0.9670 - val_accuracy: 0.6542\n",
      "Epoch 2/700\n",
      "7352/7352 [==============================] - 4s 599us/sample - loss: 0.1488 - accuracy: 0.9422 - val_loss: 0.2640 - val_accuracy: 0.9158\n",
      "Epoch 3/700\n",
      "7352/7352 [==============================] - 4s 589us/sample - loss: 0.1384 - accuracy: 0.9452 - val_loss: 0.2039 - val_accuracy: 0.9169\n",
      "Epoch 4/700\n",
      "7352/7352 [==============================] - 3s 458us/sample - loss: 0.1237 - accuracy: 0.9509 - val_loss: 0.2273 - val_accuracy: 0.9148\n",
      "Epoch 5/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.1233 - accuracy: 0.9489 - val_loss: 0.2043 - val_accuracy: 0.9175\n",
      "Epoch 6/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.1293 - accuracy: 0.9472 - val_loss: 0.2447 - val_accuracy: 0.9141\n",
      "Epoch 7/700\n",
      "7352/7352 [==============================] - 3s 387us/sample - loss: 0.1225 - accuracy: 0.9516 - val_loss: 0.2404 - val_accuracy: 0.9189\n",
      "Epoch 8/700\n",
      "7352/7352 [==============================] - 3s 438us/sample - loss: 0.1121 - accuracy: 0.9531 - val_loss: 0.2366 - val_accuracy: 0.9070\n",
      "Epoch 9/700\n",
      "7352/7352 [==============================] - 3s 450us/sample - loss: 0.1141 - accuracy: 0.9502 - val_loss: 0.2283 - val_accuracy: 0.9036\n",
      "Epoch 10/700\n",
      "7352/7352 [==============================] - 3s 412us/sample - loss: 0.1208 - accuracy: 0.9493 - val_loss: 0.2052 - val_accuracy: 0.9369\n",
      "Epoch 11/700\n",
      "7352/7352 [==============================] - 4s 516us/sample - loss: 0.1135 - accuracy: 0.9516 - val_loss: 0.2179 - val_accuracy: 0.9220\n",
      "Epoch 12/700\n",
      "7352/7352 [==============================] - 5s 638us/sample - loss: 0.1124 - accuracy: 0.9531 - val_loss: 0.2060 - val_accuracy: 0.9206\n",
      "Epoch 13/700\n",
      "7352/7352 [==============================] - 4s 488us/sample - loss: 0.1115 - accuracy: 0.9509 - val_loss: 0.2472 - val_accuracy: 0.9189\n",
      "Epoch 14/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.1061 - accuracy: 0.9491 - val_loss: 0.2440 - val_accuracy: 0.9128\n",
      "Epoch 15/700\n",
      "7352/7352 [==============================] - 3s 469us/sample - loss: 0.1030 - accuracy: 0.9533 - val_loss: 0.2177 - val_accuracy: 0.9359\n",
      "Epoch 16/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.1001 - accuracy: 0.9539 - val_loss: 0.2292 - val_accuracy: 0.9247\n",
      "Epoch 17/700\n",
      "7352/7352 [==============================] - 4s 507us/sample - loss: 0.1009 - accuracy: 0.9547 - val_loss: 0.2288 - val_accuracy: 0.9223\n",
      "Epoch 18/700\n",
      "7352/7352 [==============================] - 3s 471us/sample - loss: 0.1142 - accuracy: 0.9521 - val_loss: 0.2983 - val_accuracy: 0.9118\n",
      "Epoch 19/700\n",
      "7352/7352 [==============================] - 4s 589us/sample - loss: 0.1066 - accuracy: 0.9548 - val_loss: 0.2559 - val_accuracy: 0.9328\n",
      "Epoch 20/700\n",
      "7352/7352 [==============================] - 3s 432us/sample - loss: 0.0996 - accuracy: 0.9584 - val_loss: 0.2152 - val_accuracy: 0.9488\n",
      "Epoch 21/700\n",
      "7352/7352 [==============================] - 3s 411us/sample - loss: 0.1089 - accuracy: 0.9542 - val_loss: 0.2310 - val_accuracy: 0.9240\n",
      "Epoch 22/700\n",
      "7352/7352 [==============================] - 3s 385us/sample - loss: 0.1006 - accuracy: 0.9559 - val_loss: 0.2166 - val_accuracy: 0.9386\n",
      "Epoch 23/700\n",
      "7352/7352 [==============================] - 3s 410us/sample - loss: 0.0971 - accuracy: 0.9597 - val_loss: 0.2168 - val_accuracy: 0.9298\n",
      "Epoch 24/700\n",
      "7352/7352 [==============================] - 3s 377us/sample - loss: 0.1020 - accuracy: 0.9570 - val_loss: 0.2261 - val_accuracy: 0.9318\n",
      "Epoch 25/700\n",
      "7352/7352 [==============================] - 3s 395us/sample - loss: 0.0905 - accuracy: 0.9614 - val_loss: 0.2299 - val_accuracy: 0.9223\n",
      "Epoch 26/700\n",
      "7352/7352 [==============================] - 3s 407us/sample - loss: 0.0918 - accuracy: 0.9593 - val_loss: 0.2985 - val_accuracy: 0.9165\n",
      "Epoch 27/700\n",
      "7352/7352 [==============================] - 3s 381us/sample - loss: 0.0992 - accuracy: 0.9548 - val_loss: 0.2676 - val_accuracy: 0.9128\n",
      "Epoch 28/700\n",
      "7352/7352 [==============================] - 3s 365us/sample - loss: 0.0958 - accuracy: 0.9566 - val_loss: 0.2645 - val_accuracy: 0.9335\n",
      "Epoch 29/700\n",
      "7352/7352 [==============================] - 3s 370us/sample - loss: 0.0913 - accuracy: 0.9578 - val_loss: 0.2304 - val_accuracy: 0.9386\n",
      "Epoch 30/700\n",
      "7352/7352 [==============================] - 3s 350us/sample - loss: 0.0946 - accuracy: 0.9596 - val_loss: 0.2295 - val_accuracy: 0.9433\n",
      "Epoch 31/700\n",
      "7352/7352 [==============================] - 3s 375us/sample - loss: 0.0916 - accuracy: 0.9591 - val_loss: 0.2372 - val_accuracy: 0.9372\n",
      "Epoch 32/700\n",
      "7352/7352 [==============================] - 3s 400us/sample - loss: 0.0832 - accuracy: 0.9634 - val_loss: 0.2342 - val_accuracy: 0.9301\n",
      "Epoch 33/700\n",
      "7352/7352 [==============================] - 3s 365us/sample - loss: 0.0937 - accuracy: 0.9570 - val_loss: 0.2113 - val_accuracy: 0.9440\n",
      "Epoch 34/700\n",
      "7352/7352 [==============================] - 3s 373us/sample - loss: 0.0828 - accuracy: 0.9664 - val_loss: 0.2112 - val_accuracy: 0.9410\n",
      "Epoch 35/700\n",
      "7352/7352 [==============================] - 3s 344us/sample - loss: 0.0853 - accuracy: 0.9619 - val_loss: 0.1982 - val_accuracy: 0.9382\n",
      "Epoch 36/700\n",
      "7352/7352 [==============================] - 3s 365us/sample - loss: 0.0815 - accuracy: 0.9626 - val_loss: 0.2248 - val_accuracy: 0.9359\n",
      "Epoch 37/700\n",
      "7352/7352 [==============================] - 3s 361us/sample - loss: 0.0775 - accuracy: 0.9663 - val_loss: 0.2298 - val_accuracy: 0.9318\n",
      "Epoch 38/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0810 - accuracy: 0.9631 - val_loss: 0.2852 - val_accuracy: 0.9206\n",
      "Epoch 39/700\n",
      "7352/7352 [==============================] - 3s 395us/sample - loss: 0.0843 - accuracy: 0.9634 - val_loss: 0.2543 - val_accuracy: 0.9454\n",
      "Epoch 40/700\n",
      "7352/7352 [==============================] - 3s 378us/sample - loss: 0.0861 - accuracy: 0.9615 - val_loss: 0.2141 - val_accuracy: 0.9318859 - accuracy: 0.96\n",
      "Epoch 41/700\n",
      "7352/7352 [==============================] - 3s 416us/sample - loss: 0.0862 - accuracy: 0.9627 - val_loss: 0.2176 - val_accuracy: 0.9311\n",
      "Epoch 42/700\n",
      "7352/7352 [==============================] - 3s 413us/sample - loss: 0.0803 - accuracy: 0.9646 - val_loss: 0.2322 - val_accuracy: 0.9196\n",
      "Epoch 43/700\n",
      "7352/7352 [==============================] - 3s 364us/sample - loss: 0.0752 - accuracy: 0.9653 - val_loss: 0.2363 - val_accuracy: 0.9345\n",
      "Epoch 44/700\n",
      "7352/7352 [==============================] - 3s 366us/sample - loss: 0.0749 - accuracy: 0.9652 - val_loss: 0.2071 - val_accuracy: 0.9413\n",
      "Epoch 45/700\n",
      "7352/7352 [==============================] - 3s 381us/sample - loss: 0.0892 - accuracy: 0.9618 - val_loss: 0.2021 - val_accuracy: 0.9457\n",
      "Epoch 46/700\n",
      "7352/7352 [==============================] - 3s 378us/sample - loss: 0.0782 - accuracy: 0.9649 - val_loss: 0.2478 - val_accuracy: 0.9141\n",
      "Epoch 47/700\n",
      "7352/7352 [==============================] - 3s 369us/sample - loss: 0.0789 - accuracy: 0.9626 - val_loss: 0.2009 - val_accuracy: 0.9379\n",
      "Epoch 48/700\n",
      "7352/7352 [==============================] - 3s 386us/sample - loss: 0.0758 - accuracy: 0.9648 - val_loss: 0.1962 - val_accuracy: 0.9386\n",
      "Epoch 49/700\n",
      "7352/7352 [==============================] - 3s 403us/sample - loss: 0.0719 - accuracy: 0.9686 - val_loss: 0.1711 - val_accuracy: 0.9450\n",
      "Epoch 50/700\n",
      "7352/7352 [==============================] - 3s 397us/sample - loss: 0.0721 - accuracy: 0.9680 - val_loss: 0.2361 - val_accuracy: 0.9410\n",
      "Epoch 51/700\n",
      "7352/7352 [==============================] - 3s 426us/sample - loss: 0.0817 - accuracy: 0.9627 - val_loss: 0.2380 - val_accuracy: 0.9318\n",
      "Epoch 52/700\n",
      "7352/7352 [==============================] - 4s 479us/sample - loss: 0.0693 - accuracy: 0.9697 - val_loss: 0.2366 - val_accuracy: 0.9264\n",
      "Epoch 53/700\n",
      "7352/7352 [==============================] - 3s 368us/sample - loss: 0.0722 - accuracy: 0.9686 - val_loss: 0.2474 - val_accuracy: 0.9365\n",
      "Epoch 54/700\n",
      "7352/7352 [==============================] - 3s 369us/sample - loss: 0.0808 - accuracy: 0.9646 - val_loss: 0.2287 - val_accuracy: 0.9287\n",
      "Epoch 55/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0764 - accuracy: 0.9699 - val_loss: 0.2128 - val_accuracy: 0.9365\n",
      "Epoch 56/700\n",
      "7352/7352 [==============================] - 3s 379us/sample - loss: 0.0819 - accuracy: 0.9641 - val_loss: 0.2246 - val_accuracy: 0.9403\n",
      "Epoch 57/700\n",
      "7352/7352 [==============================] - 3s 393us/sample - loss: 0.0713 - accuracy: 0.9694 - val_loss: 0.2194 - val_accuracy: 0.9450\n",
      "Epoch 58/700\n",
      "7352/7352 [==============================] - 3s 393us/sample - loss: 0.0703 - accuracy: 0.9676 - val_loss: 0.2492 - val_accuracy: 0.9376\n",
      "Epoch 59/700\n",
      "7352/7352 [==============================] - 3s 354us/sample - loss: 0.0752 - accuracy: 0.9678 - val_loss: 0.2409 - val_accuracy: 0.9467\n",
      "Epoch 60/700\n",
      "7352/7352 [==============================] - 3s 413us/sample - loss: 0.0848 - accuracy: 0.9645 - val_loss: 0.2423 - val_accuracy: 0.9382\n",
      "Epoch 61/700\n",
      "7352/7352 [==============================] - 3s 399us/sample - loss: 0.0757 - accuracy: 0.9675 - val_loss: 0.2043 - val_accuracy: 0.9457\n",
      "Epoch 62/700\n",
      "7352/7352 [==============================] - 3s 385us/sample - loss: 0.0727 - accuracy: 0.9686 - val_loss: 0.1835 - val_accuracy: 0.9474\n",
      "Epoch 63/700\n",
      "7352/7352 [==============================] - 3s 390us/sample - loss: 0.0701 - accuracy: 0.9701 - val_loss: 0.2066 - val_accuracy: 0.9226\n",
      "Epoch 64/700\n",
      "7352/7352 [==============================] - 3s 404us/sample - loss: 0.0814 - accuracy: 0.9663 - val_loss: 0.2133 - val_accuracy: 0.9359\n",
      "Epoch 65/700\n",
      "7352/7352 [==============================] - 3s 367us/sample - loss: 0.0672 - accuracy: 0.9732 - val_loss: 0.2307 - val_accuracy: 0.9433\n",
      "Epoch 66/700\n",
      "7352/7352 [==============================] - 3s 363us/sample - loss: 0.0657 - accuracy: 0.9728 - val_loss: 0.2026 - val_accuracy: 0.9477\n",
      "Epoch 67/700\n",
      "7352/7352 [==============================] - 3s 374us/sample - loss: 0.0719 - accuracy: 0.9706 - val_loss: 0.1960 - val_accuracy: 0.9369\n",
      "Epoch 68/700\n",
      "7352/7352 [==============================] - 3s 402us/sample - loss: 0.0649 - accuracy: 0.9706 - val_loss: 0.1802 - val_accuracy: 0.9498\n",
      "Epoch 69/700\n",
      "7352/7352 [==============================] - 3s 351us/sample - loss: 0.0676 - accuracy: 0.9724 - val_loss: 0.1893 - val_accuracy: 0.9362\n",
      "Epoch 70/700\n",
      "7352/7352 [==============================] - 3s 434us/sample - loss: 0.0696 - accuracy: 0.9690 - val_loss: 0.1937 - val_accuracy: 0.9481\n",
      "Epoch 71/700\n",
      "7352/7352 [==============================] - 3s 411us/sample - loss: 0.0622 - accuracy: 0.9731 - val_loss: 0.2058 - val_accuracy: 0.9511\n",
      "Epoch 72/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0655 - accuracy: 0.9717 - val_loss: 0.2300 - val_accuracy: 0.9301\n",
      "Epoch 73/700\n",
      "7352/7352 [==============================] - 3s 430us/sample - loss: 0.0677 - accuracy: 0.9697 - val_loss: 0.1981 - val_accuracy: 0.9457\n",
      "Epoch 74/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0626 - accuracy: 0.9725 - val_loss: 0.2230 - val_accuracy: 0.9389\n",
      "Epoch 75/700\n",
      "7352/7352 [==============================] - 3s 442us/sample - loss: 0.0661 - accuracy: 0.9717 - val_loss: 0.2139 - val_accuracy: 0.9450\n",
      "Epoch 76/700\n",
      "7352/7352 [==============================] - 3s 452us/sample - loss: 0.0627 - accuracy: 0.9736 - val_loss: 0.2040 - val_accuracy: 0.9484\n",
      "Epoch 77/700\n",
      "7352/7352 [==============================] - 3s 446us/sample - loss: 0.0618 - accuracy: 0.9724 - val_loss: 0.1847 - val_accuracy: 0.9477\n",
      "Epoch 78/700\n",
      "7352/7352 [==============================] - 4s 486us/sample - loss: 0.0628 - accuracy: 0.9721 - val_loss: 0.1792 - val_accuracy: 0.9515\n",
      "Epoch 79/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0598 - accuracy: 0.9732 - val_loss: 0.2307 - val_accuracy: 0.9484\n",
      "Epoch 80/700\n",
      "7352/7352 [==============================] - 3s 457us/sample - loss: 0.0800 - accuracy: 0.9664 - val_loss: 0.1839 - val_accuracy: 0.9427\n",
      "Epoch 81/700\n",
      "7352/7352 [==============================] - 3s 475us/sample - loss: 0.0684 - accuracy: 0.9698 - val_loss: 0.1820 - val_accuracy: 0.9484\n",
      "Epoch 82/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0705 - accuracy: 0.9683 - val_loss: 0.2001 - val_accuracy: 0.9376\n",
      "Epoch 83/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0612 - accuracy: 0.9744 - val_loss: 0.1748 - val_accuracy: 0.9559\n",
      "Epoch 84/700\n",
      "7352/7352 [==============================] - 3s 465us/sample - loss: 0.0600 - accuracy: 0.9739 - val_loss: 0.1699 - val_accuracy: 0.9552\n",
      "Epoch 85/700\n",
      "7352/7352 [==============================] - 3s 452us/sample - loss: 0.0601 - accuracy: 0.9743 - val_loss: 0.2243 - val_accuracy: 0.9467\n",
      "Epoch 86/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0677 - accuracy: 0.9701 - val_loss: 0.2263 - val_accuracy: 0.9389\n",
      "Epoch 87/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0602 - accuracy: 0.9750 - val_loss: 0.1645 - val_accuracy: 0.9559\n",
      "Epoch 88/700\n",
      "7352/7352 [==============================] - 3s 426us/sample - loss: 0.0583 - accuracy: 0.9736 - val_loss: 0.2293 - val_accuracy: 0.9328\n",
      "Epoch 89/700\n",
      "7352/7352 [==============================] - 4s 503us/sample - loss: 0.0642 - accuracy: 0.9718 - val_loss: 0.1927 - val_accuracy: 0.9589\n",
      "Epoch 90/700\n",
      "7352/7352 [==============================] - 3s 470us/sample - loss: 0.0675 - accuracy: 0.9713 - val_loss: 0.1937 - val_accuracy: 0.9511\n",
      "Epoch 91/700\n",
      "7352/7352 [==============================] - 3s 394us/sample - loss: 0.0633 - accuracy: 0.9714 - val_loss: 0.1945 - val_accuracy: 0.9566\n",
      "Epoch 92/700\n",
      "7352/7352 [==============================] - 3s 467us/sample - loss: 0.0580 - accuracy: 0.9742 - val_loss: 0.2088 - val_accuracy: 0.9440\n",
      "Epoch 93/700\n",
      "7352/7352 [==============================] - 3s 442us/sample - loss: 0.0560 - accuracy: 0.9765 - val_loss: 0.2001 - val_accuracy: 0.9420\n",
      "Epoch 94/700\n",
      "7352/7352 [==============================] - 3s 438us/sample - loss: 0.0624 - accuracy: 0.9731 - val_loss: 0.2222 - val_accuracy: 0.9481\n",
      "Epoch 95/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0568 - accuracy: 0.9752 - val_loss: 0.2211 - val_accuracy: 0.9491\n",
      "Epoch 96/700\n",
      "7352/7352 [==============================] - 3s 451us/sample - loss: 0.0534 - accuracy: 0.9771 - val_loss: 0.1899 - val_accuracy: 0.9542\n",
      "Epoch 97/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0553 - accuracy: 0.9773 - val_loss: 0.1844 - val_accuracy: 0.9501\n",
      "Epoch 98/700\n",
      "7352/7352 [==============================] - 3s 453us/sample - loss: 0.0544 - accuracy: 0.9755 - val_loss: 0.2048 - val_accuracy: 0.9586\n",
      "Epoch 99/700\n",
      "7352/7352 [==============================] - 3s 396us/sample - loss: 0.0551 - accuracy: 0.9725 - val_loss: 0.1751 - val_accuracy: 0.9596\n",
      "Epoch 100/700\n",
      "7352/7352 [==============================] - 4s 478us/sample - loss: 0.0512 - accuracy: 0.9793 - val_loss: 0.2017 - val_accuracy: 0.9508\n",
      "Epoch 101/700\n",
      "7352/7352 [==============================] - 3s 463us/sample - loss: 0.0575 - accuracy: 0.9732 - val_loss: 0.1957 - val_accuracy: 0.9515\n",
      "Epoch 102/700\n",
      "7352/7352 [==============================] - 3s 456us/sample - loss: 0.0533 - accuracy: 0.9773 - val_loss: 0.2043 - val_accuracy: 0.9593\n",
      "Epoch 103/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.0480 - accuracy: 0.9804 - val_loss: 0.2184 - val_accuracy: 0.9525\n",
      "Epoch 104/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0551 - accuracy: 0.9765 - val_loss: 0.2172 - val_accuracy: 0.9583\n",
      "Epoch 105/700\n",
      "7352/7352 [==============================] - 3s 393us/sample - loss: 0.0536 - accuracy: 0.9789 - val_loss: 0.1804 - val_accuracy: 0.9532\n",
      "Epoch 106/700\n",
      "7352/7352 [==============================] - 3s 419us/sample - loss: 0.0503 - accuracy: 0.9781 - val_loss: 0.1939 - val_accuracy: 0.9630\n",
      "Epoch 107/700\n",
      "7352/7352 [==============================] - 3s 462us/sample - loss: 0.0512 - accuracy: 0.9788 - val_loss: 0.1729 - val_accuracy: 0.9623\n",
      "Epoch 108/700\n",
      "7352/7352 [==============================] - 3s 451us/sample - loss: 0.0532 - accuracy: 0.9762 - val_loss: 0.1898 - val_accuracy: 0.9586\n",
      "Epoch 109/700\n",
      "7352/7352 [==============================] - 3s 434us/sample - loss: 0.0488 - accuracy: 0.9800 - val_loss: 0.2048 - val_accuracy: 0.9600\n",
      "Epoch 110/700\n",
      "7352/7352 [==============================] - 3s 442us/sample - loss: 0.0535 - accuracy: 0.9773 - val_loss: 0.2325 - val_accuracy: 0.9447\n",
      "Epoch 111/700\n",
      "7352/7352 [==============================] - 4s 486us/sample - loss: 0.0494 - accuracy: 0.9780 - val_loss: 0.2134 - val_accuracy: 0.9579\n",
      "Epoch 112/700\n",
      "7352/7352 [==============================] - 3s 428us/sample - loss: 0.0447 - accuracy: 0.9816 - val_loss: 0.1893 - val_accuracy: 0.9654\n",
      "Epoch 113/700\n",
      "7352/7352 [==============================] - 3s 450us/sample - loss: 0.0482 - accuracy: 0.9808 - val_loss: 0.1899 - val_accuracy: 0.9393\n",
      "Epoch 114/700\n",
      "7352/7352 [==============================] - 3s 424us/sample - loss: 0.0496 - accuracy: 0.9793 - val_loss: 0.2047 - val_accuracy: 0.9559\n",
      "Epoch 115/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0530 - accuracy: 0.9777 - val_loss: 0.2229 - val_accuracy: 0.9511\n",
      "Epoch 116/700\n",
      "7352/7352 [==============================] - 3s 412us/sample - loss: 0.0642 - accuracy: 0.9739 - val_loss: 0.2050 - val_accuracy: 0.9440\n",
      "Epoch 117/700\n",
      "7352/7352 [==============================] - 4s 495us/sample - loss: 0.0471 - accuracy: 0.9801 - val_loss: 0.2425 - val_accuracy: 0.9410\n",
      "Epoch 118/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0464 - accuracy: 0.9815 - val_loss: 0.1815 - val_accuracy: 0.9549\n",
      "Epoch 119/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0433 - accuracy: 0.9818 - val_loss: 0.1718 - val_accuracy: 0.9593\n",
      "Epoch 120/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0490 - accuracy: 0.9804 - val_loss: 0.2098 - val_accuracy: 0.9552\n",
      "Epoch 121/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0436 - accuracy: 0.9818 - val_loss: 0.2001 - val_accuracy: 0.9562\n",
      "Epoch 122/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.0480 - accuracy: 0.9800 - val_loss: 0.1763 - val_accuracy: 0.9647\n",
      "Epoch 123/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0507 - accuracy: 0.9797 - val_loss: 0.2307 - val_accuracy: 0.9559\n",
      "Epoch 124/700\n",
      "7352/7352 [==============================] - 3s 462us/sample - loss: 0.0434 - accuracy: 0.9820 - val_loss: 0.1832 - val_accuracy: 0.9579\n",
      "Epoch 125/700\n",
      "7352/7352 [==============================] - 3s 417us/sample - loss: 0.0409 - accuracy: 0.9823 - val_loss: 0.1890 - val_accuracy: 0.9576\n",
      "Epoch 126/700\n",
      "7352/7352 [==============================] - 3s 427us/sample - loss: 0.0458 - accuracy: 0.9801 - val_loss: 0.1788 - val_accuracy: 0.9593\n",
      "Epoch 127/700\n",
      "7352/7352 [==============================] - 3s 460us/sample - loss: 0.0389 - accuracy: 0.9834 - val_loss: 0.1736 - val_accuracy: 0.9549\n",
      "Epoch 128/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.0418 - accuracy: 0.9835 - val_loss: 0.1738 - val_accuracy: 0.9576\n",
      "Epoch 129/700\n",
      "7352/7352 [==============================] - 3s 472us/sample - loss: 0.0397 - accuracy: 0.9831 - val_loss: 0.1637 - val_accuracy: 0.9593\n",
      "Epoch 130/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0455 - accuracy: 0.9827 - val_loss: 0.2087 - val_accuracy: 0.9623\n",
      "Epoch 131/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0362 - accuracy: 0.9842 - val_loss: 0.1995 - val_accuracy: 0.9695\n",
      "Epoch 132/700\n",
      "7352/7352 [==============================] - 4s 484us/sample - loss: 0.0449 - accuracy: 0.9812 - val_loss: 0.2035 - val_accuracy: 0.9623\n",
      "Epoch 133/700\n",
      "7352/7352 [==============================] - 3s 443us/sample - loss: 0.0393 - accuracy: 0.9833 - val_loss: 0.1797 - val_accuracy: 0.9684\n",
      "Epoch 134/700\n",
      "7352/7352 [==============================] - 3s 462us/sample - loss: 0.0418 - accuracy: 0.9837 - val_loss: 0.1613 - val_accuracy: 0.9623\n",
      "Epoch 135/700\n",
      "7352/7352 [==============================] - 3s 407us/sample - loss: 0.0366 - accuracy: 0.9848 - val_loss: 0.2409 - val_accuracy: 0.9569\n",
      "Epoch 136/700\n",
      "7352/7352 [==============================] - 4s 507us/sample - loss: 0.0537 - accuracy: 0.9793 - val_loss: 0.1626 - val_accuracy: 0.9315\n",
      "Epoch 137/700\n",
      "7352/7352 [==============================] - 3s 470us/sample - loss: 0.0722 - accuracy: 0.9699 - val_loss: 0.1317 - val_accuracy: 0.9589\n",
      "Epoch 138/700\n",
      "7352/7352 [==============================] - 3s 464us/sample - loss: 0.0426 - accuracy: 0.9823 - val_loss: 0.1394 - val_accuracy: 0.9620\n",
      "Epoch 139/700\n",
      "7352/7352 [==============================] - 4s 489us/sample - loss: 0.0450 - accuracy: 0.9818 - val_loss: 0.1494 - val_accuracy: 0.9589\n",
      "Epoch 140/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0410 - accuracy: 0.9839 - val_loss: 0.1817 - val_accuracy: 0.9562\n",
      "Epoch 141/700\n",
      "7352/7352 [==============================] - 3s 469us/sample - loss: 0.0386 - accuracy: 0.9838 - val_loss: 0.2964 - val_accuracy: 0.9427\n",
      "Epoch 142/700\n",
      "7352/7352 [==============================] - 3s 449us/sample - loss: 0.0501 - accuracy: 0.9807 - val_loss: 0.2050 - val_accuracy: 0.9467\n",
      "Epoch 143/700\n",
      "7352/7352 [==============================] - 3s 429us/sample - loss: 0.0341 - accuracy: 0.9867 - val_loss: 0.1561 - val_accuracy: 0.9654\n",
      "Epoch 144/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0373 - accuracy: 0.9856 - val_loss: 0.1402 - val_accuracy: 0.9667\n",
      "Epoch 145/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0595 - accuracy: 0.9766 - val_loss: 0.1581 - val_accuracy: 0.9589\n",
      "Epoch 146/700\n",
      "7352/7352 [==============================] - 3s 417us/sample - loss: 0.0401 - accuracy: 0.9831 - val_loss: 0.1511 - val_accuracy: 0.9623\n",
      "Epoch 147/700\n",
      "7352/7352 [==============================] - 4s 522us/sample - loss: 0.0418 - accuracy: 0.9859 - val_loss: 0.1813 - val_accuracy: 0.9634\n",
      "Epoch 148/700\n",
      "7352/7352 [==============================] - 3s 423us/sample - loss: 0.0469 - accuracy: 0.9819 - val_loss: 0.2287 - val_accuracy: 0.9522\n",
      "Epoch 149/700\n",
      "7352/7352 [==============================] - 3s 416us/sample - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.1774 - val_accuracy: 0.9606\n",
      "Epoch 150/700\n",
      "7352/7352 [==============================] - 3s 424us/sample - loss: 0.0386 - accuracy: 0.9846 - val_loss: 0.2090 - val_accuracy: 0.9535\n",
      "Epoch 151/700\n",
      "7352/7352 [==============================] - 3s 463us/sample - loss: 0.0606 - accuracy: 0.9742 - val_loss: 0.1806 - val_accuracy: 0.9600\n",
      "Epoch 152/700\n",
      "7352/7352 [==============================] - 3s 427us/sample - loss: 0.0450 - accuracy: 0.9815 - val_loss: 0.2201 - val_accuracy: 0.9511\n",
      "Epoch 153/700\n",
      "7352/7352 [==============================] - 3s 473us/sample - loss: 0.0387 - accuracy: 0.9850 - val_loss: 0.2497 - val_accuracy: 0.9440\n",
      "Epoch 154/700\n",
      "7352/7352 [==============================] - 3s 468us/sample - loss: 0.0349 - accuracy: 0.9849 - val_loss: 0.1927 - val_accuracy: 0.9559\n",
      "Epoch 155/700\n",
      "7352/7352 [==============================] - 3s 460us/sample - loss: 0.0356 - accuracy: 0.9860 - val_loss: 0.2242 - val_accuracy: 0.9532\n",
      "Epoch 156/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0360 - accuracy: 0.9856 - val_loss: 0.2564 - val_accuracy: 0.9447\n",
      "Epoch 157/700\n",
      "7352/7352 [==============================] - 3s 394us/sample - loss: 0.0438 - accuracy: 0.9827 - val_loss: 0.1820 - val_accuracy: 0.9606\n",
      "Epoch 158/700\n",
      "7352/7352 [==============================] - 4s 480us/sample - loss: 0.0395 - accuracy: 0.9837 - val_loss: 0.2112 - val_accuracy: 0.9549\n",
      "Epoch 159/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0364 - accuracy: 0.9864 - val_loss: 0.1649 - val_accuracy: 0.9627\n",
      "Epoch 160/700\n",
      "7352/7352 [==============================] - 4s 485us/sample - loss: 0.0374 - accuracy: 0.9830 - val_loss: 0.1767 - val_accuracy: 0.9620\n",
      "Epoch 161/700\n",
      "7352/7352 [==============================] - 3s 460us/sample - loss: 0.0409 - accuracy: 0.9849 - val_loss: 0.1405 - val_accuracy: 0.9650\n",
      "Epoch 162/700\n",
      "7352/7352 [==============================] - 4s 485us/sample - loss: 0.0390 - accuracy: 0.9842 - val_loss: 0.2267 - val_accuracy: 0.9535\n",
      "Epoch 163/700\n",
      "7352/7352 [==============================] - 4s 489us/sample - loss: 0.0594 - accuracy: 0.9754 - val_loss: 0.1745 - val_accuracy: 0.9528\n",
      "Epoch 164/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0374 - accuracy: 0.9845 - val_loss: 0.1778 - val_accuracy: 0.9617\n",
      "Epoch 165/700\n",
      "7352/7352 [==============================] - 3s 451us/sample - loss: 0.0361 - accuracy: 0.9852 - val_loss: 0.1750 - val_accuracy: 0.9600\n",
      "Epoch 166/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0359 - accuracy: 0.9844 - val_loss: 0.1785 - val_accuracy: 0.9623\n",
      "Epoch 167/700\n",
      "7352/7352 [==============================] - 3s 461us/sample - loss: 0.0430 - accuracy: 0.9838 - val_loss: 0.1661 - val_accuracy: 0.9586\n",
      "Epoch 168/700\n",
      "7352/7352 [==============================] - 3s 437us/sample - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.1721 - val_accuracy: 0.9596\n",
      "Epoch 169/700\n",
      "7352/7352 [==============================] - 3s 449us/sample - loss: 0.0345 - accuracy: 0.9874 - val_loss: 0.1872 - val_accuracy: 0.9637\n",
      "Epoch 170/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0334 - accuracy: 0.9859 - val_loss: 0.1882 - val_accuracy: 0.9572\n",
      "Epoch 171/700\n",
      "7352/7352 [==============================] - 3s 467us/sample - loss: 0.0347 - accuracy: 0.9867 - val_loss: 0.1473 - val_accuracy: 0.9684\n",
      "Epoch 172/700\n",
      "7352/7352 [==============================] - 3s 437us/sample - loss: 0.0317 - accuracy: 0.9879 - val_loss: 0.1701 - val_accuracy: 0.9664\n",
      "Epoch 173/700\n",
      "7352/7352 [==============================] - 3s 434us/sample - loss: 0.0303 - accuracy: 0.9880 - val_loss: 0.1529 - val_accuracy: 0.9715\n",
      "Epoch 174/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0344 - accuracy: 0.9856 - val_loss: 0.1844 - val_accuracy: 0.9661\n",
      "Epoch 175/700\n",
      "7352/7352 [==============================] - 3s 472us/sample - loss: 0.0412 - accuracy: 0.9854 - val_loss: 0.1843 - val_accuracy: 0.9627\n",
      "Epoch 176/700\n",
      "7352/7352 [==============================] - 4s 478us/sample - loss: 0.0400 - accuracy: 0.9839 - val_loss: 0.1534 - val_accuracy: 0.9691\n",
      "Epoch 177/700\n",
      "7352/7352 [==============================] - 3s 434us/sample - loss: 0.0278 - accuracy: 0.9888 - val_loss: 0.1339 - val_accuracy: 0.9664\n",
      "Epoch 178/700\n",
      "7352/7352 [==============================] - 3s 460us/sample - loss: 0.0290 - accuracy: 0.9897 - val_loss: 0.1869 - val_accuracy: 0.9674\n",
      "Epoch 179/700\n",
      "7352/7352 [==============================] - 3s 468us/sample - loss: 0.0333 - accuracy: 0.9865 - val_loss: 0.1898 - val_accuracy: 0.9647\n",
      "Epoch 180/700\n",
      "7352/7352 [==============================] - 4s 512us/sample - loss: 0.0320 - accuracy: 0.9876 - val_loss: 0.1706 - val_accuracy: 0.9671\n",
      "Epoch 181/700\n",
      "7352/7352 [==============================] - 3s 417us/sample - loss: 0.0310 - accuracy: 0.9878 - val_loss: 0.1630 - val_accuracy: 0.9667\n",
      "Epoch 182/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0346 - accuracy: 0.9857 - val_loss: 0.1926 - val_accuracy: 0.9579\n",
      "Epoch 183/700\n",
      "7352/7352 [==============================] - 3s 446us/sample - loss: 0.0294 - accuracy: 0.9884 - val_loss: 0.1966 - val_accuracy: 0.9617\n",
      "Epoch 184/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0397 - accuracy: 0.9838 - val_loss: 0.1287 - val_accuracy: 0.9630\n",
      "Epoch 185/700\n",
      "7352/7352 [==============================] - 3s 462us/sample - loss: 0.0328 - accuracy: 0.9868 - val_loss: 0.1826 - val_accuracy: 0.9566\n",
      "Epoch 186/700\n",
      "7352/7352 [==============================] - 3s 415us/sample - loss: 0.0275 - accuracy: 0.9901 - val_loss: 0.1732 - val_accuracy: 0.9674\n",
      "Epoch 187/700\n",
      "7352/7352 [==============================] - 3s 466us/sample - loss: 0.0369 - accuracy: 0.9865 - val_loss: 0.1880 - val_accuracy: 0.9634\n",
      "Epoch 188/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0306 - accuracy: 0.9880 - val_loss: 0.1658 - val_accuracy: 0.9610\n",
      "Epoch 189/700\n",
      "7352/7352 [==============================] - 3s 422us/sample - loss: 0.0493 - accuracy: 0.9796 - val_loss: 0.2075 - val_accuracy: 0.9535: 0.97\n",
      "Epoch 190/700\n",
      "7352/7352 [==============================] - 3s 453us/sample - loss: 0.0372 - accuracy: 0.9856 - val_loss: 0.1292 - val_accuracy: 0.9688\n",
      "Epoch 191/700\n",
      "7352/7352 [==============================] - 3s 467us/sample - loss: 0.0327 - accuracy: 0.9856 - val_loss: 0.1487 - val_accuracy: 0.9705\n",
      "Epoch 192/700\n",
      "7352/7352 [==============================] - 3s 419us/sample - loss: 0.0321 - accuracy: 0.9879 - val_loss: 0.1803 - val_accuracy: 0.9705\n",
      "Epoch 193/700\n",
      "7352/7352 [==============================] - 3s 402us/sample - loss: 0.0333 - accuracy: 0.9875 - val_loss: 0.1608 - val_accuracy: 0.9712\n",
      "Epoch 194/700\n",
      "7352/7352 [==============================] - 3s 449us/sample - loss: 0.0361 - accuracy: 0.9861 - val_loss: 0.1595 - val_accuracy: 0.9681\n",
      "Epoch 195/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0307 - accuracy: 0.9876 - val_loss: 0.2077 - val_accuracy: 0.9644\n",
      "Epoch 196/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0291 - accuracy: 0.9879 - val_loss: 0.1885 - val_accuracy: 0.9589\n",
      "Epoch 197/700\n",
      "7352/7352 [==============================] - 3s 448us/sample - loss: 0.0297 - accuracy: 0.9888 - val_loss: 0.1876 - val_accuracy: 0.9647\n",
      "Epoch 198/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0342 - accuracy: 0.9867 - val_loss: 0.1937 - val_accuracy: 0.9674\n",
      "Epoch 199/700\n",
      "7352/7352 [==============================] - 3s 442us/sample - loss: 0.0379 - accuracy: 0.9861 - val_loss: 0.2140 - val_accuracy: 0.9596\n",
      "Epoch 200/700\n",
      "7352/7352 [==============================] - 3s 460us/sample - loss: 0.0361 - accuracy: 0.9869 - val_loss: 0.2569 - val_accuracy: 0.9477\n",
      "Epoch 201/700\n",
      "7352/7352 [==============================] - 3s 427us/sample - loss: 0.0264 - accuracy: 0.9893 - val_loss: 0.1554 - val_accuracy: 0.9671\n",
      "Epoch 202/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.0336 - accuracy: 0.9867 - val_loss: 0.1566 - val_accuracy: 0.9650\n",
      "Epoch 203/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0331 - accuracy: 0.9871 - val_loss: 0.1344 - val_accuracy: 0.9634\n",
      "Epoch 204/700\n",
      "7352/7352 [==============================] - 3s 470us/sample - loss: 0.0600 - accuracy: 0.9766 - val_loss: 0.2475 - val_accuracy: 0.9352\n",
      "Epoch 205/700\n",
      "7352/7352 [==============================] - 3s 467us/sample - loss: 0.0308 - accuracy: 0.9887 - val_loss: 0.2253 - val_accuracy: 0.9532\n",
      "Epoch 206/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0308 - accuracy: 0.9872 - val_loss: 0.1517 - val_accuracy: 0.9678\n",
      "Epoch 207/700\n",
      "7352/7352 [==============================] - 4s 479us/sample - loss: 0.0329 - accuracy: 0.9876 - val_loss: 0.1204 - val_accuracy: 0.9681\n",
      "Epoch 208/700\n",
      "7352/7352 [==============================] - 4s 520us/sample - loss: 0.0366 - accuracy: 0.9853 - val_loss: 0.1345 - val_accuracy: 0.9671\n",
      "Epoch 209/700\n",
      "7352/7352 [==============================] - 4s 508us/sample - loss: 0.0334 - accuracy: 0.9859 - val_loss: 0.1927 - val_accuracy: 0.9532\n",
      "Epoch 210/700\n",
      "7352/7352 [==============================] - 3s 464us/sample - loss: 0.0287 - accuracy: 0.9884 - val_loss: 0.1724 - val_accuracy: 0.9600\n",
      "Epoch 211/700\n",
      "7352/7352 [==============================] - 3s 468us/sample - loss: 0.0472 - accuracy: 0.9833 - val_loss: 0.2132 - val_accuracy: 0.9562\n",
      "Epoch 212/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0373 - accuracy: 0.9848 - val_loss: 0.1458 - val_accuracy: 0.9613\n",
      "Epoch 213/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0332 - accuracy: 0.9863 - val_loss: 0.1780 - val_accuracy: 0.9630\n",
      "Epoch 214/700\n",
      "7352/7352 [==============================] - 3s 443us/sample - loss: 0.0422 - accuracy: 0.9837 - val_loss: 0.1907 - val_accuracy: 0.9562\n",
      "Epoch 215/700\n",
      "7352/7352 [==============================] - 3s 474us/sample - loss: 0.0306 - accuracy: 0.9879 - val_loss: 0.1533 - val_accuracy: 0.9630\n",
      "Epoch 216/700\n",
      "7352/7352 [==============================] - 3s 452us/sample - loss: 0.0280 - accuracy: 0.9902 - val_loss: 0.2117 - val_accuracy: 0.9583\n",
      "Epoch 217/700\n",
      "7352/7352 [==============================] - 3s 464us/sample - loss: 0.0298 - accuracy: 0.9887 - val_loss: 0.1650 - val_accuracy: 0.9667\n",
      "Epoch 218/700\n",
      "7352/7352 [==============================] - 4s 491us/sample - loss: 0.0284 - accuracy: 0.9890 - val_loss: 0.2058 - val_accuracy: 0.9623\n",
      "Epoch 219/700\n",
      "7352/7352 [==============================] - 3s 471us/sample - loss: 0.0325 - accuracy: 0.9864 - val_loss: 0.1773 - val_accuracy: 0.9627\n",
      "Epoch 220/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0273 - accuracy: 0.9891 - val_loss: 0.1701 - val_accuracy: 0.9674\n",
      "Epoch 221/700\n",
      "7352/7352 [==============================] - 3s 450us/sample - loss: 0.0294 - accuracy: 0.9879 - val_loss: 0.1746 - val_accuracy: 0.9637\n",
      "Epoch 222/700\n",
      "7352/7352 [==============================] - 3s 437us/sample - loss: 0.0273 - accuracy: 0.9891 - val_loss: 0.1812 - val_accuracy: 0.9698\n",
      "Epoch 223/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0255 - accuracy: 0.9897 - val_loss: 0.2096 - val_accuracy: 0.9572\n",
      "Epoch 224/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0251 - accuracy: 0.9899 - val_loss: 0.2245 - val_accuracy: 0.9569\n",
      "Epoch 225/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0246 - accuracy: 0.9905 - val_loss: 0.1806 - val_accuracy: 0.9637\n",
      "Epoch 226/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0245 - accuracy: 0.9905 - val_loss: 0.2112 - val_accuracy: 0.9535\n",
      "Epoch 227/700\n",
      "7352/7352 [==============================] - 3s 470us/sample - loss: 0.0235 - accuracy: 0.9908 - val_loss: 0.1917 - val_accuracy: 0.9674\n",
      "Epoch 228/700\n",
      "7352/7352 [==============================] - 3s 463us/sample - loss: 0.0273 - accuracy: 0.9918 - val_loss: 0.1486 - val_accuracy: 0.9671\n",
      "Epoch 229/700\n",
      "7352/7352 [==============================] - 3s 462us/sample - loss: 0.0229 - accuracy: 0.9909 - val_loss: 0.2285 - val_accuracy: 0.9610\n",
      "Epoch 230/700\n",
      "7352/7352 [==============================] - 4s 476us/sample - loss: 0.0294 - accuracy: 0.9880 - val_loss: 0.2135 - val_accuracy: 0.9596\n",
      "Epoch 231/700\n",
      "7352/7352 [==============================] - 4s 496us/sample - loss: 0.0255 - accuracy: 0.9914 - val_loss: 0.1631 - val_accuracy: 0.9654\n",
      "Epoch 232/700\n",
      "7352/7352 [==============================] - 3s 432us/sample - loss: 0.0283 - accuracy: 0.9903 - val_loss: 0.1456 - val_accuracy: 0.9657\n",
      "Epoch 233/700\n",
      "7352/7352 [==============================] - 3s 471us/sample - loss: 0.0273 - accuracy: 0.9898 - val_loss: 0.1396 - val_accuracy: 0.9678\n",
      "Epoch 234/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0438 - accuracy: 0.9818 - val_loss: 0.1792 - val_accuracy: 0.9444\n",
      "Epoch 235/700\n",
      "7352/7352 [==============================] - 3s 448us/sample - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.1836 - val_accuracy: 0.9488\n",
      "Epoch 236/700\n",
      "7352/7352 [==============================] - 3s 454us/sample - loss: 0.0273 - accuracy: 0.9888 - val_loss: 0.1375 - val_accuracy: 0.9664\n",
      "Epoch 237/700\n",
      "7352/7352 [==============================] - 3s 452us/sample - loss: 0.0275 - accuracy: 0.9887 - val_loss: 0.1781 - val_accuracy: 0.9589\n",
      "Epoch 238/700\n",
      "7352/7352 [==============================] - 4s 487us/sample - loss: 0.0311 - accuracy: 0.9876 - val_loss: 0.1362 - val_accuracy: 0.9630\n",
      "Epoch 239/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0251 - accuracy: 0.9901 - val_loss: 0.1528 - val_accuracy: 0.9654\n",
      "Epoch 240/700\n",
      "7352/7352 [==============================] - 3s 418us/sample - loss: 0.0263 - accuracy: 0.9897 - val_loss: 0.1152 - val_accuracy: 0.9678\n",
      "Epoch 241/700\n",
      "7352/7352 [==============================] - 3s 465us/sample - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.1453 - val_accuracy: 0.9654\n",
      "Epoch 242/700\n",
      "7352/7352 [==============================] - 3s 449us/sample - loss: 0.0323 - accuracy: 0.9875 - val_loss: 0.2050 - val_accuracy: 0.9555\n",
      "Epoch 243/700\n",
      "7352/7352 [==============================] - 3s 466us/sample - loss: 0.0243 - accuracy: 0.9906 - val_loss: 0.1606 - val_accuracy: 0.9637\n",
      "Epoch 244/700\n",
      "7352/7352 [==============================] - 3s 475us/sample - loss: 0.0351 - accuracy: 0.9860 - val_loss: 0.1323 - val_accuracy: 0.9664\n",
      "Epoch 245/700\n",
      "7352/7352 [==============================] - 3s 446us/sample - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.1218 - val_accuracy: 0.9678\n",
      "Epoch 246/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0304 - accuracy: 0.9884 - val_loss: 0.0904 - val_accuracy: 0.9708\n",
      "Epoch 247/700\n",
      "7352/7352 [==============================] - 3s 430us/sample - loss: 0.0251 - accuracy: 0.9917 - val_loss: 0.1026 - val_accuracy: 0.9708\n",
      "Epoch 248/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.0263 - accuracy: 0.9891 - val_loss: 0.1647 - val_accuracy: 0.9576\n",
      "Epoch 249/700\n",
      "7352/7352 [==============================] - 3s 450us/sample - loss: 0.0233 - accuracy: 0.9909 - val_loss: 0.1257 - val_accuracy: 0.9688\n",
      "Epoch 250/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0256 - accuracy: 0.9905 - val_loss: 0.1342 - val_accuracy: 0.9691\n",
      "Epoch 251/700\n",
      "7352/7352 [==============================] - 3s 425us/sample - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.1551 - val_accuracy: 0.9718\n",
      "Epoch 252/700\n",
      "7352/7352 [==============================] - 3s 469us/sample - loss: 0.0220 - accuracy: 0.9914 - val_loss: 0.2031 - val_accuracy: 0.9559\n",
      "Epoch 253/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0210 - accuracy: 0.9916 - val_loss: 0.1767 - val_accuracy: 0.9640\n",
      "Epoch 254/700\n",
      "7352/7352 [==============================] - 3s 417us/sample - loss: 0.0222 - accuracy: 0.9912 - val_loss: 0.2009 - val_accuracy: 0.9650\n",
      "Epoch 255/700\n",
      "7352/7352 [==============================] - 3s 466us/sample - loss: 0.0227 - accuracy: 0.9914 - val_loss: 0.1471 - val_accuracy: 0.9661\n",
      "Epoch 256/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0207 - accuracy: 0.9916 - val_loss: 0.1599 - val_accuracy: 0.9667\n",
      "Epoch 257/700\n",
      "7352/7352 [==============================] - 3s 463us/sample - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.1431 - val_accuracy: 0.9644\n",
      "Epoch 258/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0270 - accuracy: 0.9898 - val_loss: 0.1228 - val_accuracy: 0.9735\n",
      "Epoch 259/700\n",
      "7352/7352 [==============================] - 3s 446us/sample - loss: 0.0253 - accuracy: 0.9901 - val_loss: 0.1526 - val_accuracy: 0.9681\n",
      "Epoch 260/700\n",
      "7352/7352 [==============================] - 3s 456us/sample - loss: 0.0254 - accuracy: 0.9906 - val_loss: 0.1848 - val_accuracy: 0.9600\n",
      "Epoch 261/700\n",
      "7352/7352 [==============================] - 3s 471us/sample - loss: 0.0210 - accuracy: 0.9920 - val_loss: 0.1302 - val_accuracy: 0.9701\n",
      "Epoch 262/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0229 - accuracy: 0.9908 - val_loss: 0.1827 - val_accuracy: 0.9576\n",
      "Epoch 263/700\n",
      "7352/7352 [==============================] - 3s 457us/sample - loss: 0.0223 - accuracy: 0.9912 - val_loss: 0.1960 - val_accuracy: 0.9600\n",
      "Epoch 264/700\n",
      "7352/7352 [==============================] - 3s 446us/sample - loss: 0.0259 - accuracy: 0.9897 - val_loss: 0.1477 - val_accuracy: 0.9688\n",
      "Epoch 265/700\n",
      "7352/7352 [==============================] - 3s 424us/sample - loss: 0.0266 - accuracy: 0.9899 - val_loss: 0.1437 - val_accuracy: 0.9644\n",
      "Epoch 266/700\n",
      "7352/7352 [==============================] - 3s 472us/sample - loss: 0.0234 - accuracy: 0.9908 - val_loss: 0.0918 - val_accuracy: 0.9796\n",
      "Epoch 267/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.1037 - val_accuracy: 0.9746\n",
      "Epoch 268/700\n",
      "7352/7352 [==============================] - 3s 422us/sample - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.1553 - val_accuracy: 0.9627\n",
      "Epoch 269/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0247 - accuracy: 0.9905 - val_loss: 0.1153 - val_accuracy: 0.9681s: 0.0248 - accuracy\n",
      "Epoch 270/700\n",
      "7352/7352 [==============================] - 3s 463us/sample - loss: 0.0256 - accuracy: 0.9898 - val_loss: 0.1654 - val_accuracy: 0.9647\n",
      "Epoch 271/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.1463 - val_accuracy: 0.9657\n",
      "Epoch 272/700\n",
      "7352/7352 [==============================] - 3s 463us/sample - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.2052 - val_accuracy: 0.9620\n",
      "Epoch 273/700\n",
      "7352/7352 [==============================] - 3s 420us/sample - loss: 0.0338 - accuracy: 0.9882 - val_loss: 0.1103 - val_accuracy: 0.9688\n",
      "Epoch 274/700\n",
      "7352/7352 [==============================] - 3s 437us/sample - loss: 0.0317 - accuracy: 0.9871 - val_loss: 0.1038 - val_accuracy: 0.9695\n",
      "Epoch 275/700\n",
      "7352/7352 [==============================] - 4s 497us/sample - loss: 0.0244 - accuracy: 0.9895 - val_loss: 0.1361 - val_accuracy: 0.9637\n",
      "Epoch 276/700\n",
      "7352/7352 [==============================] - 3s 404us/sample - loss: 0.0215 - accuracy: 0.9918 - val_loss: 0.1143 - val_accuracy: 0.9712\n",
      "Epoch 277/700\n",
      "7352/7352 [==============================] - 4s 478us/sample - loss: 0.0262 - accuracy: 0.9894 - val_loss: 0.1045 - val_accuracy: 0.9691\n",
      "Epoch 278/700\n",
      "7352/7352 [==============================] - 3s 450us/sample - loss: 0.0205 - accuracy: 0.9928 - val_loss: 0.1515 - val_accuracy: 0.9623\n",
      "Epoch 279/700\n",
      "7352/7352 [==============================] - 3s 410us/sample - loss: 0.0215 - accuracy: 0.9922 - val_loss: 0.1370 - val_accuracy: 0.9657\n",
      "Epoch 280/700\n",
      "7352/7352 [==============================] - 3s 432us/sample - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.1409 - val_accuracy: 0.9647\n",
      "Epoch 281/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0235 - accuracy: 0.9910 - val_loss: 0.1866 - val_accuracy: 0.9596\n",
      "Epoch 282/700\n",
      "7352/7352 [==============================] - 4s 501us/sample - loss: 0.0282 - accuracy: 0.9897 - val_loss: 0.1347 - val_accuracy: 0.9698\n",
      "Epoch 283/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.1195 - val_accuracy: 0.9623\n",
      "Epoch 284/700\n",
      "7352/7352 [==============================] - 3s 401us/sample - loss: 0.0217 - accuracy: 0.9917 - val_loss: 0.1451 - val_accuracy: 0.9644\n",
      "Epoch 285/700\n",
      "7352/7352 [==============================] - 3s 476us/sample - loss: 0.0213 - accuracy: 0.9922 - val_loss: 0.1282 - val_accuracy: 0.9684\n",
      "Epoch 286/700\n",
      "7352/7352 [==============================] - 3s 419us/sample - loss: 0.0270 - accuracy: 0.9901 - val_loss: 0.1497 - val_accuracy: 0.9684\n",
      "Epoch 287/700\n",
      "7352/7352 [==============================] - 3s 432us/sample - loss: 0.0238 - accuracy: 0.9908 - val_loss: 0.1105 - val_accuracy: 0.9691\n",
      "Epoch 288/700\n",
      "7352/7352 [==============================] - 3s 463us/sample - loss: 0.0215 - accuracy: 0.9909 - val_loss: 0.1444 - val_accuracy: 0.9661\n",
      "Epoch 289/700\n",
      "7352/7352 [==============================] - 3s 421us/sample - loss: 0.0208 - accuracy: 0.9913 - val_loss: 0.1243 - val_accuracy: 0.9644\n",
      "Epoch 290/700\n",
      "7352/7352 [==============================] - 3s 428us/sample - loss: 0.0182 - accuracy: 0.9931 - val_loss: 0.1068 - val_accuracy: 0.9701\n",
      "Epoch 291/700\n",
      "7352/7352 [==============================] - 3s 442us/sample - loss: 0.0202 - accuracy: 0.9929 - val_loss: 0.1124 - val_accuracy: 0.9688\n",
      "Epoch 292/700\n",
      "7352/7352 [==============================] - 3s 442us/sample - loss: 0.0245 - accuracy: 0.9910 - val_loss: 0.1343 - val_accuracy: 0.9681\n",
      "Epoch 293/700\n",
      "7352/7352 [==============================] - 3s 428us/sample - loss: 0.0214 - accuracy: 0.9917 - val_loss: 0.1494 - val_accuracy: 0.9715\n",
      "Epoch 294/700\n",
      "7352/7352 [==============================] - 4s 477us/sample - loss: 0.0184 - accuracy: 0.9929 - val_loss: 0.1532 - val_accuracy: 0.9688\n",
      "Epoch 295/700\n",
      "7352/7352 [==============================] - 3s 423us/sample - loss: 0.0191 - accuracy: 0.9922 - val_loss: 0.1380 - val_accuracy: 0.9708\n",
      "Epoch 296/700\n",
      "7352/7352 [==============================] - 3s 400us/sample - loss: 0.0248 - accuracy: 0.9906 - val_loss: 0.2210 - val_accuracy: 0.9488\n",
      "Epoch 297/700\n",
      "7352/7352 [==============================] - 3s 468us/sample - loss: 0.0239 - accuracy: 0.9913 - val_loss: 0.1575 - val_accuracy: 0.9664\n",
      "Epoch 298/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.1087 - val_accuracy: 0.9715\n",
      "Epoch 299/700\n",
      "7352/7352 [==============================] - 3s 467us/sample - loss: 0.0201 - accuracy: 0.9918 - val_loss: 0.1770 - val_accuracy: 0.9691\n",
      "Epoch 300/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.1190 - val_accuracy: 0.9688\n",
      "Epoch 301/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0194 - accuracy: 0.9935 - val_loss: 0.1690 - val_accuracy: 0.9640\n",
      "Epoch 302/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0207 - accuracy: 0.9924 - val_loss: 0.1372 - val_accuracy: 0.9640\n",
      "Epoch 303/700\n",
      "7352/7352 [==============================] - 3s 425us/sample - loss: 0.0240 - accuracy: 0.9909 - val_loss: 0.1516 - val_accuracy: 0.9603\n",
      "Epoch 304/700\n",
      "7352/7352 [==============================] - 3s 430us/sample - loss: 0.0174 - accuracy: 0.9931 - val_loss: 0.2076 - val_accuracy: 0.9620\n",
      "Epoch 305/700\n",
      "7352/7352 [==============================] - 3s 400us/sample - loss: 0.0201 - accuracy: 0.9928 - val_loss: 0.1403 - val_accuracy: 0.9644\n",
      "Epoch 306/700\n",
      "7352/7352 [==============================] - 3s 422us/sample - loss: 0.0200 - accuracy: 0.9914 - val_loss: 0.1514 - val_accuracy: 0.9678\n",
      "Epoch 307/700\n",
      "7352/7352 [==============================] - 3s 464us/sample - loss: 0.0192 - accuracy: 0.9922 - val_loss: 0.1208 - val_accuracy: 0.9688\n",
      "Epoch 308/700\n",
      "7352/7352 [==============================] - 3s 472us/sample - loss: 0.0181 - accuracy: 0.9932 - val_loss: 0.1830 - val_accuracy: 0.9640\n",
      "Epoch 309/700\n",
      "7352/7352 [==============================] - 3s 427us/sample - loss: 0.0344 - accuracy: 0.9861 - val_loss: 0.1893 - val_accuracy: 0.9532\n",
      "Epoch 310/700\n",
      "7352/7352 [==============================] - 3s 417us/sample - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.1739 - val_accuracy: 0.9667\n",
      "Epoch 311/700\n",
      "7352/7352 [==============================] - 4s 500us/sample - loss: 0.0180 - accuracy: 0.9925 - val_loss: 0.1570 - val_accuracy: 0.9681\n",
      "Epoch 312/700\n",
      "7352/7352 [==============================] - 3s 412us/sample - loss: 0.0217 - accuracy: 0.9917 - val_loss: 0.1895 - val_accuracy: 0.9657\n",
      "Epoch 313/700\n",
      "7352/7352 [==============================] - 3s 463us/sample - loss: 0.0258 - accuracy: 0.9901 - val_loss: 0.1789 - val_accuracy: 0.9674\n",
      "Epoch 314/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.2378 - val_accuracy: 0.9600\n",
      "Epoch 315/700\n",
      "7352/7352 [==============================] - 3s 399us/sample - loss: 0.0194 - accuracy: 0.9932 - val_loss: 0.1896 - val_accuracy: 0.9650\n",
      "Epoch 316/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.1321 - val_accuracy: 0.9725\n",
      "Epoch 317/700\n",
      "7352/7352 [==============================] - 4s 492us/sample - loss: 0.0289 - accuracy: 0.9882 - val_loss: 0.3412 - val_accuracy: 0.9440\n",
      "Epoch 318/700\n",
      "7352/7352 [==============================] - 3s 448us/sample - loss: 0.0218 - accuracy: 0.9922 - val_loss: 0.2040 - val_accuracy: 0.9654\n",
      "Epoch 319/700\n",
      "7352/7352 [==============================] - 3s 464us/sample - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.1925 - val_accuracy: 0.9613\n",
      "Epoch 320/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.1385 - val_accuracy: 0.9688\n",
      "Epoch 321/700\n",
      "7352/7352 [==============================] - 3s 432us/sample - loss: 0.0242 - accuracy: 0.9899 - val_loss: 0.1721 - val_accuracy: 0.9661\n",
      "Epoch 322/700\n",
      "7352/7352 [==============================] - 3s 451us/sample - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.1461 - val_accuracy: 0.9654\n",
      "Epoch 323/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.1570 - val_accuracy: 0.9691\n",
      "Epoch 324/700\n",
      "7352/7352 [==============================] - 3s 458us/sample - loss: 0.0225 - accuracy: 0.9909 - val_loss: 0.1337 - val_accuracy: 0.9712\n",
      "Epoch 325/700\n",
      "7352/7352 [==============================] - 3s 456us/sample - loss: 0.0190 - accuracy: 0.9929 - val_loss: 0.1660 - val_accuracy: 0.9583\n",
      "Epoch 326/700\n",
      "7352/7352 [==============================] - 3s 403us/sample - loss: 0.0207 - accuracy: 0.9917 - val_loss: 0.1264 - val_accuracy: 0.9671\n",
      "Epoch 327/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.0176 - accuracy: 0.9939 - val_loss: 0.1149 - val_accuracy: 0.9729\n",
      "Epoch 328/700\n",
      "7352/7352 [==============================] - 4s 480us/sample - loss: 0.0197 - accuracy: 0.9929 - val_loss: 0.1561 - val_accuracy: 0.9688\n",
      "Epoch 329/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0209 - accuracy: 0.9916 - val_loss: 0.1257 - val_accuracy: 0.9701\n",
      "Epoch 330/700\n",
      "7352/7352 [==============================] - 3s 469us/sample - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.1581 - val_accuracy: 0.9684\n",
      "Epoch 331/700\n",
      "7352/7352 [==============================] - 3s 454us/sample - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.1364 - val_accuracy: 0.9664\n",
      "Epoch 332/700\n",
      "7352/7352 [==============================] - 4s 489us/sample - loss: 0.0178 - accuracy: 0.9931 - val_loss: 0.1574 - val_accuracy: 0.9654\n",
      "Epoch 333/700\n",
      "7352/7352 [==============================] - 3s 461us/sample - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.0893 - val_accuracy: 0.9759\n",
      "Epoch 334/700\n",
      "7352/7352 [==============================] - 3s 425us/sample - loss: 0.0202 - accuracy: 0.9918 - val_loss: 0.1441 - val_accuracy: 0.9712\n",
      "Epoch 335/700\n",
      "7352/7352 [==============================] - 3s 450us/sample - loss: 0.0240 - accuracy: 0.9905 - val_loss: 0.1196 - val_accuracy: 0.9671\n",
      "Epoch 336/700\n",
      "7352/7352 [==============================] - 3s 449us/sample - loss: 0.0188 - accuracy: 0.9929 - val_loss: 0.1446 - val_accuracy: 0.9620\n",
      "Epoch 337/700\n",
      "7352/7352 [==============================] - 3s 437us/sample - loss: 0.0229 - accuracy: 0.9905 - val_loss: 0.1234 - val_accuracy: 0.9681\n",
      "Epoch 338/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0203 - accuracy: 0.9921 - val_loss: 0.0919 - val_accuracy: 0.9756\n",
      "Epoch 339/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0199 - accuracy: 0.9922 - val_loss: 0.1161 - val_accuracy: 0.9695\n",
      "Epoch 340/700\n",
      "7352/7352 [==============================] - 3s 475us/sample - loss: 0.0176 - accuracy: 0.9932 - val_loss: 0.1458 - val_accuracy: 0.9684\n",
      "Epoch 341/700\n",
      "7352/7352 [==============================] - 3s 469us/sample - loss: 0.0183 - accuracy: 0.9925 - val_loss: 0.1107 - val_accuracy: 0.9698\n",
      "Epoch 342/700\n",
      "7352/7352 [==============================] - 3s 428us/sample - loss: 0.0180 - accuracy: 0.9931 - val_loss: 0.0986 - val_accuracy: 0.9725\n",
      "Epoch 343/700\n",
      "7352/7352 [==============================] - 3s 407us/sample - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.1363 - val_accuracy: 0.9674\n",
      "Epoch 344/700\n",
      "7352/7352 [==============================] - 4s 500us/sample - loss: 0.0182 - accuracy: 0.9932 - val_loss: 0.1686 - val_accuracy: 0.9664\n",
      "Epoch 345/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.1201 - val_accuracy: 0.9705\n",
      "Epoch 346/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0170 - accuracy: 0.9935 - val_loss: 0.1460 - val_accuracy: 0.9644\n",
      "Epoch 347/700\n",
      "7352/7352 [==============================] - 3s 432us/sample - loss: 0.0162 - accuracy: 0.9943 - val_loss: 0.1418 - val_accuracy: 0.9674\n",
      "Epoch 348/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0225 - accuracy: 0.9917 - val_loss: 0.1638 - val_accuracy: 0.9630\n",
      "Epoch 349/700\n",
      "7352/7352 [==============================] - 3s 419us/sample - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.1800 - val_accuracy: 0.9603\n",
      "Epoch 350/700\n",
      "7352/7352 [==============================] - 4s 484us/sample - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.1738 - val_accuracy: 0.9647\n",
      "Epoch 351/700\n",
      "7352/7352 [==============================] - 3s 470us/sample - loss: 0.0220 - accuracy: 0.9917 - val_loss: 0.1210 - val_accuracy: 0.9671\n",
      "Epoch 352/700\n",
      "7352/7352 [==============================] - 3s 450us/sample - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.1436 - val_accuracy: 0.9674\n",
      "Epoch 353/700\n",
      "7352/7352 [==============================] - 3s 420us/sample - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.1418 - val_accuracy: 0.9630\n",
      "Epoch 354/700\n",
      "7352/7352 [==============================] - 3s 423us/sample - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.1789 - val_accuracy: 0.9600\n",
      "Epoch 355/700\n",
      "7352/7352 [==============================] - 3s 454us/sample - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.1000 - val_accuracy: 0.9712\n",
      "Epoch 356/700\n",
      "7352/7352 [==============================] - 3s 420us/sample - loss: 0.0187 - accuracy: 0.9928 - val_loss: 0.0972 - val_accuracy: 0.9708\n",
      "Epoch 357/700\n",
      "7352/7352 [==============================] - 3s 401us/sample - loss: 0.0158 - accuracy: 0.9940 - val_loss: 0.1406 - val_accuracy: 0.9657\n",
      "Epoch 358/700\n",
      "7352/7352 [==============================] - 3s 429us/sample - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.0915 - val_accuracy: 0.9725\n",
      "Epoch 359/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0148 - accuracy: 0.9959 - val_loss: 0.2050 - val_accuracy: 0.9630\n",
      "Epoch 360/700\n",
      "7352/7352 [==============================] - 3s 423us/sample - loss: 0.0233 - accuracy: 0.9910 - val_loss: 0.1605 - val_accuracy: 0.9674\n",
      "Epoch 361/700\n",
      "7352/7352 [==============================] - 3s 443us/sample - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.1800 - val_accuracy: 0.9596\n",
      "Epoch 362/700\n",
      "7352/7352 [==============================] - 4s 505us/sample - loss: 0.0298 - accuracy: 0.9888 - val_loss: 0.1683 - val_accuracy: 0.9589\n",
      "Epoch 363/700\n",
      "7352/7352 [==============================] - 3s 424us/sample - loss: 0.0198 - accuracy: 0.9927 - val_loss: 0.1777 - val_accuracy: 0.9623\n",
      "Epoch 364/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0203 - accuracy: 0.9922 - val_loss: 0.1537 - val_accuracy: 0.9661\n",
      "Epoch 365/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0204 - accuracy: 0.9924 - val_loss: 0.2179 - val_accuracy: 0.9555\n",
      "Epoch 366/700\n",
      "7352/7352 [==============================] - 3s 456us/sample - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.1465 - val_accuracy: 0.9691\n",
      "Epoch 367/700\n",
      "7352/7352 [==============================] - 3s 441us/sample - loss: 0.0167 - accuracy: 0.9931 - val_loss: 0.1906 - val_accuracy: 0.9603\n",
      "Epoch 368/700\n",
      "7352/7352 [==============================] - 3s 461us/sample - loss: 0.0178 - accuracy: 0.9927 - val_loss: 0.1519 - val_accuracy: 0.9674\n",
      "Epoch 369/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0195 - accuracy: 0.9931 - val_loss: 0.1474 - val_accuracy: 0.9650\n",
      "Epoch 370/700\n",
      "7352/7352 [==============================] - 3s 459us/sample - loss: 0.0140 - accuracy: 0.9946 - val_loss: 0.1045 - val_accuracy: 0.9712\n",
      "Epoch 371/700\n",
      "7352/7352 [==============================] - 3s 454us/sample - loss: 0.0186 - accuracy: 0.9920 - val_loss: 0.0961 - val_accuracy: 0.9776\n",
      "Epoch 372/700\n",
      "7352/7352 [==============================] - 3s 471us/sample - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.1399 - val_accuracy: 0.9735\n",
      "Epoch 373/700\n",
      "7352/7352 [==============================] - 4s 549us/sample - loss: 0.0275 - accuracy: 0.9891 - val_loss: 0.1532 - val_accuracy: 0.9667\n",
      "Epoch 374/700\n",
      "7352/7352 [==============================] - 4s 542us/sample - loss: 0.0184 - accuracy: 0.9933 - val_loss: 0.1444 - val_accuracy: 0.9705\n",
      "Epoch 375/700\n",
      "7352/7352 [==============================] - 3s 379us/sample - loss: 0.0196 - accuracy: 0.9924 - val_loss: 0.0978 - val_accuracy: 0.9712\n",
      "Epoch 376/700\n",
      "7352/7352 [==============================] - 3s 421us/sample - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.1350 - val_accuracy: 0.9681\n",
      "Epoch 377/700\n",
      "7352/7352 [==============================] - 3s 416us/sample - loss: 0.0215 - accuracy: 0.9913 - val_loss: 0.1095 - val_accuracy: 0.9762\n",
      "Epoch 378/700\n",
      "7352/7352 [==============================] - 3s 391us/sample - loss: 0.0238 - accuracy: 0.9913 - val_loss: 0.1109 - val_accuracy: 0.9712\n",
      "Epoch 379/700\n",
      "7352/7352 [==============================] - 3s 389us/sample - loss: 0.0319 - accuracy: 0.9867 - val_loss: 0.1282 - val_accuracy: 0.9732\n",
      "Epoch 380/700\n",
      "7352/7352 [==============================] - 4s 515us/sample - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.1005 - val_accuracy: 0.9752\n",
      "Epoch 381/700\n",
      "7352/7352 [==============================] - 4s 487us/sample - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.1192 - val_accuracy: 0.9708\n",
      "Epoch 382/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0174 - accuracy: 0.9933 - val_loss: 0.1351 - val_accuracy: 0.9701\n",
      "Epoch 383/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.0175 - accuracy: 0.9931 - val_loss: 0.1056 - val_accuracy: 0.9722\n",
      "Epoch 384/700\n",
      "7352/7352 [==============================] - 3s 405us/sample - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.1158 - val_accuracy: 0.9718\n",
      "Epoch 385/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.1019 - val_accuracy: 0.9732\n",
      "Epoch 386/700\n",
      "7352/7352 [==============================] - 3s 388us/sample - loss: 0.0177 - accuracy: 0.9933 - val_loss: 0.0818 - val_accuracy: 0.9735\n",
      "Epoch 387/700\n",
      "7352/7352 [==============================] - 3s 409us/sample - loss: 0.0154 - accuracy: 0.9940 - val_loss: 0.1182 - val_accuracy: 0.9735\n",
      "Epoch 388/700\n",
      "7352/7352 [==============================] - 3s 378us/sample - loss: 0.0139 - accuracy: 0.9940 - val_loss: 0.0865 - val_accuracy: 0.9779\n",
      "Epoch 389/700\n",
      "7352/7352 [==============================] - 3s 405us/sample - loss: 0.0160 - accuracy: 0.9936 - val_loss: 0.1195 - val_accuracy: 0.9735\n",
      "Epoch 390/700\n",
      "7352/7352 [==============================] - 3s 385us/sample - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.1395 - val_accuracy: 0.9722\n",
      "Epoch 391/700\n",
      "7352/7352 [==============================] - 3s 378us/sample - loss: 0.0138 - accuracy: 0.9946 - val_loss: 0.1210 - val_accuracy: 0.9752\n",
      "Epoch 392/700\n",
      "7352/7352 [==============================] - 3s 380us/sample - loss: 0.0174 - accuracy: 0.9925 - val_loss: 0.0787 - val_accuracy: 0.9762\n",
      "Epoch 393/700\n",
      "7352/7352 [==============================] - 4s 528us/sample - loss: 0.0181 - accuracy: 0.9935 - val_loss: 0.0682 - val_accuracy: 0.9790\n",
      "Epoch 394/700\n",
      "7352/7352 [==============================] - 5s 664us/sample - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.0955 - val_accuracy: 0.9701\n",
      "Epoch 395/700\n",
      "7352/7352 [==============================] - 3s 401us/sample - loss: 0.0183 - accuracy: 0.9935 - val_loss: 0.0804 - val_accuracy: 0.9776\n",
      "Epoch 396/700\n",
      "7352/7352 [==============================] - 3s 359us/sample - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.0882 - val_accuracy: 0.9766\n",
      "Epoch 397/700\n",
      "7352/7352 [==============================] - 3s 400us/sample - loss: 0.0163 - accuracy: 0.9939 - val_loss: 0.0881 - val_accuracy: 0.9776\n",
      "Epoch 398/700\n",
      "7352/7352 [==============================] - 3s 393us/sample - loss: 0.0180 - accuracy: 0.9935 - val_loss: 0.0680 - val_accuracy: 0.9830\n",
      "Epoch 399/700\n",
      "7352/7352 [==============================] - 3s 374us/sample - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.0908 - val_accuracy: 0.9779\n",
      "Epoch 400/700\n",
      "7352/7352 [==============================] - 3s 371us/sample - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.0904 - val_accuracy: 0.9749\n",
      "Epoch 401/700\n",
      "7352/7352 [==============================] - 3s 349us/sample - loss: 0.0152 - accuracy: 0.9940 - val_loss: 0.1072 - val_accuracy: 0.9708\n",
      "Epoch 402/700\n",
      "7352/7352 [==============================] - 4s 480us/sample - loss: 0.0251 - accuracy: 0.9905 - val_loss: 0.1105 - val_accuracy: 0.9678\n",
      "Epoch 403/700\n",
      "7352/7352 [==============================] - 3s 403us/sample - loss: 0.0196 - accuracy: 0.9929 - val_loss: 0.1096 - val_accuracy: 0.9688\n",
      "Epoch 404/700\n",
      "7352/7352 [==============================] - 3s 447us/sample - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.1146 - val_accuracy: 0.9657\n",
      "Epoch 405/700\n",
      "7352/7352 [==============================] - 3s 426us/sample - loss: 0.0153 - accuracy: 0.9942 - val_loss: 0.0989 - val_accuracy: 0.9712\n",
      "Epoch 406/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.0155 - accuracy: 0.9943 - val_loss: 0.1053 - val_accuracy: 0.9712\n",
      "Epoch 407/700\n",
      "7352/7352 [==============================] - 4s 498us/sample - loss: 0.0175 - accuracy: 0.9933 - val_loss: 0.0983 - val_accuracy: 0.9756\n",
      "Epoch 408/700\n",
      "7352/7352 [==============================] - 4s 486us/sample - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0760 - val_accuracy: 0.9796\n",
      "Epoch 409/700\n",
      "7352/7352 [==============================] - 3s 416us/sample - loss: 0.0187 - accuracy: 0.9925 - val_loss: 0.0870 - val_accuracy: 0.9749\n",
      "Epoch 410/700\n",
      "7352/7352 [==============================] - 3s 475us/sample - loss: 0.0171 - accuracy: 0.9936 - val_loss: 0.0721 - val_accuracy: 0.9769\n",
      "Epoch 411/700\n",
      "7352/7352 [==============================] - 4s 484us/sample - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.1550 - val_accuracy: 0.9725\n",
      "Epoch 412/700\n",
      "7352/7352 [==============================] - 4s 556us/sample - loss: 0.0162 - accuracy: 0.9940 - val_loss: 0.1385 - val_accuracy: 0.9698\n",
      "Epoch 413/700\n",
      "7352/7352 [==============================] - 4s 490us/sample - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.1169 - val_accuracy: 0.9705\n",
      "Epoch 414/700\n",
      "7352/7352 [==============================] - 3s 461us/sample - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.1491 - val_accuracy: 0.9701\n",
      "Epoch 415/700\n",
      "7352/7352 [==============================] - 3s 468us/sample - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.0958 - val_accuracy: 0.9722\n",
      "Epoch 416/700\n",
      "7352/7352 [==============================] - 5s 716us/sample - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.1155 - val_accuracy: 0.9729\n",
      "Epoch 417/700\n",
      "7352/7352 [==============================] - 6s 751us/sample - loss: 0.0171 - accuracy: 0.9932 - val_loss: 0.1141 - val_accuracy: 0.9695\n",
      "Epoch 418/700\n",
      "7352/7352 [==============================] - 3s 453us/sample - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1064 - val_accuracy: 0.9739\n",
      "Epoch 419/700\n",
      "7352/7352 [==============================] - 3s 370us/sample - loss: 0.0140 - accuracy: 0.9950 - val_loss: 0.0760 - val_accuracy: 0.9803\n",
      "Epoch 420/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0139 - accuracy: 0.9943 - val_loss: 0.0977 - val_accuracy: 0.9759\n",
      "Epoch 421/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0130 - accuracy: 0.9950 - val_loss: 0.1094 - val_accuracy: 0.9722\n",
      "Epoch 422/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.1096 - val_accuracy: 0.9746\n",
      "Epoch 423/700\n",
      "7352/7352 [==============================] - 3s 395us/sample - loss: 0.0135 - accuracy: 0.9948 - val_loss: 0.0768 - val_accuracy: 0.9796\n",
      "Epoch 424/700\n",
      "7352/7352 [==============================] - 3s 405us/sample - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0770 - val_accuracy: 0.9783\n",
      "Epoch 425/700\n",
      "7352/7352 [==============================] - 3s 386us/sample - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.0965 - val_accuracy: 0.9749\n",
      "Epoch 426/700\n",
      "7352/7352 [==============================] - 3s 407us/sample - loss: 0.0138 - accuracy: 0.9944 - val_loss: 0.0999 - val_accuracy: 0.9749\n",
      "Epoch 427/700\n",
      "7352/7352 [==============================] - 3s 369us/sample - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.1173 - val_accuracy: 0.9715\n",
      "Epoch 428/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.0868 - val_accuracy: 0.9729\n",
      "Epoch 429/700\n",
      "7352/7352 [==============================] - 4s 494us/sample - loss: 0.0122 - accuracy: 0.9961 - val_loss: 0.1298 - val_accuracy: 0.9667\n",
      "Epoch 430/700\n",
      "7352/7352 [==============================] - 3s 390us/sample - loss: 0.0205 - accuracy: 0.9927 - val_loss: 0.0953 - val_accuracy: 0.9691\n",
      "Epoch 431/700\n",
      "7352/7352 [==============================] - 3s 374us/sample - loss: 0.0128 - accuracy: 0.9948 - val_loss: 0.0966 - val_accuracy: 0.9705\n",
      "Epoch 432/700\n",
      "7352/7352 [==============================] - 3s 472us/sample - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.1188 - val_accuracy: 0.9671\n",
      "Epoch 433/700\n",
      "7352/7352 [==============================] - 3s 358us/sample - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0732 - val_accuracy: 0.9810\n",
      "Epoch 434/700\n",
      "7352/7352 [==============================] - 3s 413us/sample - loss: 0.0171 - accuracy: 0.9924 - val_loss: 0.0790 - val_accuracy: 0.9773\n",
      "Epoch 435/700\n",
      "7352/7352 [==============================] - 3s 364us/sample - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0696 - val_accuracy: 0.9803\n",
      "Epoch 436/700\n",
      "7352/7352 [==============================] - 3s 384us/sample - loss: 0.0148 - accuracy: 0.9939 - val_loss: 0.0718 - val_accuracy: 0.9790\n",
      "Epoch 437/700\n",
      "7352/7352 [==============================] - 3s 390us/sample - loss: 0.0140 - accuracy: 0.9951 - val_loss: 0.0786 - val_accuracy: 0.9773\n",
      "Epoch 438/700\n",
      "7352/7352 [==============================] - 3s 411us/sample - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0757 - val_accuracy: 0.9769\n",
      "Epoch 439/700\n",
      "7352/7352 [==============================] - 3s 360us/sample - loss: 0.0130 - accuracy: 0.9947 - val_loss: 0.0724 - val_accuracy: 0.9779\n",
      "Epoch 440/700\n",
      "7352/7352 [==============================] - 3s 411us/sample - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0767 - val_accuracy: 0.9796\n",
      "Epoch 441/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.0166 - accuracy: 0.9939 - val_loss: 0.0780 - val_accuracy: 0.9769\n",
      "Epoch 442/700\n",
      "7352/7352 [==============================] - 3s 470us/sample - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.1018 - val_accuracy: 0.9722\n",
      "Epoch 443/700\n",
      "7352/7352 [==============================] - 4s 518us/sample - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.1004 - val_accuracy: 0.9776\n",
      "Epoch 444/700\n",
      "7352/7352 [==============================] - 4s 570us/sample - loss: 0.0153 - accuracy: 0.9937 - val_loss: 0.0854 - val_accuracy: 0.9749\n",
      "Epoch 445/700\n",
      "7352/7352 [==============================] - 3s 434us/sample - loss: 0.0182 - accuracy: 0.9927 - val_loss: 0.0786 - val_accuracy: 0.9762\n",
      "Epoch 446/700\n",
      "7352/7352 [==============================] - 3s 386us/sample - loss: 0.0149 - accuracy: 0.9944 - val_loss: 0.0774 - val_accuracy: 0.9766\n",
      "Epoch 447/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.0915 - val_accuracy: 0.9698\n",
      "Epoch 448/700\n",
      "7352/7352 [==============================] - 3s 475us/sample - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0877 - val_accuracy: 0.9712\n",
      "Epoch 449/700\n",
      "7352/7352 [==============================] - 3s 415us/sample - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0807 - val_accuracy: 0.9779\n",
      "Epoch 450/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0849 - val_accuracy: 0.9766\n",
      "Epoch 451/700\n",
      "7352/7352 [==============================] - 3s 427us/sample - loss: 0.0128 - accuracy: 0.9948 - val_loss: 0.0888 - val_accuracy: 0.9786\n",
      "Epoch 452/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0693 - val_accuracy: 0.9841\n",
      "Epoch 453/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.0635 - val_accuracy: 0.9813\n",
      "Epoch 454/700\n",
      "7352/7352 [==============================] - 3s 379us/sample - loss: 0.0131 - accuracy: 0.9955 - val_loss: 0.1018 - val_accuracy: 0.9729\n",
      "Epoch 455/700\n",
      "7352/7352 [==============================] - 3s 411us/sample - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.0708 - val_accuracy: 0.9810\n",
      "Epoch 456/700\n",
      "7352/7352 [==============================] - 3s 412us/sample - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0857 - val_accuracy: 0.9762\n",
      "Epoch 457/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0176 - accuracy: 0.9933 - val_loss: 0.1689 - val_accuracy: 0.9583\n",
      "Epoch 458/700\n",
      "7352/7352 [==============================] - 3s 465us/sample - loss: 0.0106 - accuracy: 0.9958 - val_loss: 0.1060 - val_accuracy: 0.9746\n",
      "Epoch 459/700\n",
      "7352/7352 [==============================] - 3s 382us/sample - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.1297 - val_accuracy: 0.9688\n",
      "Epoch 460/700\n",
      "7352/7352 [==============================] - 3s 429us/sample - loss: 0.0164 - accuracy: 0.9935 - val_loss: 0.0970 - val_accuracy: 0.9732\n",
      "Epoch 461/700\n",
      "7352/7352 [==============================] - 3s 378us/sample - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.1011 - val_accuracy: 0.9739\n",
      "Epoch 462/700\n",
      "7352/7352 [==============================] - 3s 396us/sample - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.1771 - val_accuracy: 0.9572\n",
      "Epoch 463/700\n",
      "7352/7352 [==============================] - 3s 399us/sample - loss: 0.0126 - accuracy: 0.9956 - val_loss: 0.1002 - val_accuracy: 0.9718\n",
      "Epoch 464/700\n",
      "7352/7352 [==============================] - 3s 418us/sample - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.1274 - val_accuracy: 0.9661\n",
      "Epoch 465/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.0106 - accuracy: 0.9962 - val_loss: 0.0869 - val_accuracy: 0.9776\n",
      "Epoch 466/700\n",
      "7352/7352 [==============================] - 3s 406us/sample - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.0797 - val_accuracy: 0.9769\n",
      "Epoch 467/700\n",
      "7352/7352 [==============================] - 3s 417us/sample - loss: 0.0120 - accuracy: 0.9952 - val_loss: 0.0925 - val_accuracy: 0.9739\n",
      "Epoch 468/700\n",
      "7352/7352 [==============================] - 3s 378us/sample - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0985 - val_accuracy: 0.9712\n",
      "Epoch 469/700\n",
      "7352/7352 [==============================] - 3s 414us/sample - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.0833 - val_accuracy: 0.9773\n",
      "Epoch 470/700\n",
      "7352/7352 [==============================] - 3s 457us/sample - loss: 0.0115 - accuracy: 0.9946 - val_loss: 0.1042 - val_accuracy: 0.9701\n",
      "Epoch 471/700\n",
      "7352/7352 [==============================] - 3s 400us/sample - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.0893 - val_accuracy: 0.9739\n",
      "Epoch 472/700\n",
      "7352/7352 [==============================] - 3s 408us/sample - loss: 0.0135 - accuracy: 0.9948 - val_loss: 0.0737 - val_accuracy: 0.9803\n",
      "Epoch 473/700\n",
      "7352/7352 [==============================] - 3s 408us/sample - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.0757 - val_accuracy: 0.9776\n",
      "Epoch 474/700\n",
      "7352/7352 [==============================] - 4s 482us/sample - loss: 0.0127 - accuracy: 0.9959 - val_loss: 0.0719 - val_accuracy: 0.9786\n",
      "Epoch 475/700\n",
      "7352/7352 [==============================] - 3s 415us/sample - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0688 - val_accuracy: 0.9786\n",
      "Epoch 476/700\n",
      "7352/7352 [==============================] - 3s 384us/sample - loss: 0.0113 - accuracy: 0.9958 - val_loss: 0.0976 - val_accuracy: 0.9742\n",
      "Epoch 477/700\n",
      "7352/7352 [==============================] - 3s 384us/sample - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.0911 - val_accuracy: 0.9742\n",
      "Epoch 478/700\n",
      "7352/7352 [==============================] - 3s 373us/sample - loss: 0.0128 - accuracy: 0.9956 - val_loss: 0.0796 - val_accuracy: 0.9759\n",
      "Epoch 479/700\n",
      "7352/7352 [==============================] - 3s 405us/sample - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.1177 - val_accuracy: 0.9623\n",
      "Epoch 480/700\n",
      "7352/7352 [==============================] - 3s 347us/sample - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.0988 - val_accuracy: 0.9691\n",
      "Epoch 481/700\n",
      "7352/7352 [==============================] - 3s 397us/sample - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.0834 - val_accuracy: 0.9783\n",
      "Epoch 482/700\n",
      "7352/7352 [==============================] - 3s 373us/sample - loss: 0.0110 - accuracy: 0.9956 - val_loss: 0.0712 - val_accuracy: 0.9817\n",
      "Epoch 483/700\n",
      "7352/7352 [==============================] - 3s 366us/sample - loss: 0.0119 - accuracy: 0.9956 - val_loss: 0.0945 - val_accuracy: 0.9749\n",
      "Epoch 484/700\n",
      "7352/7352 [==============================] - 3s 378us/sample - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0636 - val_accuracy: 0.9803\n",
      "Epoch 485/700\n",
      "7352/7352 [==============================] - 3s 449us/sample - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0692 - val_accuracy: 0.9793\n",
      "Epoch 486/700\n",
      "7352/7352 [==============================] - 3s 397us/sample - loss: 0.0106 - accuracy: 0.9956 - val_loss: 0.0696 - val_accuracy: 0.9827\n",
      "Epoch 487/700\n",
      "7352/7352 [==============================] - 3s 370us/sample - loss: 0.0124 - accuracy: 0.9947 - val_loss: 0.0592 - val_accuracy: 0.9820\n",
      "Epoch 488/700\n",
      "7352/7352 [==============================] - 3s 389us/sample - loss: 0.0112 - accuracy: 0.9952 - val_loss: 0.0741 - val_accuracy: 0.9762\n",
      "Epoch 489/700\n",
      "7352/7352 [==============================] - 3s 370us/sample - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0612 - val_accuracy: 0.9820\n",
      "Epoch 490/700\n",
      "7352/7352 [==============================] - 3s 359us/sample - loss: 0.0155 - accuracy: 0.9940 - val_loss: 0.0854 - val_accuracy: 0.9742\n",
      "Epoch 491/700\n",
      "7352/7352 [==============================] - 3s 396us/sample - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.1081 - val_accuracy: 0.9698\n",
      "Epoch 492/700\n",
      "7352/7352 [==============================] - 3s 395us/sample - loss: 0.0137 - accuracy: 0.9946 - val_loss: 0.0565 - val_accuracy: 0.9834\n",
      "Epoch 493/700\n",
      "7352/7352 [==============================] - 3s 374us/sample - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0503 - val_accuracy: 0.9841\n",
      "Epoch 494/700\n",
      "7352/7352 [==============================] - 3s 408us/sample - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0535 - val_accuracy: 0.9800\n",
      "Epoch 495/700\n",
      "7352/7352 [==============================] - 3s 394us/sample - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.0646 - val_accuracy: 0.9790\n",
      "Epoch 496/700\n",
      "7352/7352 [==============================] - 3s 429us/sample - loss: 0.0117 - accuracy: 0.9956 - val_loss: 0.0602 - val_accuracy: 0.9813\n",
      "Epoch 497/700\n",
      "7352/7352 [==============================] - 3s 451us/sample - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.0872 - val_accuracy: 0.9759\n",
      "Epoch 498/700\n",
      "7352/7352 [==============================] - 4s 498us/sample - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0824 - val_accuracy: 0.9746\n",
      "Epoch 499/700\n",
      "7352/7352 [==============================] - 3s 394us/sample - loss: 0.0098 - accuracy: 0.9954 - val_loss: 0.0700 - val_accuracy: 0.9776\n",
      "Epoch 500/700\n",
      "7352/7352 [==============================] - 3s 402us/sample - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0906 - val_accuracy: 0.9752\n",
      "Epoch 501/700\n",
      "7352/7352 [==============================] - 3s 411us/sample - loss: 0.0111 - accuracy: 0.9955 - val_loss: 0.0753 - val_accuracy: 0.9759\n",
      "Epoch 502/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0101 - accuracy: 0.9961 - val_loss: 0.0889 - val_accuracy: 0.9732\n",
      "Epoch 503/700\n",
      "7352/7352 [==============================] - 3s 391us/sample - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.1107 - val_accuracy: 0.9705\n",
      "Epoch 504/700\n",
      "7352/7352 [==============================] - 4s 557us/sample - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.0757 - val_accuracy: 0.9742\n",
      "Epoch 505/700\n",
      "7352/7352 [==============================] - 4s 599us/sample - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0805 - val_accuracy: 0.9712\n",
      "Epoch 506/700\n",
      "7352/7352 [==============================] - 3s 428us/sample - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.0765 - val_accuracy: 0.9732\n",
      "Epoch 507/700\n",
      "7352/7352 [==============================] - 3s 394us/sample - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.0811 - val_accuracy: 0.9732\n",
      "Epoch 508/700\n",
      "7352/7352 [==============================] - 3s 368us/sample - loss: 0.0119 - accuracy: 0.9955 - val_loss: 0.0754 - val_accuracy: 0.9779\n",
      "Epoch 509/700\n",
      "7352/7352 [==============================] - 3s 372us/sample - loss: 0.0151 - accuracy: 0.9939 - val_loss: 0.0699 - val_accuracy: 0.9810\n",
      "Epoch 510/700\n",
      "7352/7352 [==============================] - 3s 355us/sample - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.0923 - val_accuracy: 0.9735\n",
      "Epoch 511/700\n",
      "7352/7352 [==============================] - 3s 398us/sample - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.0911 - val_accuracy: 0.9735\n",
      "Epoch 512/700\n",
      "7352/7352 [==============================] - 3s 381us/sample - loss: 0.0126 - accuracy: 0.9943 - val_loss: 0.0852 - val_accuracy: 0.9725\n",
      "Epoch 513/700\n",
      "7352/7352 [==============================] - 3s 349us/sample - loss: 0.0129 - accuracy: 0.9950 - val_loss: 0.0817 - val_accuracy: 0.9752\n",
      "Epoch 514/700\n",
      "7352/7352 [==============================] - 3s 421us/sample - loss: 0.0089 - accuracy: 0.9963 - val_loss: 0.1130 - val_accuracy: 0.9667\n",
      "Epoch 515/700\n",
      "7352/7352 [==============================] - 4s 507us/sample - loss: 0.0164 - accuracy: 0.9935 - val_loss: 0.1094 - val_accuracy: 0.9674\n",
      "Epoch 516/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0133 - accuracy: 0.9944 - val_loss: 0.1017 - val_accuracy: 0.9674\n",
      "Epoch 517/700\n",
      "7352/7352 [==============================] - 4s 488us/sample - loss: 0.0119 - accuracy: 0.9952 - val_loss: 0.0845 - val_accuracy: 0.9752\n",
      "Epoch 518/700\n",
      "7352/7352 [==============================] - 6s 789us/sample - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0859 - val_accuracy: 0.9776\n",
      "Epoch 519/700\n",
      "7352/7352 [==============================] - 3s 422us/sample - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.0966 - val_accuracy: 0.9705\n",
      "Epoch 520/700\n",
      "7352/7352 [==============================] - 3s 432us/sample - loss: 0.0102 - accuracy: 0.9961 - val_loss: 0.0824 - val_accuracy: 0.9739\n",
      "Epoch 521/700\n",
      "7352/7352 [==============================] - 3s 393us/sample - loss: 0.0102 - accuracy: 0.9962 - val_loss: 0.1040 - val_accuracy: 0.9718\n",
      "Epoch 522/700\n",
      "7352/7352 [==============================] - 3s 446us/sample - loss: 0.0163 - accuracy: 0.9936 - val_loss: 0.0791 - val_accuracy: 0.9735\n",
      "Epoch 523/700\n",
      "7352/7352 [==============================] - 3s 421us/sample - loss: 0.0159 - accuracy: 0.9940 - val_loss: 0.1175 - val_accuracy: 0.9708\n",
      "Epoch 524/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.1004 - val_accuracy: 0.9712\n",
      "Epoch 525/700\n",
      "7352/7352 [==============================] - 3s 450us/sample - loss: 0.0131 - accuracy: 0.9944 - val_loss: 0.1032 - val_accuracy: 0.9722\n",
      "Epoch 526/700\n",
      "7352/7352 [==============================] - 3s 437us/sample - loss: 0.0096 - accuracy: 0.9961 - val_loss: 0.1101 - val_accuracy: 0.9701\n",
      "Epoch 527/700\n",
      "7352/7352 [==============================] - 3s 414us/sample - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0974 - val_accuracy: 0.9718\n",
      "Epoch 528/700\n",
      "7352/7352 [==============================] - 3s 464us/sample - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.0755 - val_accuracy: 0.9776\n",
      "Epoch 529/700\n",
      "7352/7352 [==============================] - 3s 448us/sample - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0815 - val_accuracy: 0.9739\n",
      "Epoch 530/700\n",
      "7352/7352 [==============================] - 3s 448us/sample - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.0700 - val_accuracy: 0.9800\n",
      "Epoch 531/700\n",
      "7352/7352 [==============================] - 3s 411us/sample - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0700 - val_accuracy: 0.9793\n",
      "Epoch 532/700\n",
      "7352/7352 [==============================] - 3s 429us/sample - loss: 0.0133 - accuracy: 0.9947 - val_loss: 0.0702 - val_accuracy: 0.9786\n",
      "Epoch 533/700\n",
      "7352/7352 [==============================] - 3s 399us/sample - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0749 - val_accuracy: 0.9769\n",
      "Epoch 534/700\n",
      "7352/7352 [==============================] - 3s 467us/sample - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.0763 - val_accuracy: 0.9790\n",
      "Epoch 535/700\n",
      "7352/7352 [==============================] - 3s 426us/sample - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0875 - val_accuracy: 0.9722\n",
      "Epoch 536/700\n",
      "7352/7352 [==============================] - 3s 432us/sample - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.0745 - val_accuracy: 0.9742\n",
      "Epoch 537/700\n",
      "7352/7352 [==============================] - 3s 445us/sample - loss: 0.0129 - accuracy: 0.9948 - val_loss: 0.0615 - val_accuracy: 0.9800s: 0.012\n",
      "Epoch 538/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.0688 - val_accuracy: 0.9786\n",
      "Epoch 539/700\n",
      "7352/7352 [==============================] - 3s 419us/sample - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0804 - val_accuracy: 0.9762\n",
      "Epoch 540/700\n",
      "7352/7352 [==============================] - 3s 430us/sample - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.0761 - val_accuracy: 0.9759\n",
      "Epoch 541/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0602 - val_accuracy: 0.9824\n",
      "Epoch 542/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0115 - accuracy: 0.9955 - val_loss: 0.0762 - val_accuracy: 0.9779\n",
      "Epoch 543/700\n",
      "7352/7352 [==============================] - 3s 412us/sample - loss: 0.0095 - accuracy: 0.9962 - val_loss: 0.0715 - val_accuracy: 0.9779\n",
      "Epoch 544/700\n",
      "7352/7352 [==============================] - 3s 416us/sample - loss: 0.0106 - accuracy: 0.9963 - val_loss: 0.0767 - val_accuracy: 0.9766\n",
      "Epoch 545/700\n",
      "7352/7352 [==============================] - 3s 456us/sample - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.1098 - val_accuracy: 0.9695\n",
      "Epoch 546/700\n",
      "7352/7352 [==============================] - 3s 429us/sample - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1023 - val_accuracy: 0.9722\n",
      "Epoch 547/700\n",
      "7352/7352 [==============================] - 3s 462us/sample - loss: 0.0099 - accuracy: 0.9961 - val_loss: 0.0930 - val_accuracy: 0.9729\n",
      "Epoch 548/700\n",
      "7352/7352 [==============================] - 3s 426us/sample - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0692 - val_accuracy: 0.9766\n",
      "Epoch 549/700\n",
      "7352/7352 [==============================] - 3s 448us/sample - loss: 0.0097 - accuracy: 0.9974 - val_loss: 0.0719 - val_accuracy: 0.9786\n",
      "Epoch 550/700\n",
      "7352/7352 [==============================] - 3s 471us/sample - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.0817 - val_accuracy: 0.9756\n",
      "Epoch 551/700\n",
      "7352/7352 [==============================] - 3s 429us/sample - loss: 0.0096 - accuracy: 0.9962 - val_loss: 0.0682 - val_accuracy: 0.9820\n",
      "Epoch 552/700\n",
      "7352/7352 [==============================] - 3s 437us/sample - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0702 - val_accuracy: 0.9776\n",
      "Epoch 553/700\n",
      "7352/7352 [==============================] - 3s 425us/sample - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0815 - val_accuracy: 0.9756\n",
      "Epoch 554/700\n",
      "7352/7352 [==============================] - 3s 449us/sample - loss: 0.0094 - accuracy: 0.9966 - val_loss: 0.0898 - val_accuracy: 0.9729\n",
      "Epoch 555/700\n",
      "7352/7352 [==============================] - 3s 455us/sample - loss: 0.0112 - accuracy: 0.9950 - val_loss: 0.0793 - val_accuracy: 0.9769\n",
      "Epoch 556/700\n",
      "7352/7352 [==============================] - 3s 425us/sample - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.0701 - val_accuracy: 0.9790\n",
      "Epoch 557/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.0763 - val_accuracy: 0.9766\n",
      "Epoch 558/700\n",
      "7352/7352 [==============================] - 3s 427us/sample - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0991 - val_accuracy: 0.9708\n",
      "Epoch 559/700\n",
      "7352/7352 [==============================] - 3s 453us/sample - loss: 0.0076 - accuracy: 0.9971 - val_loss: 0.0886 - val_accuracy: 0.9722\n",
      "Epoch 560/700\n",
      "7352/7352 [==============================] - 3s 425us/sample - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0933 - val_accuracy: 0.9746\n",
      "Epoch 561/700\n",
      "7352/7352 [==============================] - 3s 424us/sample - loss: 0.0097 - accuracy: 0.9962 - val_loss: 0.0747 - val_accuracy: 0.9769\n",
      "Epoch 562/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.0799 - val_accuracy: 0.9752\n",
      "Epoch 563/700\n",
      "7352/7352 [==============================] - 3s 441us/sample - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0979 - val_accuracy: 0.9715\n",
      "Epoch 564/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 565/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.1069 - val_accuracy: 0.9691\n",
      "Epoch 566/700\n",
      "7352/7352 [==============================] - 3s 416us/sample - loss: 0.0163 - accuracy: 0.9931 - val_loss: 0.0961 - val_accuracy: 0.9718\n",
      "Epoch 567/700\n",
      "7352/7352 [==============================] - 3s 443us/sample - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0804 - val_accuracy: 0.9746\n",
      "Epoch 568/700\n",
      "7352/7352 [==============================] - 3s 396us/sample - loss: 0.0104 - accuracy: 0.9956 - val_loss: 0.1016 - val_accuracy: 0.9695\n",
      "Epoch 569/700\n",
      "7352/7352 [==============================] - 3s 441us/sample - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.0805 - val_accuracy: 0.9746\n",
      "Epoch 570/700\n",
      "7352/7352 [==============================] - 4s 517us/sample - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0884 - val_accuracy: 0.9732\n",
      "Epoch 571/700\n",
      "7352/7352 [==============================] - 3s 457us/sample - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0753 - val_accuracy: 0.9793\n",
      "Epoch 572/700\n",
      "7352/7352 [==============================] - 3s 413us/sample - loss: 0.0098 - accuracy: 0.9959 - val_loss: 0.0821 - val_accuracy: 0.9742\n",
      "Epoch 573/700\n",
      "7352/7352 [==============================] - 3s 439us/sample - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.0928 - val_accuracy: 0.9729\n",
      "Epoch 574/700\n",
      "7352/7352 [==============================] - 3s 416us/sample - loss: 0.0113 - accuracy: 0.9955 - val_loss: 0.0942 - val_accuracy: 0.9698\n",
      "Epoch 575/700\n",
      "7352/7352 [==============================] - 3s 454us/sample - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.0938 - val_accuracy: 0.9691\n",
      "Epoch 576/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0104 - accuracy: 0.9961 - val_loss: 0.1017 - val_accuracy: 0.9698\n",
      "Epoch 577/700\n",
      "7352/7352 [==============================] - 5s 703us/sample - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0756 - val_accuracy: 0.9752\n",
      "Epoch 578/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.0097 - accuracy: 0.9958 - val_loss: 0.0706 - val_accuracy: 0.9746\n",
      "Epoch 579/700\n",
      "7352/7352 [==============================] - 3s 368us/sample - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0817 - val_accuracy: 0.9749\n",
      "Epoch 580/700\n",
      "7352/7352 [==============================] - 3s 449us/sample - loss: 0.0105 - accuracy: 0.9966 - val_loss: 0.1035 - val_accuracy: 0.9695\n",
      "Epoch 581/700\n",
      "7352/7352 [==============================] - 4s 504us/sample - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0693 - val_accuracy: 0.9790\n",
      "Epoch 582/700\n",
      "7352/7352 [==============================] - 5s 621us/sample - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0798 - val_accuracy: 0.9752\n",
      "Epoch 583/700\n",
      "7352/7352 [==============================] - 6s 751us/sample - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0724 - val_accuracy: 0.9783\n",
      "Epoch 584/700\n",
      "7352/7352 [==============================] - 5s 727us/sample - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.0972 - val_accuracy: 0.9671\n",
      "Epoch 585/700\n",
      "7352/7352 [==============================] - 4s 528us/sample - loss: 0.0087 - accuracy: 0.9966 - val_loss: 0.0782 - val_accuracy: 0.9735\n",
      "Epoch 586/700\n",
      "7352/7352 [==============================] - 4s 516us/sample - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0657 - val_accuracy: 0.9783\n",
      "Epoch 587/700\n",
      "7352/7352 [==============================] - 4s 579us/sample - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0755 - val_accuracy: 0.9773\n",
      "Epoch 588/700\n",
      "7352/7352 [==============================] - 5s 744us/sample - loss: 0.0188 - accuracy: 0.9931 - val_loss: 0.0833 - val_accuracy: 0.9742\n",
      "Epoch 589/700\n",
      "7352/7352 [==============================] - 8s 1ms/sample - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0817 - val_accuracy: 0.9756\n",
      "Epoch 590/700\n",
      "7352/7352 [==============================] - 6s 818us/sample - loss: 0.0108 - accuracy: 0.9961 - val_loss: 0.0863 - val_accuracy: 0.9715\n",
      "Epoch 591/700\n",
      "7352/7352 [==============================] - 5s 649us/sample - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0965 - val_accuracy: 0.9688\n",
      "Epoch 592/700\n",
      "7352/7352 [==============================] - 6s 749us/sample - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0899 - val_accuracy: 0.9742\n",
      "Epoch 593/700\n",
      "7352/7352 [==============================] - 4s 598us/sample - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0917 - val_accuracy: 0.9698\n",
      "Epoch 594/700\n",
      "7352/7352 [==============================] - 4s 537us/sample - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0993 - val_accuracy: 0.9688\n",
      "Epoch 595/700\n",
      "7352/7352 [==============================] - 4s 498us/sample - loss: 0.0128 - accuracy: 0.9952 - val_loss: 0.0963 - val_accuracy: 0.9681\n",
      "Epoch 596/700\n",
      "7352/7352 [==============================] - 4s 569us/sample - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0971 - val_accuracy: 0.9705\n",
      "Epoch 597/700\n",
      "7352/7352 [==============================] - 3s 467us/sample - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.0758 - val_accuracy: 0.9766\n",
      "Epoch 598/700\n",
      "7352/7352 [==============================] - 3s 469us/sample - loss: 0.0099 - accuracy: 0.9963 - val_loss: 0.0808 - val_accuracy: 0.9762\n",
      "Epoch 599/700\n",
      "7352/7352 [==============================] - 5s 689us/sample - loss: 0.0119 - accuracy: 0.9946 - val_loss: 0.0947 - val_accuracy: 0.9732\n",
      "Epoch 600/700\n",
      "7352/7352 [==============================] - 4s 553us/sample - loss: 0.0091 - accuracy: 0.9967 - val_loss: 0.1081 - val_accuracy: 0.9695\n",
      "Epoch 601/700\n",
      "7352/7352 [==============================] - 5s 741us/sample - loss: 0.0086 - accuracy: 0.9966 - val_loss: 0.0806 - val_accuracy: 0.9810\n",
      "Epoch 602/700\n",
      "7352/7352 [==============================] - 3s 474us/sample - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.0708 - val_accuracy: 0.9817\n",
      "Epoch 603/700\n",
      "7352/7352 [==============================] - 4s 476us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0840 - val_accuracy: 0.9759\n",
      "Epoch 604/700\n",
      "7352/7352 [==============================] - 4s 517us/sample - loss: 0.0086 - accuracy: 0.9970 - val_loss: 0.0794 - val_accuracy: 0.9800\n",
      "Epoch 605/700\n",
      "7352/7352 [==============================] - 4s 526us/sample - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0601 - val_accuracy: 0.9830\n",
      "Epoch 606/700\n",
      "7352/7352 [==============================] - 3s 417us/sample - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0865 - val_accuracy: 0.9749\n",
      "Epoch 607/700\n",
      "7352/7352 [==============================] - 3s 438us/sample - loss: 0.0154 - accuracy: 0.9939 - val_loss: 0.0797 - val_accuracy: 0.9766\n",
      "Epoch 608/700\n",
      "7352/7352 [==============================] - 3s 428us/sample - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0657 - val_accuracy: 0.9824\n",
      "Epoch 609/700\n",
      "7352/7352 [==============================] - 3s 466us/sample - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0786 - val_accuracy: 0.9776\n",
      "Epoch 610/700\n",
      "7352/7352 [==============================] - 3s 434us/sample - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0662 - val_accuracy: 0.9817\n",
      "Epoch 611/700\n",
      "7352/7352 [==============================] - 3s 417us/sample - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0802 - val_accuracy: 0.9790\n",
      "Epoch 612/700\n",
      "7352/7352 [==============================] - 3s 462us/sample - loss: 0.0129 - accuracy: 0.9946 - val_loss: 0.0692 - val_accuracy: 0.9810\n",
      "Epoch 613/700\n",
      "7352/7352 [==============================] - 3s 457us/sample - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0642 - val_accuracy: 0.9817\n",
      "Epoch 614/700\n",
      "7352/7352 [==============================] - 3s 407us/sample - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.0685 - val_accuracy: 0.9807\n",
      "Epoch 615/700\n",
      "7352/7352 [==============================] - 3s 424us/sample - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.0806 - val_accuracy: 0.9800\n",
      "Epoch 616/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.1014 - val_accuracy: 0.9732\n",
      "Epoch 617/700\n",
      "7352/7352 [==============================] - 3s 413us/sample - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0867 - val_accuracy: 0.9746\n",
      "Epoch 618/700\n",
      "7352/7352 [==============================] - 3s 422us/sample - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0912 - val_accuracy: 0.9722\n",
      "Epoch 619/700\n",
      "7352/7352 [==============================] - 3s 470us/sample - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0799 - val_accuracy: 0.9762\n",
      "Epoch 620/700\n",
      "7352/7352 [==============================] - 3s 435us/sample - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0775 - val_accuracy: 0.9762\n",
      "Epoch 621/700\n",
      "7352/7352 [==============================] - 3s 442us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0907 - val_accuracy: 0.9752\n",
      "Epoch 622/700\n",
      "7352/7352 [==============================] - 3s 422us/sample - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0760 - val_accuracy: 0.9786\n",
      "Epoch 623/700\n",
      "7352/7352 [==============================] - 3s 458us/sample - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0947 - val_accuracy: 0.9722\n",
      "Epoch 624/700\n",
      "7352/7352 [==============================] - 3s 444us/sample - loss: 0.0107 - accuracy: 0.9956 - val_loss: 0.0862 - val_accuracy: 0.9766\n",
      "Epoch 625/700\n",
      "7352/7352 [==============================] - 3s 422us/sample - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0727 - val_accuracy: 0.9779\n",
      "Epoch 626/700\n",
      "7352/7352 [==============================] - 3s 420us/sample - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.1013 - val_accuracy: 0.9695\n",
      "Epoch 627/700\n",
      "7352/7352 [==============================] - 4s 594us/sample - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0728 - val_accuracy: 0.9776\n",
      "Epoch 628/700\n",
      "7352/7352 [==============================] - 5s 627us/sample - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0863 - val_accuracy: 0.9718\n",
      "Epoch 629/700\n",
      "7352/7352 [==============================] - 4s 555us/sample - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0792 - val_accuracy: 0.9746\n",
      "Epoch 630/700\n",
      "7352/7352 [==============================] - 3s 431us/sample - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0805 - val_accuracy: 0.9762\n",
      "Epoch 631/700\n",
      "7352/7352 [==============================] - 4s 538us/sample - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1011 - val_accuracy: 0.9695\n",
      "Epoch 632/700\n",
      "7352/7352 [==============================] - 3s 399us/sample - loss: 0.0096 - accuracy: 0.9958 - val_loss: 0.0798 - val_accuracy: 0.9752\n",
      "Epoch 633/700\n",
      "7352/7352 [==============================] - 3s 358us/sample - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.0767 - val_accuracy: 0.9773\n",
      "Epoch 634/700\n",
      "7352/7352 [==============================] - 3s 390us/sample - loss: 0.0091 - accuracy: 0.9963 - val_loss: 0.0807 - val_accuracy: 0.9773\n",
      "Epoch 635/700\n",
      "7352/7352 [==============================] - 3s 410us/sample - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.0737 - val_accuracy: 0.9766\n",
      "Epoch 636/700\n",
      "7352/7352 [==============================] - 3s 382us/sample - loss: 0.0081 - accuracy: 0.9966 - val_loss: 0.0728 - val_accuracy: 0.9773\n",
      "Epoch 637/700\n",
      "7352/7352 [==============================] - 3s 363us/sample - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0694 - val_accuracy: 0.9762\n",
      "Epoch 638/700\n",
      "7352/7352 [==============================] - 3s 398us/sample - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0725 - val_accuracy: 0.9756\n",
      "Epoch 639/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0081 - accuracy: 0.9971 - val_loss: 0.0877 - val_accuracy: 0.9739\n",
      "Epoch 640/700\n",
      "7352/7352 [==============================] - 3s 422us/sample - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0932 - val_accuracy: 0.9756\n",
      "Epoch 641/700\n",
      "7352/7352 [==============================] - 3s 392us/sample - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.1021 - val_accuracy: 0.9732\n",
      "Epoch 642/700\n",
      "7352/7352 [==============================] - 3s 379us/sample - loss: 0.0094 - accuracy: 0.9962 - val_loss: 0.0898 - val_accuracy: 0.9729\n",
      "Epoch 643/700\n",
      "7352/7352 [==============================] - 3s 381us/sample - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0581 - val_accuracy: 0.9813\n",
      "Epoch 644/700\n",
      "7352/7352 [==============================] - 3s 380us/sample - loss: 0.0080 - accuracy: 0.9967 - val_loss: 0.0641 - val_accuracy: 0.9779\n",
      "Epoch 645/700\n",
      "7352/7352 [==============================] - 3s 365us/sample - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0633 - val_accuracy: 0.9800\n",
      "Epoch 646/700\n",
      "7352/7352 [==============================] - 3s 386us/sample - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0892 - val_accuracy: 0.9732\n",
      "Epoch 647/700\n",
      "7352/7352 [==============================] - 3s 364us/sample - loss: 0.0066 - accuracy: 0.9976 - val_loss: 0.0856 - val_accuracy: 0.9725\n",
      "Epoch 648/700\n",
      "7352/7352 [==============================] - 3s 386us/sample - loss: 0.0068 - accuracy: 0.9973 - val_loss: 0.0779 - val_accuracy: 0.9756\n",
      "Epoch 649/700\n",
      "7352/7352 [==============================] - 3s 402us/sample - loss: 0.0089 - accuracy: 0.9965 - val_loss: 0.0887 - val_accuracy: 0.9735\n",
      "Epoch 650/700\n",
      "7352/7352 [==============================] - 3s 387us/sample - loss: 0.0068 - accuracy: 0.9974 - val_loss: 0.0827 - val_accuracy: 0.9742\n",
      "Epoch 651/700\n",
      "7352/7352 [==============================] - 3s 372us/sample - loss: 0.0090 - accuracy: 0.9965 - val_loss: 0.0813 - val_accuracy: 0.9759\n",
      "Epoch 652/700\n",
      "7352/7352 [==============================] - 3s 390us/sample - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.0792 - val_accuracy: 0.9749\n",
      "Epoch 653/700\n",
      "7352/7352 [==============================] - 3s 369us/sample - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0970 - val_accuracy: 0.9725\n",
      "Epoch 654/700\n",
      "7352/7352 [==============================] - 3s 396us/sample - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0939 - val_accuracy: 0.9735\n",
      "Epoch 655/700\n",
      "7352/7352 [==============================] - 3s 386us/sample - loss: 0.0068 - accuracy: 0.9969 - val_loss: 0.1030 - val_accuracy: 0.9712\n",
      "Epoch 656/700\n",
      "7352/7352 [==============================] - 3s 399us/sample - loss: 0.0086 - accuracy: 0.9959 - val_loss: 0.1087 - val_accuracy: 0.9698\n",
      "Epoch 657/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0108 - accuracy: 0.9955 - val_loss: 0.1321 - val_accuracy: 0.9654\n",
      "Epoch 658/700\n",
      "7352/7352 [==============================] - 3s 371us/sample - loss: 0.0120 - accuracy: 0.9951 - val_loss: 0.0873 - val_accuracy: 0.9759\n",
      "Epoch 659/700\n",
      "7352/7352 [==============================] - 3s 383us/sample - loss: 0.0099 - accuracy: 0.9961 - val_loss: 0.1047 - val_accuracy: 0.9722\n",
      "Epoch 660/700\n",
      "7352/7352 [==============================] - 3s 377us/sample - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0979 - val_accuracy: 0.9732\n",
      "Epoch 661/700\n",
      "7352/7352 [==============================] - 3s 380us/sample - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0822 - val_accuracy: 0.9776\n",
      "Epoch 662/700\n",
      "7352/7352 [==============================] - 3s 371us/sample - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.0822 - val_accuracy: 0.9766\n",
      "Epoch 663/700\n",
      "7352/7352 [==============================] - 3s 377us/sample - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0940 - val_accuracy: 0.9735\n",
      "Epoch 664/700\n",
      "7352/7352 [==============================] - 3s 374us/sample - loss: 0.0069 - accuracy: 0.9974 - val_loss: 0.0788 - val_accuracy: 0.9769\n",
      "Epoch 665/700\n",
      "7352/7352 [==============================] - 3s 380us/sample - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.0851 - val_accuracy: 0.9759\n",
      "Epoch 666/700\n",
      "7352/7352 [==============================] - 3s 381us/sample - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0754 - val_accuracy: 0.9790\n",
      "Epoch 667/700\n",
      "7352/7352 [==============================] - 3s 386us/sample - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0858 - val_accuracy: 0.9749\n",
      "Epoch 668/700\n",
      "7352/7352 [==============================] - 3s 364us/sample - loss: 0.0074 - accuracy: 0.9967 - val_loss: 0.0818 - val_accuracy: 0.9776\n",
      "Epoch 669/700\n",
      "7352/7352 [==============================] - 3s 388us/sample - loss: 0.0098 - accuracy: 0.9962 - val_loss: 0.1049 - val_accuracy: 0.9701\n",
      "Epoch 670/700\n",
      "7352/7352 [==============================] - 3s 397us/sample - loss: 0.0084 - accuracy: 0.9965 - val_loss: 0.0832 - val_accuracy: 0.9773\n",
      "Epoch 671/700\n",
      "7352/7352 [==============================] - 3s 390us/sample - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.0901 - val_accuracy: 0.9746\n",
      "Epoch 672/700\n",
      "7352/7352 [==============================] - 3s 384us/sample - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0864 - val_accuracy: 0.9756\n",
      "Epoch 673/700\n",
      "7352/7352 [==============================] - 3s 385us/sample - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0971 - val_accuracy: 0.9756\n",
      "Epoch 674/700\n",
      "7352/7352 [==============================] - 3s 397us/sample - loss: 0.0072 - accuracy: 0.9986 - val_loss: 0.1075 - val_accuracy: 0.9674\n",
      "Epoch 675/700\n",
      "7352/7352 [==============================] - 3s 416us/sample - loss: 0.0075 - accuracy: 0.9969 - val_loss: 0.0908 - val_accuracy: 0.9729\n",
      "Epoch 676/700\n",
      "7352/7352 [==============================] - 4s 501us/sample - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0859 - val_accuracy: 0.9766\n",
      "Epoch 677/700\n",
      "7352/7352 [==============================] - 3s 458us/sample - loss: 0.0063 - accuracy: 0.9986 - val_loss: 0.0793 - val_accuracy: 0.9783\n",
      "Epoch 678/700\n",
      "7352/7352 [==============================] - 3s 433us/sample - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0687 - val_accuracy: 0.9817\n",
      "Epoch 679/700\n",
      "7352/7352 [==============================] - 3s 382us/sample - loss: 0.0093 - accuracy: 0.9963 - val_loss: 0.0829 - val_accuracy: 0.9752\n",
      "Epoch 680/700\n",
      "7352/7352 [==============================] - 3s 395us/sample - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.0758 - val_accuracy: 0.9793\n",
      "Epoch 681/700\n",
      "7352/7352 [==============================] - 3s 398us/sample - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0664 - val_accuracy: 0.9830\n",
      "Epoch 682/700\n",
      "7352/7352 [==============================] - 3s 462us/sample - loss: 0.0078 - accuracy: 0.9971 - val_loss: 0.0749 - val_accuracy: 0.9810\n",
      "Epoch 683/700\n",
      "7352/7352 [==============================] - 3s 468us/sample - loss: 0.0084 - accuracy: 0.9966 - val_loss: 0.0686 - val_accuracy: 0.9810\n",
      "Epoch 684/700\n",
      "7352/7352 [==============================] - 3s 436us/sample - loss: 0.0095 - accuracy: 0.9961 - val_loss: 0.0809 - val_accuracy: 0.9766\n",
      "Epoch 685/700\n",
      "7352/7352 [==============================] - 3s 415us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.0820 - val_accuracy: 0.9769\n",
      "Epoch 686/700\n",
      "7352/7352 [==============================] - 3s 391us/sample - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0723 - val_accuracy: 0.9790\n",
      "Epoch 687/700\n",
      "7352/7352 [==============================] - 4s 528us/sample - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0882 - val_accuracy: 0.9735\n",
      "Epoch 688/700\n",
      "7352/7352 [==============================] - 3s 419us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0756 - val_accuracy: 0.9773\n",
      "Epoch 689/700\n",
      "7352/7352 [==============================] - 3s 410us/sample - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0763 - val_accuracy: 0.9756\n",
      "Epoch 690/700\n",
      "7352/7352 [==============================] - 3s 470us/sample - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.0729 - val_accuracy: 0.9773\n",
      "Epoch 691/700\n",
      "7352/7352 [==============================] - 3s 475us/sample - loss: 0.0050 - accuracy: 0.9981 - val_loss: 0.0790 - val_accuracy: 0.9752\n",
      "Epoch 692/700\n",
      "7352/7352 [==============================] - 3s 473us/sample - loss: 0.0054 - accuracy: 0.9981 - val_loss: 0.0909 - val_accuracy: 0.9735\n",
      "Epoch 693/700\n",
      "7352/7352 [==============================] - 3s 453us/sample - loss: 0.0085 - accuracy: 0.9965 - val_loss: 0.0696 - val_accuracy: 0.9793\n",
      "Epoch 694/700\n",
      "7352/7352 [==============================] - 3s 391us/sample - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0827 - val_accuracy: 0.9752\n",
      "Epoch 695/700\n",
      "7352/7352 [==============================] - 3s 423us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0794 - val_accuracy: 0.9769\n",
      "Epoch 696/700\n",
      "7352/7352 [==============================] - 3s 371us/sample - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.0773 - val_accuracy: 0.9766\n",
      "Epoch 697/700\n",
      "7352/7352 [==============================] - 3s 440us/sample - loss: 0.0071 - accuracy: 0.9973 - val_loss: 0.0791 - val_accuracy: 0.9773\n",
      "Epoch 698/700\n",
      "7352/7352 [==============================] - 3s 401us/sample - loss: 0.0078 - accuracy: 0.9967 - val_loss: 0.0998 - val_accuracy: 0.9742\n",
      "Epoch 699/700\n",
      "7352/7352 [==============================] - 3s 401us/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.0712 - val_accuracy: 0.9796\n",
      "Epoch 700/700\n",
      "7352/7352 [==============================] - 3s 395us/sample - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.0751 - val_accuracy: 0.9759\n",
      "------------------------ 测试中---------------------------\n",
      "2947/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 141us/sample - loss: 0.0376 - accuracy: 0.9759\n",
      "Baseline Error: 2.41%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "           WALKING       1.00      0.99      0.99       496\n",
      "  WALKING_UPSTAIRS       0.99      0.97      0.98       471\n",
      "WALKING_DOWNSTAIRS       0.96      1.00      0.98       420\n",
      "           SITTING       0.98      0.92      0.95       491\n",
      "          STANDING       0.93      0.98      0.96       532\n",
      "            LAYING       1.00      1.00      1.00       537\n",
      "\n",
      "          accuracy                           0.98      2947\n",
      "         macro avg       0.98      0.98      0.98      2947\n",
      "      weighted avg       0.98      0.98      0.98      2947\n",
      "\n",
      "[[491   1   4   0   0   0]\n",
      " [  0 458  13   0   0   0]\n",
      " [  0   2 418   0   0   0]\n",
      " [  0   2   0 450  38   1]\n",
      " [  0   0   1   9 522   0]\n",
      " [  0   0   0   0   0 537]]\n",
      "Size of the unpruned model before compression: 2.71 Mb\n",
      "Size of the unpruned model after compression: 2.45 Mb\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import csv\n",
    "import tempfile\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Reshape\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.keras import backend as K\n",
    "from utils.utilities import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(813306)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 忽略 Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
    "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allocator_type = 'BFC'  # A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "#config.gpu_options.allow_growth = True\n",
    "#set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "#数据预处理\n",
    "tf.keras.backend.set_image_data_format('channels_last')\n",
    "#构建数据集 channel_last\n",
    "#构建数据集 channel_last\n",
    "def load_data():    \n",
    "    X_train, labels_train, list_ch_train = read_data(data_path=\"../data/HAR_Dataset\", split=\"train\") # train\n",
    "    X_test, labels_test, list_ch_test = read_data(data_path=\"../data/HAR_Dataset\", split=\"test\") # test\n",
    "    assert list_ch_train == list_ch_test, \"Mistmatch in channels!\"\n",
    "    x_train = X_train[:,:,np.newaxis,:]\n",
    "    x_val = X_test[:,:,np.newaxis,:]\n",
    "    y_train = to_categorical(labels_train)\n",
    "    y_val = to_categorical(labels_test)\n",
    "    return (x_train,y_train),(x_val,y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_resnet(input_shape, n_feature_maps, nb_classes, dropout):\n",
    "    print('build conv_x')\n",
    "    x = Input(shape=(input_shape))\n",
    "\n",
    "    x_total = keras.layers.Conv2D(10, (17, 1),strides = (1,1), padding='same')(x)\n",
    "    conv_x = keras.layers.BatchNormalization()(x_total)  # 853\n",
    "\n",
    " \n",
    "    conv_x = keras.layers.Conv2D(n_feature_maps, (17, 1), padding='same')(conv_x)  # input size == ouput size\n",
    "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "    conv_x = Activation('relu')(conv_x)\n",
    "\n",
    "    print('build conv_y')\n",
    "    conv_y = keras.layers.Conv2D(n_feature_maps * 2, (17, 1), padding='same')(conv_x)\n",
    "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "    conv_y = Activation('relu')(conv_y)\n",
    "\n",
    "    conv_y = Dropout(dropout)(conv_y)\n",
    "    print('build conv_z')\n",
    "    conv_z = keras.layers.Conv2D(n_feature_maps, (9, 1), padding='same')(conv_y)\n",
    "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "    is_expand_channels = not (input_shape[-1] == n_feature_maps)  # 若当前输出和跨层连接的x，通道数不同，则采用1*1卷积使得通道数相同\n",
    "    if is_expand_channels:\n",
    "        shortcut_y = keras.layers.Conv2D(n_feature_maps, (1, 1), padding='same')(x_total)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "    else:\n",
    "        shortcut_y = keras.layers.BatchNormalization()(x_total)\n",
    "\n",
    "    print('Merging skip connection')\n",
    "    # y = merge([shortcut_y, conv_z], mode='sum')\n",
    "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "\n",
    "    full = keras.layers.GlobalAveragePooling2D()(y)\n",
    "    out = Dense(nb_classes, activation='softmax')(full)\n",
    "    print('        -- model was built.')\n",
    "    return x, out\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = 7\n",
    "    channels = 9\n",
    "    dropout = 0.2\n",
    "    nb_epochs = 700\n",
    "    batch_size = 50\n",
    "    data_row = 128\n",
    "    data_column = 1\n",
    "    trainpath = r'./data'\n",
    "\n",
    "    (x_train,y_train),(x_val,y_val) = load_data()\n",
    "\n",
    "\n",
    "    tf.keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "\n",
    "    input_shape = (data_row, data_column,channels)\n",
    "\n",
    "    print('train dataset size:',x_train.shape[0])\n",
    "    print('validation dataset size:',x_val.shape[0])\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    x, y = build_resnet(input_shape, 64, num, dropout)  # 建立resnet只考虑了单个example\n",
    "    model = Model(inputs=x, outputs=y)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.9,\n",
    "                                  patience=20, min_lr=0.00005)\n",
    "    hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,\n",
    "                     verbose=1, validation_data=(x_val, y_val), callbacks=[reduce_lr])  # 回调函数会在训练的时候适当被调用\n",
    "\n",
    "\n",
    "    # 测试\n",
    "    print(\"------------------------ 测试中---------------------------\")\n",
    "    #evaluation of the model\n",
    "    scores = model.evaluate(x_val,y_val)\n",
    "    print('Baseline Error: %.2f%%'%(100 * (1 - scores[1])))\n",
    "    y_pred_array = model.predict(x_val)\n",
    "    y_pred = []\n",
    "    for i in y_pred_array:\n",
    "        y_pred.append(np.argmax(i))\n",
    "    y_true = []\n",
    "    for i in y_val:\n",
    "        y_true.append(np.argmax(i))\n",
    "    print(classification_report(y_true, y_pred,target_names=['WALKING','WALKING_UPSTAIRS','WALKING_DOWNSTAIRS','SITTING','STANDING','LAYING'],digits=2))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    keras.models.save_model(model, '../model/test_resnet_v4.h5')\n",
    "    keras_file = '../model/test_resnet_v4.h5'\n",
    "    _, zip1 = tempfile.mkstemp('.zip') \n",
    "    with zipfile.ZipFile(zip1, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(keras_file)\n",
    "    print(\"Size of the unpruned model before compression: %.2f Mb\" % \n",
    "          (os.path.getsize(keras_file) / float(2**20)))\n",
    "    print(\"Size of the unpruned model after compression: %.2f Mb\" % \n",
    "          (os.path.getsize(zip1) / float(2**20)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HAR模型量化**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
